<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled</title>
    <meta name="description" content="Untitled - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme */
            --primary-color: #2980b9;
            --primary-hover: #1a5276;
            --link-color: #c0392b;
            --text-color: #333;
            --text-light: #666;
            --text-muted: #999;
            --bg-color: #fff;
            --bg-secondary: #f8f9fa;
            --bg-code: #f5f5f5;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px rgba(0,0,0,0.1);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#learning-without-forgetting">Learning without Forgetting</a></li>
<li><a href="#references">References</a></li>
<li><a href="#大模型译-arrow_down">大模型译 :arrow_down:</a></li>
<li><a href="#0-摘要">0. 摘要</a></li>
<li><a href="#1-引言">1. 引言</a></li>
<li><a href="#2-相关工作">2. 相关工作</a><ul>
<li><a href="#21-比较方法">2.1 比较方法</a></li>
<li><a href="#22-主题相关方法">2.2 主题相关方法</a></li>
</ul>
</li>
<li><a href="#3-无遗忘学习">3. 无遗忘学习</a></li>
<li><a href="#4-实验">4. 实验</a><ul>
<li><a href="#41-主要实验">4.1 主要实验</a></li>
<li><a href="#42-设计选择和替代方案">4.2 设计选择和替代方案</a></li>
</ul>
</li>
<li><a href="#5-讨论">5. 讨论</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>Untitled</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-01-28</span>
                        <span><i class="fas fa-folder"></i> AINotes/40.CIL/31.Logit Distillation</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="learning-without-forgetting">Learning without Forgetting<a class="anchor-link" href="#learning-without-forgetting" title="Permanent link">&para;</a></h2>
<p><a href="https://arxiv.org/abs/1606.09282">LwF</a>算法是基于深度学习的增量学习的里程碑之作，在介绍LwF算法之前，我们先了解一些最简单的增量学习方法。</p>
<p><img alt="LwF" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202412051039815.jpg" />  </p>
<p>上图展示了一个具有多头网络结构的模型学习新任务的不同策略，其中(a)为已经训练好的基于CNN的原始模型，<span class="math-inline">\theta_s</span> 示不同任务共享的CNN参数，<span class="math-inline">\theta_o</span> 示与原始任务相关的MLP参数【旧任务的分类器】，当加入一个新的分类任务时，我们可以增加一个随机初始化的MLP参数<span class="math-inline">\theta_n</span>【新任务分类器】。基于<span class="math-inline">\theta_s,\theta_o</span> 学习<span class="math-inline">\theta_n</span> 方法包括如下几类：</p>
<ul>
<li><strong>微调(Fine-tuning)</strong>：没有旧任务参数和样本的指导，因此模型在旧任务上的表现会变差，也就是发生灾难性遗忘。</li>
<li><strong>联合训练(Joint Training)</strong>：联合训练相当于在所有已知数据上重新训练模型，效果最好，因此通常被认为是<strong>增量学习的性能上界</strong>，但训练成本太高。</li>
<li><strong>特征抽取(Feature Extraction)</strong>：特征抽取只训练<span class="math-inline">\theta_n</span>，共享参数<span class="math-inline">\theta_s</span> 有得到更新，虽然不影响模型在旧任务上的表现，但不能有效捕获新任务独有的特征表示，在新任务上的表现通常不如人意。</li>
</ul>
<p>LwF算法是介于联合训练和微调训练之间的训练方式，LwF的特点是它不需要使用旧任务的数据也能够更新<span class="math-inline">\theta_o</span>。LwF算法的主要思想来自于<a href="https://arxiv.org/abs/1503.02531">Distilling the Knowledge in a Neural Network</a>，也就是使新模型在新任务上的预测和旧模型在新任务上的预测相近。具体来说，LwF算法先得到旧模型在新任务上的预测值，在损失函数中引入新模型输出的蒸馏损失，然后用微调的方法在新任务上训练模型，从而避免新任务的训练过分调整旧模型的参数而导致新模型在旧任务上性能的下降。算法流程如下图所示，其中<span class="math-inline">\lambda_o</span> 于权衡模型的稳定性和可塑性。</p>
<p><img alt="LwF—Algorithm" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202412051039816.jpg" />  </p>
<p><strong>分类loss</strong><br />
<div class="math-display"><br />
\mathcal{L}_{new}(\mathbf{y}_n,\mathbf{\hat{y}}_n) = - \mathbf{y}_n \cdot \log\mathbf{\hat{y}}_n<br />
</div><br />
- <span class="math-inline">\mathbf{y}_n</span>: 新数据的标签<br />
- <span class="math-inline">\mathbf{\hat{y}}_n</span>：新数据在新模型上的输出（分类器的参数输出包括<span class="math-inline">\hat{\theta_o}</span>, <span class="math-inline">\hat{\theta_n}</span>，这里取的<span class="math-inline">\hat{\theta_n}</span>）</p>
<p><strong>保留旧知识loss</strong><br />
<div class="math-display"><br />
\mathcal{L}<em>{old}(\mathbf{y}_o,\mathbf{\hat{y}}_o) = - H(\mathbf{y}'_o,\mathbf{\hat{y}}'_o) \<br />
    = - \sum</em>{i=1}^l y_o^{\prime (i)} \log \hat{y}_o^{\prime (i)}<br />
</div><br />
- <span class="math-inline">\mathbf{y}_o</span>: 新数据在旧模型的输出<br />
- <span class="math-inline">\mathbf{\hat{y}}_o</span>：新数据在新模型上的输出（分类器的参数输出包括<span class="math-inline">\hat{\theta_o}</span>, <span class="math-inline">\hat{\theta_n}</span>，这里取的<span class="math-inline">\hat{\theta_o}</span>）</p>
<p><div class="math-display"><br />
 y_o^{\prime (i)} = \dfrac{(y_o^{(i)})^{1/T}}{\sum_j (y_o^{(j)})^{1/T}}, \quad \hat{y}_o^{\prime (i)} = \dfrac{(\hat{y}_o^{(i)})^{1/T}}{\sum_j (\hat{y}_o^{(j)})^{1/T}}.<br />
</div></p>
<p>但是，这种方法的缺点是高度依赖于新旧任务之间的相关性，当任务差异太大时会出现任务混淆的现象(inter-task confusion)，并且一个任务的训练时间会随着学习任务的数量线性增长，同时引入的正则项常常不能有效地约束模型在新任务上的优化过程。</p>
<h2 id="references">References<a class="anchor-link" href="#references" title="Permanent link">&para;</a></h2>
<p>-<a href="https://zhuanlan.zhihu.com/p/301117945">增量学习(Incremental Learning)小综述</a></p>
<h2 id="大模型译-arrow_down">大模型译 :arrow_down:<a class="anchor-link" href="#大模型译-arrow_down" title="Permanent link">&para;</a></h2>
<h2 id="0-摘要">0. 摘要<a class="anchor-link" href="#0-摘要" title="Permanent link">&para;</a></h2>
<p>当构建一个统一的视觉系统或逐步向系统中添加新功能时，通常的假设是所有任务的训练数据始终可用。然而，随着任务数量的增长，存储和重新训练这些数据变得不可行。一个新的问题出现了，即我们向卷积神经网络（CNN）添加新功能，但现有的训练数据无法使用。我们提出了一种“无遗忘学习”方法，该方法仅使用新任务数据来训练网络，同时保留原始功能。我们的方法与常用的特征提取和微调适应技术相比表现良好，并且与我们假设不可用的原始任务数据的多任务学习表现相似。一个更令人惊讶的观察是，无遗忘学习可能能够用类似的旧任务和新任务数据集替换微调，以提高新任务的性能。</p>
<h2 id="1-引言">1. 引言<a class="anchor-link" href="#1-引言" title="Permanent link">&para;</a></h2>
<p>许多实际的视觉应用需要在保持现有性能的同时学习新的视觉功能。例如，一个机器人可能被送到某人家中，具备一组默认的目标识别功能，但需要添加新的特定场所的对象模型。或者在建筑安全方面，一个系统可以识别工人是否穿着安全背心或硬帽，但主管可能希望添加检测不当鞋履的能力。理想情况下，新任务可以在不遭受灾难性遗忘 [1]、[2]（在旧任务上的性能下降）或无法访问旧训练数据的情况下学习。遗留数据可能是未记录的、专有的，或者在训练新任务时使用起来太麻烦。这个问题在精神上类似于转移、多任务和终身学习。</p>
<p>我们的目标是开发一种简单但有效的策略，用于各种图像分类问题中的卷积神经网络（CNN）分类器。在我们的设置中，CNN 有一组共享参数 <span class="math-inline">\theta_s</span>（例如，AlexNet[3] 架构的五个卷积层和两个全连接层），之前学习的任务的特定任务参数 <span class="math-inline">\theta_o</span>（例如，ImageNet[4] 分类和相应权重的输出层），以及为新任务随机初始化的特定任务参数 <span class="math-inline">\theta_n</span>（例如，场景分类器）。将 <span class="math-inline">\theta_o</span> 和 <span class="math-inline">\theta_n</span> 视为在 <span class="math-inline">\theta_s</span> 参数化的特征上运行的分类器是有用的。目前，有三种常见的方法（图 1、2）来学习 <span class="math-inline">\theta_n</span>，同时从之前学习的 <span class="math-inline">\theta_s</span> 中受益：</p>
<p><strong>特征提取</strong>（例如，[5]）：<span class="math-inline">\theta_s</span> 和 <span class="math-inline">\theta_o</span> 保持不变，一个或多个层的输出用作新任务的特征来训练 <span class="math-inline">\theta_n</span>。</p>
<p><strong>微调</strong>（例如，[6]）：<span class="math-inline">\theta_s</span> 和 <span class="math-inline">\theta_n</span> 针对新任务进行优化，而 <span class="math-inline">\theta_o</span> 是固定的。通常使用低学习率以防止 <span class="math-inline">\theta_s</span> 发生大的变化。潜在的是，原始网络可以为每个新任务复制并微调，以创建一组专用网络。</p>
<p>也可以使用微调的一种变体，其中部分 <span class="math-inline">\theta_s</span> —— 卷积层 —— 被冻结以防止过拟合，只有顶层全连接层被微调。这可以看作是微调和特征提取之间的折衷。在这项工作中，我们将这种方法称为微调 FC，其中 FC 代表全连接。</p>
<p><strong>联合训练</strong>（例如，[7]）：所有参数 <span class="math-inline">\theta_s</span>、<span class="math-inline">\theta_o</span>、<span class="math-inline">\theta_n</span> 共同优化，例如通过交错每个任务的样本。这种方法的性能可以看作是我们提出的方法可以实现的上限。</p>
<p>这些策略都有一个主要缺点。特征提取通常在新任务上表现不佳，因为共享参数未能表示对新任务有辨识信息的一些信息。微调因为共享参数的变化而没有原始任务特定的预测参数的新指导而降低了之前学习任务的性能。为每个任务复制和微调导致测试时间随着新任务的增加而线性增加，而不是共享共享参数的计算。微调 FC，正如我们在实验中所示，仍然降低了新任务的性能。联合训练随着学习的任务越来越多，在训练中变得越来越繁琐，如果之前学习的任务的训练数据不可用，则不可能进行。</p>
<p>除了这些常用的方法外，还有 [8]、[9] 提出的方法可以不断地添加新的预测任务，通过适应共享参数而无需访问之前学习的任务的训练数据。（见第 2 节）</p>
<p>在这篇论文中，我们扩展了我们之前的工作 [10]，无遗忘学习（LwF）。仅使用新任务的示例，我们优化了新任务的高准确性和对原始网络的现有任务响应的保留。我们的方法与联合训练相似，除了我们的方法不需要旧任务的图像和标签。显然，如果网络被保留，使得 <span class="math-inline">\theta_o</span> 在所有相关图像上产生完全相同的输出，旧任务的准确性将是最好的。</p>
<h2 id="2-相关工作">2. 相关工作<a class="anchor-link" href="#2-相关工作" title="Permanent link">&para;</a></h2>
<p>多任务学习、转移学习和相关方法有着悠久的历史。简而言之，我们的无遗忘学习方法可以被视为蒸馏网络 [11] 和微调 [6] 的结合。微调以在相关数据丰富的问题上训练的现有网络的参数开始，并通过为新任务优化参数来寻找新的局部最小值，使用低学习率。蒸馏网络的思想是学习一个更简单的网络参数，以在原始训练集或大量未标记的数据集上产生与更复杂的网络集合相同的输出。我们的方法不同之处在于，我们解决的是使用相同的数据来监督新任务的学习，并为旧任务提供无监督的输出指导，以找到在新旧任务上都表现良好的参数集。</p>
<h3 id="21-比较方法">2.1 比较方法<a class="anchor-link" href="#21-比较方法" title="Permanent link">&para;</a></h3>
<p>特征提取 [5]、[12] 使用预训练的深度 CNN 来计算图像的特征。提取的特征是给定图像的一个层（通常是最后一个隐藏层）或多个层的激活。在这些特征上训练的分类器可以实现竞争结果，有时超过人工设计的特征 [5]。进一步的研究表明 [13] 如何选择超参数，例如原始网络结构，以获得更好的性能。特征提取不修改原始网络，允许新任务从之前任务中学习到的复杂特征中受益。然而，这些特征不是为新任务专门化的，通常可以通过微调来改进。</p>
<p>微调 [6] 修改现有 CNN 的参数以训练新任务。输出层通过为新任务随机初始化的权重进行扩展，并且使用小的学习率来调整所有参数从它们的原始值以最小化新任务的损失。有时，网络的一部分被冻结（例如卷积层）以防止过拟合。使用适当的训练超参数，得到的模型通常优于特征提取 [6]、[13] 或从随机初始化的网络 [14]、[15] 开始学习。微调适应共享参数 <span class="math-inline">\theta_s</span> 以使它们对新任务更具辨识性，低学习率是保留原始任务中学到的一些表示结构的间接机制。我们的方法提供了一种更直接的方式来保留对原始任务重要的表示，与微调相比，在大多数实验中提高了原始和新任务的性能。</p>
<p>多任务学习（例如，[7]）旨在通过结合所有任务的共同知识，同时改进所有任务。每个任务为共享或受限的参数提供额外的训练数据，作为其他任务的正则化形式 [16]。对于神经网络，Caruana[7] 对多任务学习进行了详细研究。通常，网络的底层是共享的，而顶层是特定于任务的。多任务学习要求所有任务的数据都要存在，而我们的方法只需要新任务的数据。在每个网络层添加新节点是保留原始网络参数的同时学习新判别特征的一种方式。例如，Terekhov 等人 [17] 提出了完全连接神经网络的深度块模块化神经网络，Rusu 等人 [18] 提出了用于强化学习的渐进神经网络。原始网络的参数不受影响，新添加的节点与它们下面的层完全连接。这些方法的缺点是显著扩展了网络中的参数数量，并且如果用于学习新参数的训练数据不足，它们可能会表现不佳 [17]，因为它们需要从头开始训练大量的参数。我们尝试扩展原始网络的全连接层，但发现扩展并没有改善我们原始方法的效果。</p>
<h3 id="22-主题相关方法">2.2 主题相关方法<a class="anchor-link" href="#22-主题相关方法" title="Permanent link">&para;</a></h3>
<p>我们的工作还与在网络之间转移知识的方法有关。Hinton 等人 [11] 提出了知识蒸馏，将知识从大型网络或网络集合转移到小型网络，以实现高效的部署。小型网络使用修改后的交叉熵损失（在第 3 节中进一步描述），鼓励原始网络和新网络的响应相似。Romero 等人 [19] 在这项工作的基础上，通过在中间层提供额外的指导，将其转移到更深的网络。Chen 等人 [20] 提出了 Net2Net 方法，可以立即生成一个更深、更宽的网络，该网络在功能上等同于现有的一个。这种技术可以快速初始化网络，以进行更快的超参数探索。这些方法旨在产生一个结构不同的网络，以近似原始网络，而我们的目标是找到新参数，以使原始网络结构（<span class="math-inline">\theta_s</span>, <span class="math-inline">\theta_o</span>）在调整共享参数 <span class="math-inline">\theta_s</span> 以适应新任务的同时，近似原始输出。</p>
<h2 id="3-无遗忘学习">3. 无遗忘学习<a class="anchor-link" href="#3-无遗忘学习" title="Permanent link">&para;</a></h2>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241204155101.png" style="zoom: 80%;" /></div>

<p>给定一个具有共享参数 <span class="math-inline">\theta_s</span> 和特定任务参数 <span class="math-inline">\theta_o</span> 的 CNN（如图 2(a) 所示），我们的目标是添加针对新任务的特定任务参数 <span class="math-inline">\theta_n</span>，并学习在新旧任务上都表现良好的参数，仅使用新任务的图像和标签（即，不使用现有任务的数据）。我们的算法在图 3 中概述，网络结构在图 2(e) 中说明。首先，我们记录了原始网络对每个新任务图像在旧任务输出上的响应 <span class="math-inline">y_o</span>。在我们的实验中涉及分类，因此响应是每个训练图像的标签概率集合。在输出层添加了每个新类的节点，与下面的层完全连接，随机初始化权重 <span class="math-inline">\theta_n</span>。新参数的数量等于新类别数量乘以最后共享层中的节点数，通常是总参数数量的非常小的一部分。在我们的实验（第 4.2 节）中，我们还比较了修改网络以适应新任务的替代方法。接下来，我们训练网络以最小化所有任务的损失和正则化 <span class="math-inline">R</span>，使用随机梯度下降。正则化 <span class="math-inline">R</span> 对应于简单的权重衰减 0.0005。在训练时，我们首先冻结 <span class="math-inline">\theta_s</span> 和 <span class="math-inline">\theta_o</span> 并训练 <span class="math-inline">\theta_n</span> 至收敛（预热步骤）。然后，我们共同训练所有权重 <span class="math-inline">\theta_s</span>、<span class="math-inline">\theta_o</span> 和 <span class="math-inline">\theta_n</span> 直至收敛（联合优化步骤）。预热步骤极大地增强了微调的旧任务性能，但对我们的方法或比较的 Less Forgetting Learning（见表 2(b)）并不是至关重要的。我们仍然在无遗忘学习（以及大多数比较的方法）中采用这种技术，因为它有轻微的增强作用，并且可以进行公平比较。为了简单起见，我们表示单个示例的损失函数、输出和真实标签。总损失在训练中的批次的所有图像上平均。对于新任务，损失鼓励预测 <span class="math-inline">\hat{y}<em>n</span> 与真实标签 <span class="math-inline">y_n</span> 一致。我们实验中的任务是多类分类，因此我们使用常见的 [3]、[27] 多项式逻辑损失：<br />
<div class="math-display"><br />
    L</em>{\text{new}}(y_n, \hat{y}<em>n) = -y_n \cdot \log \hat{y}_n<br />
</div><br />
其中 <span class="math-inline">\hat{y}_n</span> 是网络的 softmax 输出，<span class="math-inline">y_n</span> 是独热真实标签向量。如果有多个新任务，或者任务是多标签分类，我们对新任务和标签的损失求和。对于每个原始任务，我们希望每个图像的输出概率接近原始网络记录的输出。我们使用知识蒸馏损失，Hinton 等人 [11] 发现这种损失对于鼓励一个网络的输出近似另一个网络的输出效果很好。这是一种修改后的交叉熵损失，增加了对较小概率的权重：<br />
<div class="math-display"><br />
    L</em>{\text{old}}(y_o, \hat{y}_o) = -H(y'_o, \hat{y}'_o)<br />
</div></p>
<p><div class="math-display"><br />
    = -\sum_{i=1}^{l} y'(i)_o \log \hat{y}'(i)_o<br />
</div><br />
其中 <span class="math-inline">l</span> 是标签的数量，<span class="math-inline">y'(i)_o</span>、<span class="math-inline">\hat{y}'(i)_o</span> 是记录和当前概率 <span class="math-inline">y(i)_o</span>、<span class="math-inline">\hat{y}(i)_o</span> 的修改版本：<br />
<div class="math-display"><br />
    y'(i)_o = \frac{(y(i)_o)^{1/T}}{\sum_j (y(j)_o)^{1/T}}, \quad \hat{y}'(i)_o = \frac{(\hat{y}(i)_o)^{1/T}}{\sum_j (\hat{y}(j)_o)^{1/T}}<br />
</div><br />
如果存在多个旧任务，或者旧任务是多标签分类，我们对每个旧任务和标签的损失求和。Hinton 等人 [11] 建议设置 <span class="math-inline">T &gt; 1</span>，这增加了对较小对数值的权重，并鼓励网络更好地编码类别之间的相似性。我们根据保留集上的网格搜索使用 <span class="math-inline">T = 2</span>，这与作者的建议一致。在实验中，使用知识蒸馏损失导致的表现略优于其他合理的损失，因此，将原始任务的输出约束为与原始网络相似是重要的，但相似性度量并不是至关重要的。</p>
<p><span class="math-inline">\lambda_o</span> 是损失平衡权重，在我们的大多数实验中设置为 1。使 <span class="math-inline">\lambda</span> 更大将有利于旧任务的性能而不是新任务，因此我们可以通过改变 <span class="math-inline">\lambda_o</span> 获得旧任务 - 新任务性能线（见图 7）。</p>
<p>与联合训练的关系。如前所述，联合训练和我们方法之间的主要区别是需要旧数据集。联合训练使用旧任务的图像和标签进行训练，而无遗忘学习不再使用它们，而是使用新任务图像 <span class="math-inline">X_n</span> 和记录的响应 <span class="math-inline">Y_o</span> 作为替代品。这消除了对旧数据集的需求，带来了联合优化共享 <span class="math-inline">\theta_s</span> 的好处，并且节省了计算量，因为图像 <span class="math-inline">X_n</span> 只需要通过共享层一次就可以同时处理新任务和旧任务。然而，这些任务的图像分布可能非常不同，这种替代可能会潜在地降低性能。因此，联合训练的性能可以被视为我们方法的上限。</p>
<p>效率比较。使用神经网络最计算密集的部分是评估或反向传播共享参数 <span class="math-inline">\theta_s</span>，特别是卷积层。对于训练，特征提取是最快的，因为只调整新任务参数。LwF 比微调稍慢，因为它需要对旧任务的 <span class="math-inline">\theta_o</span> 进行反向传播，但只需要评估和反向传播 <span class="math-inline">\theta_s</span> 一次。联合训练是最慢的，因为不同任务使用不同的图像，每个任务都需要单独通过共享参数反向传播。</p>
<p>所有方法评估测试图像的时间大致相同。然而，复制网络并为每个任务微调需要 <span class="math-inline">m</span> 倍的时间，其中 <span class="math-inline">m</span> 是任务的总数。</p>
<h2 id="4-实验">4. 实验<a class="anchor-link" href="#4-实验" title="Permanent link">&para;</a></h2>
<p>我们的实验旨在评估无遗忘学习（LwF）是否是一种有效的方法，可以在学习新任务的同时保持旧任务的性能。我们将常见的特征提取、微调和微调 FC 方法以及 Less Forgetting Learning（LFL）[9] 进行比较，这些方法利用现有网络进行新任务学习，而不需要原始任务的训练数据。特征提取保持原始任务的确切性能。我们还与联合训练（有时称为多任务学习）作为可能的旧任务性能的上限进行比较，因为联合训练使用原始和新任务的图像和标签，而 LwF 仅使用新任务的图像和标签。我们在不同程度上对原始任务和新任务相似性的各种图像分类问题上进行实验。对于原始（旧）任务，我们考虑了 ImageNet[4] 的 ILSVRC 2012 子集和 Places365 标准 [30] 数据集。注意，我们之前的工作使用了 Places2，ILSVRC 2015[4] 的一个小型挑战赛和 Places365 的一个早期版本，但在我们发表后该数据集被弃用了。ImageNet 有 1,000 个对象类别和超过 1,000,000 个训练图像。Places365 有 365 个场景类别和约 1,600,000 个训练图像。我们也使用这些大型数据集，因为我们假设我们从一个训练有素的网络开始，这意味着是一个大规模的数据集。对于新任务，我们考虑了 PASCAL VOC 2012 图像分类 [31]（“VOC”）、Caltech-UCSD Birds-200-2011 细粒度分类 [32]（“CUB”）和 MIT 室内场景分类 [33]（“场景”）。这些数据集有适量的图像用于训练：VOC 5,717 个；CUB 5,994 个；场景 5,360 个。其中，VOC 与 ImageNet 非常相似，因为它的标签子类别可以在 ImageNet 类别中找到。MIT 室内场景数据集与 Places365 相似。CUB 与两者都不同，因为它只包括鸟类，需要捕捉图像的细微细节才能进行有效的预测。在一个实验中，我们使用 MNIST[34] 作为新任务，预计我们的方法将表现不佳，因为手写字符与 ImageNet 类别完全不相关。我们主要使用 AlexNet[3] 网络结构，因为它训练速度快且社区研究充分 [6]、[13]、[15]。我们还验证了在较小的实验集上使用 16 层 VGGnet[27] 的结果是否相似。对于这两种网络结构，最终层（fc8）被视为特定任务的，其余的是共享的（<span class="math-inline">\theta_s</span>）除非另有说明。预训练在 ImageNet 和 Places365 标准的原始网络是从公共在线资源获得的。我们报告 VOC 的中心图像裁剪平均精度，以及其他所有任务的中心图像裁剪精度。我们报告 VOC、ImageNet 和 Places365 的验证集精度，以及 CUB 和场景数据集的测试集精度。由于前三个的测试性能不能频繁评估，我们只在实验中提供它们的测试集性能。由于 CNN 训练的随机性，我们进行三次实验，并报告平均性能。我们的实验调查了将单个新任务添加到网络或逐步添加多个任务。我们还检查了数据集大小和网络设计的影响。在消融研究中，我们检查了替代响应保留损失、扩展网络结构的效用，以及使用较低学习率进行微调以保留原始任务性能。注意，结果有多个方差的来源，包括随机初始化和训练、预定终止（性能可能因训练 1 或 2 个额外周期而波动）等。</p>
<h3 id="41-主要实验">4.1 主要实验<a class="anchor-link" href="#41-主要实验" title="Permanent link">&para;</a></h3>
<p>单个新任务场景。首先，我们比较了在不同任务对和不同方法中学习一个新任务的结果。表 1(a)、1(b) 显示了我们的方法的性能，以及使用 AlexNet 的其他方法的相对性能。我们还在图 7 中可视化了两个任务对的旧任务和新任务性能比较。我们观察到以下情况：</p>
<p>在新任务上，我们的方法在大多数情况下超过了微调、LFL、微调 FC 和特征提取，除了 ImageNet→MNIST 和 Places365→CUB 使用微调。超过微调的增益是出乎意料的，表明在旧任务上保留输出是有效的正则化器。（见第 5 节的简要讨论）。这一发现激发了用 LwF 替换微调作为适应网络到新任务的标准方法。在旧任务上，我们的方法比微调表现更好，但通常不如特征提取、微调 FC，有时不如 LFL。通过改变共享参数 <span class="math-inline">\theta_s</span>，微调显著降低了原始网络训练任务的性能。通过共同适应 <span class="math-inline">\theta_s</span> 和 <span class="math-inline">\theta_o</span> 以在旧任务上生成与原始网络相似的输出，性能损失大大减少。考虑到两个任务，图 7 显示，如果调整 <span class="math-inline">\lambda_o</span>，LwF 可以在新任务上比 LFL 和微调 FC 表现得更好，同时在第一个任务对上保持相同的旧任务性能，并且在第二个任务对上与 LFL 表现相似。实际上，微调 FC 在微调和特征提取之间提供了性能。LwF 提供了改变共享表示的自由度，与 LFL 相比，这可能提高了新任务的性能。我们的方法在新任务上与联合训练表现相似，但在添加更多任务后在旧任务上表现较差。</p>
<p>在不同数据集大小的影响下，我们检查了新任务数据集的大小是否影响我们与其他方法的性能比较。我们在将 CUB 添加到 ImageNet 时对 AlexNet 进行实验，并报告整个验证集的结果。注意，对于联合训练，由于每个数据集的大小不同，因此在训练两者时对相同数量的图像进行采样（每个时期重新采样），这意味着一次使用较少的 ImageNet 图像。我们的结果显示在图 5 中。结果表明，相同的观察结果成立。我们的方法在两个任务上都超过了微调。随着使用更多的数据，方法之间的差异趋于增加，尽管相关性并不确定。</p>
<h3 id="42-设计选择和替代方案">4.2 设计选择和替代方案<a class="anchor-link" href="#42-设计选择和替代方案" title="Permanent link">&para;</a></h3>
<p>特定任务层的选择。可以将更多层视为特定任务 <span class="math-inline">\theta_o</span>、<span class="math-inline">\theta_n</span>（见图 6(a)），而不仅仅是输出节点。这可能对两个任务都有好处，因为后面的层往往更特定于任务 [13]。然而，这样做需要更多的存储，因为 AlexNet 中的大多数参数都在前两个全连接层中。表 2(a) 显示了三个任务对的比较。我们的结果并没有表明有更多的特定任务层有任何优势。</p>
<p>网络扩展。我们探索了另一种修改网络结构的方法，我们称之为“网络扩展”，它在某些层添加节点。这允许在早期层中额外的新任务特定信息，同时仍然使用原始网络的信息。图 6(b) 说明了这种方法。我们在顶部 3 层的每个层添加了 1024 个节点。从前一层的所有节点到当前层的新节点的权重初始化方式与 Net2Net[20] 扩展层的方式相同。从新节点的前一层到当前层的原始节点的权重初始化为零。新节点的顶层权重随机重新初始化。然后我们要么冻结现有权重并在新任务上微调新权重（“网络扩展”），要么像以前一样使用无遗忘学习进行训练（“网络扩展 + LwF”）。注意，这两种方法都需要网络规模与新任务的数量成二次方增长。表 2(a) 显示了与我们原始方法的比较。单独的网络扩展表现优于特征提取，但在新任务上不如 LwF。网络扩展 + LwF 表现与 LwF 相似，但计算成本和复杂性增加。</p>
<p>降低共享参数学习率的影响。我们调查了是否简单地降低共享参数 <span class="math-inline">\theta_s</span> 的学习率可以保留原始任务性能。结果如表 2(a) 所示。降低学习率并不能阻止微调显著降低原始任务性能，并且它降低了新任务性能。这表明简单地降低共享层的学习率对于保留原始任务是不够的。</p>
<p>L2 软约束权重。也许 LwF 的一个明显替代方案是保持网络参数（而不是响应）接近原始值。我们将其与微调的基线进行比较，在微调损失中添加了 <span class="math-inline">\frac{1}{2}\lambda_o |w - w_0|^2</span>，其中 <span class="math-inline">w</span> 和 <span class="math-inline">w_0</span> 是所有共享参数 <span class="math-inline">\theta_s</span> 及其原始值的扁平化向量。我们改变了系数 <span class="math-inline">\lambda_o</span> 并观察了其对性能的影响。对于 Places365→VOC，<span class="math-inline">\lambda_o</span> 设置为 0.15、0.5、1.5、2.5，对于 ImageNet→Scene，<span class="math-inline">\lambda_o</span> 设置为 0.005、0.015、0.05、0.15、0.25。如图 7 所示，我们的方法超过了这个基线，它在特征提取（无参数变化）和微调（自由参数变化）之间产生了结果。我们认为，通过正则化输出，我们的方法比正则化单个参数更好地保持了旧任务性能，因为许多小的参数变化可能导致输出的大变化。</p>
<p>响应保留损失的选择。我们比较了使用 L1、L2、交叉熵损失和知识蒸馏损失（T = 2）以保持 <span class="math-inline">y'_o</span>、<span class="math-inline">\hat{y}'_o</span> 相似的结果。我们在相同的任务对上进行了测试。图 7 显示了我们的结果。结果表明我们的知识蒸馏损失略优于比较损失，尽管优势不大。</p>
<h2 id="5-讨论">5. 讨论<a class="anchor-link" href="#5-讨论" title="Permanent link">&para;</a></h2>
<p>我们解决了在不访问原始任务训练数据的情况下，适应新任务的同时保持原始任务性能的问题。我们为卷积神经网络提出了无遗忘学习方法，它可以被视为知识蒸馏和微调的混合体，学习对新任务有辨识性的参数，同时在训练数据上保留原始任务的输出。我们在多个分类任务上展示了我们方法的有效性。</p>
<p>作为另一个用例示例，我们在附录 A 中研究了 LwF 在跟踪中的应用。我们基于 MD-Net[35]，它将跟踪视为模板分类任务。从训练视频转移的分类器被在线微调，以将区域分类为对象或背景。我们提出用无遗忘学习替换微调步骤。我们留下了细节和实现给附录。我们观察到应用 LwF 有一些改进，但差异并不具有统计学意义。我们的工作有两个用途。首先，如果我们想要扩展现有网络可能的预测集，我们的方法与联合训练表现相似，但训练速度更快，不需要访问之前任务的训练数据。其次，如果我们只关心新任务的性能，我们的方法通常优于当前标准的微调。微调方法使用低学习率，希望参数能够在一个“好”的局部最小值附近，不要太远离原始值。在旧任务上保留输出是一种更直接和可解释的方式来保留之前任务中学到的重要共享结构。我们看到了未来工作的几个方向。我们已经证明了 LwF 在图像分类和一个跟踪实验中的有效性，但希望进一步在语义分割、检测以及计算机视觉之外的问题上进行实验。此外，可以探索该方法的变体，例如维护一组未标记的图像作为之前学习任务的代表性示例。从理论上讲，基于从不同分布中抽取的样本保留输出来限制旧任务性能是有趣的。更一般地，需要适合在线学习不同任务的方法，特别是当类别具有重尾分布时。</p>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
