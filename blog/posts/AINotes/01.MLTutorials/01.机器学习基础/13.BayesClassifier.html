<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>贝叶斯分类器</title>
    <meta name="description" content="贝叶斯分类器 - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme */
            --primary-color: #2980b9;
            --primary-hover: #1a5276;
            --link-color: #c0392b;
            --text-color: #333;
            --text-light: #666;
            --text-muted: #999;
            --bg-color: #fff;
            --bg-secondary: #f8f9fa;
            --bg-code: #f5f5f5;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px rgba(0,0,0,0.1);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#贝叶斯决策论">贝叶斯决策论</a></li>
<li><a href="#极大似然估计">极大似然估计</a></li>
<li><a href="#朴素贝叶斯分类器">朴素贝叶斯分类器</a><ul>
<li><a href="#平滑">平滑</a></li>
<li><a href="#实际使用">实际使用</a></li>
</ul>
</li>
<li><a href="#半朴素贝叶斯分类器">半朴素贝叶斯分类器</a><ul>
<li><a href="#spode">SPODE</a></li>
<li><a href="#tan">TAN</a></li>
<li><a href="#aode">AODE</a></li>
<li><a href="#高阶依赖">高阶依赖</a></li>
</ul>
</li>
<li><a href="#贝叶斯网">贝叶斯网</a></li>
<li><a href="#em算法">EM算法</a></li>
<li><a href="#补充内容">补充内容</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>贝叶斯分类器</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-01-28</span>
                        <span><i class="fas fa-folder"></i> AINotes/01.MLTutorials/01.机器学习基础</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h1 id="贝叶斯分类器">贝叶斯分类器<a class="anchor-link" href="#贝叶斯分类器" title="Permanent link">&para;</a></h1>
<p><strong>贝叶斯分类器</strong>（Bayes Classifier）是一种通过最大化后验概率进行单点估计的分类器。</p>
<p>这一章的内容大致如下：</p>
<ul>
<li>
<p><strong>贝叶斯决策论</strong>：如何计算某个样本误分类的期望损失/条件风险？贝叶斯判定准则是怎样的？什么是判别式模型？什么是生成式模型？贝叶斯定理中各个概率代表什么？估计后验概率有什么难处？</p>
</li>
<li>
<p><strong>极大似然估计</strong>：如何估计类条件概率？频率学派和贝叶斯学派对参数估计有什么不同的见解？极大似然估计的思想是什么？如何处理概率连成造成的下溢？试想一下连续属性和离散属性的极大似然估计。这种估计方法有什么缺点？</p>
</li>
<li>
<p><strong>朴素贝叶斯分类器</strong>：朴素贝叶斯分类器是基于什么假设的？表达式怎么写？为什么估计概率值时需要进行平滑？拉普拉斯修正是怎样的？现实任务中中如何使用朴素贝叶斯分类器？</p>
</li>
<li>
<p><strong>半朴素贝叶斯分类器</strong>：半朴素贝叶斯分类器是基于什么假设的？什么是独依赖估计？独依赖分类器有哪些学习方法？AODE有什么优点？是否可以通过考虑属性之间的高阶依赖来进一步提升模型的泛化性能？</p>
</li>
<li>
<p><strong>贝叶斯网络</strong>：什么是贝叶斯网络？它的结构是怎样的？如何进行模型的学习？如何对新样本进行推断？</p>
</li>
<li>
<p><strong>EM算法</strong>：什么是隐变量？EM算法的步骤是怎样的？和梯度下降有什么不同？</p>
</li>
</ul>
<h2 id="贝叶斯决策论">贝叶斯决策论<a class="anchor-link" href="#贝叶斯决策论" title="Permanent link">&para;</a></h2>
<p><strong>贝叶斯决策论</strong>（Bayesian decision theory）是概率框架下实施决策的基本方法。具体来说，在分类任务中，贝叶斯决策论基于概率和误判损失选择出最优的类别标记。</p>
<p>以多分类任务为例，假设有 <span class="math-inline">N</span> 种标记，即 <span class="math-inline">\mathcal{Y} = {c_1, c_2,..., c_N}</span>，用 <span class="math-inline">\lambda_{ij}</span> 表示把一个真实标记为 <span class="math-inline">c_i</span> 的样本误分类为 <span class="math-inline">c_j</span> 所产生的损失。那么将样本 <span class="math-inline">\mathbf{x}</span> 分类为 <span class="math-inline">c_i</span> 的<strong>期望损失（expected loss）</strong>或者说，在样本 <span class="math-inline">\mathbf{x}</span> s上的<strong>条件风险（conditional risk）</strong>：</p>
<p><div class="math-display"> R(c_i | \mathbf{x}) = \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})</div></p>
<p>它描述的是，给定一个样本 <span class="math-inline">\mathbf{x}</span>，把它分类为 <span class="math-inline">c_i</span> 需要冒多大的风险。或者说，当样本真实标记不是 <span class="math-inline">c_i</span> 时，会有多大的损失。这个损失是一个求和，每一个求和项都是某一类别的后验概率和对应误分类损失的积。（<strong>注</strong>：书中这个地方不够细致，求和项的下标是要排除 <span class="math-inline">i</span> 本身的）</p>
<p>在单个样本条件风险的基础上，可以定义<strong>总体风险</strong>：</p>
<p><div class="math-display"> R(h) = \mathbb{E}_{\mathbf{x}}[R(h(\mathbf{x})\ |\ \mathbf{x})]</div></p>
<p>它描述的是，<strong>所有样本的条件风险的数学期望</strong>。其中 <span class="math-inline">h</span> 是一种用于产生分类结果的判断准则。</p>
<p>那么我们的目标就是找出能最小化总体风险 <span class="math-inline">R(h)</span> 的判断准则。怎样的判断准则能满足这个要求呢？很直观地，如果一个判断准则 <span class="math-inline">h</span> 能最小化所有样本 <span class="math-inline">\mathbf{x}</span> 的条件风险，那它对应的总体风险必然也是最小的。由此，可以得到<strong>贝叶斯判定准则（Bayes decision rule）</strong>：要最小化总体风险，只需<strong>在每个样本上选择能使对应的条件风险 <span class="math-inline">R(c\ |\ \mathbf{x})</span> 最小的标记</strong>。即：</p>
<p><div class="math-display">h^*(\mathbf{x}) = \arg \min_{c \in \mathcal{Y}} R(c\ |\ \mathbf{x})</div></p>
<p>这个判断准则 <span class="math-inline">h^<em></span> 称为</em><em>贝叶斯最优分类器（Bayes optimal classifier）</em><em>，对应的总体风险 <span class="math-inline">R(h^</em>)</span> 称为<strong>贝叶斯风险（Bayes risk）</strong>，而  <span class="math-inline">1-R(h^<em>)</span> 则反映了分类器所能达到的最好性能，也即</em><em>模型精度的理论上限</em>*。</p>
<p>进一步地，如果我们学习模型的目标是<strong>令分类错误率最小</strong>，那么分类正确时误分类损失 <span class="math-inline">\lambda_{ij}</span> 为0，反之为1。这是条件风险就是：</p>
<p><div class="math-display">R(c\ |\ \mathbf{x}) = 1-P(c\ |\ \mathbf{x})</div></p>
<p>要令风险最小，我们只需要选择使样本 <span class="math-inline">\mathbf{x}</span> 后验概率最大的一个类别标记就可以了。</p>
<p>问题在于，<strong>怎样获取后验概率呢？</strong></p>
<p>事实上，从概率的角度来理解，机器学习的目标就是<strong>基于有限的训练样本集尽可能准确地估计出后验概率</strong>（当然，大多数机器学习技术无需准确估计出后验概率）。要实现这个目标，主要有两种策略：</p>
<ul>
<li>
<p>构建<strong>判别式模型（discriminative models）</strong>：给定样本 <span class="math-inline">\mathbf{x}</span>，直接对后验概率 <span class="math-inline">P(\mathbf{x}\ |\ c)</span> 建模来预测 <span class="math-inline">c</span>。这类模型包括决策树、BP神经网络、支持向量机等等。</p>
</li>
<li>
<p>构建<strong>生成式模型（generative models）</strong> ：给定样本 <span class="math-inline">\mathbf{x}</span>，先对联合概率分布 <span class="math-inline">P(\mathbf{x},c)</span> 建模，然后再利用联合概率计算出后验概率 <span class="math-inline">P(c\ |\ \mathbf{x})</span>，也即 <span class="math-inline">P(c\ |\ \mathbf{x}) = \frac{P(\mathbf{x},c)}{P(\mathbf{x})}</span>。</p>
</li>
</ul>
<p>又因为联合概率 <span class="math-inline">P(\mathbf{x},c) = P(c\ |\ \mathbf{x}) \times P(\mathbf{x}) = P(\mathbf{x}\ |\ c) \times P(c)</span>，由此，能得到<strong>贝叶斯定理</strong>：</p>
<p><div class="math-display">P(c\ |\ \mathbf{x}) = \frac{P(\mathbf{x}\ |\ c) \times P(c)}{P(\mathbf{x})}</div></p>
<p>在贝叶斯定理中，每个概率都有约定俗成的名称：</p>
<ul>
<li>
<p><span class="math-inline">P(c\ |\ \mathbf{x})</span> 是类标记 <span class="math-inline">c</span> 相对于样本 <span class="math-inline">\mathbf{x}</span> 的条件概率，也由于得自 <span class="math-inline">\mathbf{x}</span> 的取值而被称作 <span class="math-inline">c</span> 的后验概率。</p>
</li>
<li>
<p><span class="math-inline">P(\mathbf{x}\ |\ c)</span> 是样本 <span class="math-inline">\mathbf{x}</span> 相对于类标记 <span class="math-inline">c</span> 的<strong>类条件概率（class-conditional probability）</strong>，或称为<strong>似然（likelihood）</strong>，也由于得自 <span class="math-inline">c</span> 的取值而被称作 <span class="math-inline">\mathbf{x}</span> 的后验概率。</p>
</li>
<li>
<p><span class="math-inline">P(c)</span> 是 <span class="math-inline">c</span> 的先验概率（也称为边缘概率），之所以称为"先验"是因为它不考虑任何 <span class="math-inline">\mathbf{x}</span> 方面的因素。在这里又称为<strong>类先验（prior）概率</strong>。</p>
</li>
<li>
<p><span class="math-inline">P(\mathbf{x})</span> 是 <span class="math-inline">\mathbf{x}</span> 的先验概率。在这里是用作归一化的<strong>证据（evidence）因子</strong>，与类标记无关。</p>
</li>
</ul>
<p>有了贝叶斯定理，如何估计后验概率 <span class="math-inline">P(c\ |\ \mathbf{x})</span> 的问题就转化为<strong>如何计算类先验概率 <span class="math-inline">P(c)</span> 和类条件概率 <span class="math-inline">P(\mathbf{x}\ |\ c)</span> </strong>了。</p>
<p>类先验概率 <span class="math-inline">P(c)</span> 表示的是<strong>样本空间中各类样本的比例</strong>，根据大数定律，<strong>当训练集包含足够多的独立同分布样本</strong>时，类先验概率可以直接通过<strong>训练集中各类样本出现的频率</strong>进行估计。</p>
<p>类条件概率 <span class="math-inline">P(\mathbf{x}\ |\ c)</span> 的情况就复杂多了，它涉及到类 <span class="math-inline">c</span> 中<strong>样本 <span class="math-inline">\mathbf{x}</span> 所有属性的联合概率</strong>，假设每个样本有 <span class="math-inline">d</span> 个二值属性，那么可能的取值组合就多达 <span class="math-inline">2^d</span> 个，这个数目可能<strong>远多于训练集的规模</strong>，也就意味着很多样本的取值没有在训练集中出现，所以<strong>直接用训练集出现的频率进行估计是不可行的</strong>。必须注意<strong>未被观测到</strong>和<strong>出现概率为0</strong>的区别。</p>
<p><strong>注意</strong>，上述讨论中，均假设属性是离散型，对于连续型属性，只需把概率质量函数 <span class="math-inline">P(\cdot)</span> 换为概率密度函数 <span class="math-inline">p(\cdot)</span> 就可以了。</p>
<h2 id="极大似然估计">极大似然估计<a class="anchor-link" href="#极大似然估计" title="Permanent link">&para;</a></h2>
<p>估计类条件概率的一种常用策略是：先<strong>假定该类样本服从某种确定的概率分布形式</strong>，然后再<strong>基于训练集中的该类样本对假定的概率分布的参数进行估计</strong>。比方说假定该类样本服从高斯分布，那么接下来就是利用训练集中该类样本来估计高斯分布的参数——均值和方差。</p>
<p>具体来说，如果类 <span class="math-inline">c</span> 的样本服从参数为 <span class="math-inline">\theta_c</span>（可能不止一个参数）的分布，那么我们从样本空间抽取到该类的某一个样本 <span class="math-inline">\mathbf{x}</span> 的概率就是 <span class="math-inline">P(\mathbf{x}\ |\ \theta_c)</span>。使用 <span class="math-inline">D_c</span> 来表示训练集中类 <span class="math-inline">c</span> 的子集，可以定义数据集 <span class="math-inline">D_c</span> 的<strong>似然（likelihood）</strong>为：</p>
<p><div class="math-display">P(D_c\ |\ \theta_c) = \prod_{\mathbf{x} \in D_c} P(\mathbf{x}\ |\ \theta_c)</div></p>
<p>由于<strong>连乘操作容易造成下溢</strong>，实际任务中通常使用<strong>对数似然（log-likelihood）</strong>代替：</p>
<p><div class="math-display">LL(\theta_c) = \log P(D_c\ |\ \theta_c) = \sum_{\mathbf{x} \in D_c} \log P(\mathbf{x}\ |\ \theta_c)</div></p>
<p>所谓<strong>极大似然估计（Maximum Likelihood Estimation，简称MLE）</strong>就是<strong>找出令似然最大的参数 <span class="math-inline">\theta_c</span></strong>。也即从 <span class="math-inline">\theta_c</span> 的所有可能取值中找到一个<strong>令所抽取样本出现的可能性最大</strong>的值。</p>
<p>求解的过程也很简单，就是求似然函数的导数，令导数为0，得到<strong>似然方程</strong>，解似然方程得到最优解，也即该类样本分布的参数。</p>
<p>特别地，对于参数估计，<strong>频率主义学派（Frequentist）</strong>和<strong>贝叶斯学派（Bayesian）</strong>有不同的见解。前者认为，参数虽然未知，却是<strong>客观存在的固定值</strong>，因此可以用优化似然函数等准则确定参数值；后者认为，参数是<strong>未观测到的随机变量</strong>，<strong>参数本身也存在分布</strong>。所以可以先假定参数服从一个先验分布，然后再根据观测到的数据计算参数的后验分布。这一节讨论的极大似然估计方法源于频率主义学派。</p>
<p>尽管极大似然估计能使我们求取类条件概率的过程变得相对简单，但它有最大的一个缺点就是：估计结果的<strong>准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布</strong>。在实际任务中，我们需要利用任务所属领域的一些经验知识，全凭猜测是很容易产生误导性结果的。</p>
<p>P.S. 关于最大似然、最大后验与贝叶斯估计的爱恨纠缠可以看我写的另外一篇文章<a href="https://github.com/familyld/SYSU_Data_Mining/tree/master/Linear_Regression">参数估计：最大似然，最大后验与贝叶斯</a>。</p>
<h2 id="朴素贝叶斯分类器">朴素贝叶斯分类器<a class="anchor-link" href="#朴素贝叶斯分类器" title="Permanent link">&para;</a></h2>
<p>前面提到了，估计后验概率 <span class="math-inline">P(c\ |\ \mathbf{x})</span> 最大的一个难处是：类条件概率 <span class="math-inline">P(\mathbf{x}\ |\ c)</span> 是所有属性上的联合概率，而多个属性的不同属性值组合并不一定全部囊括在训练集内，所以很难通过训练集估计。</p>
<p>为了避免这个障碍，<strong>朴素贝叶斯分类器（naive Bayes clssifier）</strong>采用<strong>属性条件独立性假设（attribute conditional independence assumption）</strong>。也就是说，假设<strong>所有属性相互独立，单独地对分类结果产生影响</strong>。</p>
<p>基于这个假设，可以把类条件概率写成连乘的形式，因此贝叶斯定理可重写为：</p>
<p><div class="math-display">P(c\ |\ \mathbf{x}) = \frac{P(\mathbf{x}\ |\ c) \times P(c)}{P(\mathbf{x})} = \frac{P(c)}{P(\mathbf{x})} \prod_{i=1}^{d} P(x_i\ |\ c) \qquad (1)</div></p>
<p>其中 <span class="math-inline">d</span> 为属性数目， <span class="math-inline">x_i</span> 为样本 <span class="math-inline">\mathbf{x}</span> 在第 <span class="math-inline">i</span> 个属性上的取值。</p>
<p>又因为 <span class="math-inline">P(\mathbf{x})</span> 与类别无关，所以<strong>朴素贝叶斯分类器的表达式</strong>可以写为：</p>
<p><div class="math-display">h(\mathbf{x}) = \arg \max_{c \in \mathcal{Y}} P(c) \prod_{i=1}^{d} P(x_i\ |\ c)</div></p>
<p>前面已经提到过，当训练集包含足够多独立同分布样本时，类先验概率 <span class="math-inline">P(c)</span> 可以直接算出，也即训练集该类样本的数目占训练集规模的比例：</p>
<p><div class="math-display">P(c) = \frac{|D_c|}{|D|} \qquad (2)</div></p>
<p>而条件概率 <span class="math-inline">P(x_i\ |\ c)</span>，根据属性类型分离散和连续两种情况：</p>
<ul>
<li>离散型属性：条件概率 <span class="math-inline">P(x_i\ |\ c)</span> 可以估计为，在类别 <span class="math-inline">c</span> 的样本子集中，第 <span class="math-inline">i</span> 个属性取值为 <span class="math-inline">x_i</span> 的样本所占的比例：</li>
</ul>
<p><div class="math-display">P(x_i\ |\ c) = \frac{|D_{c,x_i}|}{|D_c|} \qquad (3)</div></p>
<ul>
<li>连续性属性：替换为概率密度函数，假设第 <span class="math-inline">i</span> 个属性服从高斯分布，那么条件概率就写成 <span class="math-inline">p(x_i\ |\ c) \sim \mathcal{N}(\mu_{c,i},\sigma_{c,i}^2)</span>。我们利用类别 <span class="math-inline">c</span> 的样本子集在该属性上的取值算出分布的均值和方差，然后把属性取值 <span class="math-inline">x_i</span> 代入概率密度函数就可算出这个条件概率。</li>
</ul>
<h4 id="平滑">平滑<a class="anchor-link" href="#平滑" title="Permanent link">&para;</a></h4>
<p>注意了，若<strong>某个属性值在训练集中没有与某个类同时出现过</strong>，那么它对应的条件概率 <span class="math-inline">P(x_i\ |\ c)</span> 就为0。在连乘中，这就意味着整个式子值为0了，<strong>其他属性携带的信息都被抹去了</strong>。这是很常见的情况，举个例子，假设有一篇新闻应该在体育版发布的，它包含了 “罗纳尔多” 这个词，但由于我们构造分类器时，训练集中所有 “体育” 类的文本都没有出现这个词，于是，该新闻按照式（1）计算出的体育类的条件概率必定为0；而恰好 “娱乐” 类的文本中有一篇包含了这个词，那么计算出的娱乐类的条件概率就大于0，从而使得这篇新闻被误分到娱乐版发布了，这显然很不合理。</p>
<p>此时，我们就需要对概率值进行<strong>平滑（smoothing）</strong>了，最常用的是<strong>拉普拉斯修正（Laplacian correction）</strong>，假设<strong>训练集中</strong>包含 <span class="math-inline">N</span> 个类别，第 <span class="math-inline">i</span> 个属性包含 <span class="math-inline">N_i</span> 种取值，则拉普拉斯修正把式（2）和式（3）修改为：</p>
<p><div class="math-display">P(c) = \frac{|D_c| + 1}{|D| + N} \qquad (4)</div></p>
<p><div class="math-display">P(x_i\ |\ c) = \frac{|D_{c,x_i}| + 1}{|D_c| + N_i} \qquad (5)</div></p>
<p>再回想一下上面新闻分类的例子，尽管所有 “体育” 类的文本都没有出现 “罗纳尔多” 这个词，但使用拉普拉斯修正后，这个词（文本分类中每个词是一个属性）对应的条件概率就不为0了，而是一个很小的值；而该新闻的其他词，比如 “足球”、“球场” 等等在体育类新闻中都出现得很频繁，所以最后累乘计算出的体育类的类条件概率就大于其他类，从而能正确地进行划分了。</p>
<p>拉普拉斯修正保证了<strong>不会因为训练集样本不充分导致概率估值为零</strong>。但它实际上是假设了<strong>类别和属性值是均匀分布的</strong>，相当于额外引入了先验，这个<strong>假设并不总是成立</strong>。不过当训练集规模足够大时，引入先验所产生的影响会变得非常低。也可以理解为，此时式（4）和式（5）的分母很大，使得分子中引入的1带来的变化非常小，此时概率的估计值会趋向于真实值。</p>
<h4 id="实际使用">实际使用<a class="anchor-link" href="#实际使用" title="Permanent link">&para;</a></h4>
<p>朴素贝叶斯分类器和前面学习的模型有一个不同的地方就是，我们并不是基于训练集和某些算法来学习模型的参数；而是利用训练集来算出一些概率，在预测时，根据新样本的情况，使用不同的概率计算出它被分到各个类的后验概率，然后取后验概率最大的一个类作为结果。</p>
<p>在实际任务中，有两种使用方式：</p>
<ul>
<li>
<p><strong>查表</strong>：若对预测速度要求较高，可以先根据训练集把所有涉及到的概率计算出来，然后存储好，在预测新样本时只需要查表然后计算就可以了。</p>
</li>
<li>
<p><strong>懒惰学习</strong>：若数据更替比较频繁，也可以理解为用训练集算出的概率可能很快就失效了，更新换代的速度很快，那就采取<strong>懒惰学习（lazy learning）</strong>的方式，仅当需要预测时才计算涉及到的概率。</p>
</li>
</ul>
<p>特别地，当我们采取了预先计算所有概率的方式时，如果有新数据加入到训练集，我们只需要更新新样本涉及到的概率（或者说计数）就可以了，可以很方便地实现<strong>增量学习</strong>。</p>
<h2 id="半朴素贝叶斯分类器">半朴素贝叶斯分类器<a class="anchor-link" href="#半朴素贝叶斯分类器" title="Permanent link">&para;</a></h2>
<p><img alt="NB" src="https://raw.githubusercontent.com/familyld/Machine_Learning/master/graph/NB.jpg" /></p>
<p>朴素贝叶斯分类器基于属性条件独立性假设，每个属性仅依赖于类别，如上图。但这个假设往往很难成立的，有时候<strong>属性之间会存在依赖关系</strong>，这时我们就需要对属性条件独立性假设适度地进行放松，<strong>适当考虑一部分属性间的相互依赖信息</strong>，这就是<strong>半朴素贝叶斯分类器（semi-naive Bayes classifier）</strong>的基本思想。</p>
<p><strong>独依赖估计（One-Dependent Estimator，简称ODE）</strong>是半朴素贝叶斯分类器最常用的一种策略，它假设的是<strong>每个属性在类别之外最多仅依赖于一个其他属性</strong>。也即：</p>
<p><div class="math-display">P(c\ |\ \mathbf{x}) \propto P(c) \prod_{i=1}^{d} P(x_i\ |\ c,{pa}_i)</div></p>
<p>其中 <span class="math-inline">{pa}_i</span> 是属性 <span class="math-inline">x_i</span> 依赖的另一属性，称为 <span class="math-inline">x_i</span> 的<strong>父属性</strong>。若已知父属性，就可以按式（5）来计算了。现在问题转化为<strong>如何确定每个属性的父属性</strong>？</p>
<p>这里介绍两种产生独依赖分类器的方法：</p>
<h4 id="spode">SPODE<a class="anchor-link" href="#spode" title="Permanent link">&para;</a></h4>
<p><img alt="SPODE" src="https://raw.githubusercontent.com/familyld/Machine_Learning/master/graph/SPODE.jpg" /></p>
<p>在<strong>SPODE（Super-Parent ODE）</strong>中，所有属性都依赖于一个共同的属性，称为<strong>超父（super-parent）</strong>，比方说上图中的 <span class="math-inline">x_1</span>。可以通过交叉验证等模型选择方法来确定最合适的超父属性。</p>
<h4 id="tan">TAN<a class="anchor-link" href="#tan" title="Permanent link">&para;</a></h4>
<p><img alt="TAN" src="https://raw.githubusercontent.com/familyld/Machine_Learning/master/graph/TAN.jpg" /></p>
<p><strong>TAN（Tree augmented naive Bayes）</strong>则是一种基于<strong>最大带权生成树（maximum weighted spanning tree）</strong>的方法，包含以下四个步骤：</p>
<ol>
<li>
<p>计算任意两个属性间的<strong>条件互信息（conditional mutual information）</strong>：<br><br />
<div class="math-display">I(x_i,x_j\ |\ y) = \sum_{x_i,x_j; c\in \mathcal{Y}}  P(x_i,x_j\ |\ c) \log \frac{ P(x_i,x_j\ |\ c)}{ P(x_i\ |\ c) P(x_j\ |\ c)}</div></p>
</li>
<li>
<p>以属性为节点构建完全图，每条边的权重为对应的条件户信息。</p>
</li>
<li>
<p>构建此完全图的最大带权生成树。选一个节点作为根节点，把边转换为有向边。</p>
</li>
<li>
<p>加入类别节点 <span class="math-inline">y</span>，并增加从 <span class="math-inline">y</span> 到每个属性的有向边。</p>
</li>
</ol>
<h4 id="aode">AODE<a class="anchor-link" href="#aode" title="Permanent link">&para;</a></h4>
<p>特别地，有一种更为强大的独依赖分类器——<strong>AODE(Average One-Dependent Estimator)</strong>，它基于集成学习机制。无须通过模型选择来确定超父属性，而是尝试将每个属性都作为超父属性来构建模型，然后把有足够训练数据支撑的SPODE模型集成起来导出最终结果。</p>
<p>类似于朴素贝叶斯分类器，AODE<strong>无需进行模型选择</strong>，既可以<strong>通过预计算来节省预测时间</strong>，又可以<strong>采取懒惰学习</strong>，需要预测时再进行计数，并且可以容易地实现增量学习。</p>
<h4 id="高阶依赖">高阶依赖<a class="anchor-link" href="#高阶依赖" title="Permanent link">&para;</a></h4>
<p>ODE假设每个属性最多依赖类别以外的另一属性，但如果我们继续放宽条件，<strong>允许属性最多依赖类别以外的 k 个其他属性</strong>，也即考虑属性间的<strong>高阶依赖</strong>，那就得到了 kDE。</p>
<p>是不是考虑了高阶依赖就一定能带来性能提升呢？并不是这样的。随着 k 的增加，要准确估计条件概率 <span class="math-inline">P(x_i\ |\ c,\mathbf{pa}_i)</span> <strong>所需的训练样本会呈指数上升</strong>。如果训练样本不够，很容易陷入高阶联合概率的泥沼；但如果训练样本非常充足，那就有可能带来泛化性能的提升。</p>
<h2 id="贝叶斯网">贝叶斯网<a class="anchor-link" href="#贝叶斯网" title="Permanent link">&para;</a></h2>
<p><strong>贝叶斯网（Bayesian network）</strong>亦称<strong>信念网（belief network）</strong>，它借助<strong>有向无环图（Directed Acyclic Graph，简称DAG）</strong>来刻画属性之间的依赖关系，并使用<strong>条件概率表（Conditional Probability Table，简称CPT）</strong>来描述属性的联合概率分布。</p>
<p>贝叶斯网的学习包括结构的学习和参数的学习，而预测新样本的过程则称为<strong>推断（inference）</strong>。这部分内容设计到一些后面章节，相对复杂一些，所以暂且放下，之后有时间再写详细的笔记。</p>
<h2 id="em算法">EM算法<a class="anchor-link" href="#em算法" title="Permanent link">&para;</a></h2>
<p>前面讨论的极大似然估计方法是一种常用的参数估计方法，它是假设分布的形式，然后用训练样本来估计分布的参数。但实际任务中，我们遇到一个很大的问题就是<strong>训练样本不完整</strong>。这时就需要用到<strong>EM（Expectation-Maximization）算法</strong>了。</p>
<p>所谓不完整的样本，说的是这个样本某些属性的值缺失了。将每个属性的取值看为一个变量，那么缺失的就可以看作“未观测”变量，比方说有的西瓜根蒂脱落了，没办法看出根蒂是“蜷缩”还是“硬挺”，那么这个西瓜样本的根蒂属性取值就是一个“未观测”变量，更准确地说，称作<strong>隐变量（latent variable）</strong>。</p>
<p>整个训练集可以划分为已观测变量集 <span class="math-inline">X</span> 和隐变量集 <span class="math-inline">Z</span> 两部分。按照极大似然的思路，我们依然是想找出令训练集被观测到的概率最大的参数 <span class="math-inline">\Theta</span>。也即最大化对数似然：</p>
<p><div class="math-display">LL(\Theta\ |\ X,Z) = \ln P(X,Z\ |\ \Theta)</div></p>
<p>但是，由于 <span class="math-inline">Z</span> 是隐变量，我们没办法观测到，所以上面这个式子实际是没法求的。</p>
<p>怎么办呢？EM算法的思路很简单，步骤如下：</p>
<ol>
<li>设定一个初始的 <span class="math-inline">\Theta</span></li>
<li>按当前的 <span class="math-inline">\Theta</span> 推断隐变量 <span class="math-inline">Z</span> 的（期望）值</li>
<li>基于已观测变量 <span class="math-inline">X</span> 和 步骤2得到的 <span class="math-inline">Z</span> 对 <span class="math-inline">\Theta</span> 做最大似然估计得到新的 <span class="math-inline">\Theta</span></li>
<li>若未收敛（比方说新的 <span class="math-inline">\Theta</span> 与旧的 <span class="math-inline">\Theta</span> 相差仍大于阈值），就回到步骤2，否则停止迭代</li>
</ol>
<p>EM算法可以看作是用<strong>坐标下降（coordinate descent）</strong>法来最大化对数似然下界的过程，每次固定 <span class="math-inline">Z</span> 或者 <span class="math-inline">\Theta</span> 中的一个去优化另一个，直到最后收敛到局部最优解。</p>
<p>理论上，用梯度下降也能求解带隐变量的参数估计问题，但按我的理解，由于隐变量的加入，使得求导这个步骤非常困难，计算也会随着隐变量数目上升而更加复杂，EM算法避免了这些麻烦。</p>
<h2 id="补充内容">补充内容<a class="anchor-link" href="#补充内容" title="Permanent link">&para;</a></h2>
<p>朴素贝叶斯分类器的属性条件独立性假设在现实中很难成立，但事实上它在大多数情形下都有不错的性能。关于这点，有以下两种解释：</p>
<ol>
<li>对分类任务来说，只需各类别的条件概率<strong>排序正确</strong>，即使概率值不准确，也可以产生正确的分类结果；</li>
<li>若属性间的相互依赖对所有类别影响都相同，或者依赖关系互相抵消，则属性条件独立性假设在降低开销的同时不会给性能带来负面影响；</li>
</ol>
<p>注意，本章讨论的<strong>贝叶斯分类器</strong>和一般意义上的<strong>贝叶斯学习（Bayesian learning）</strong>是有很大差别的，本章讨论的贝叶斯分类器只是通过最大化后验概率来进行<strong>单点估计</strong>，获得的仅仅是一个数值；而贝叶斯学习则是进行<strong>分布估计</strong>或者说<strong>区间估计</strong>，获得的是一个分布。</p>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
