<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>定义模型</title>
    <meta name="description" content="定义模型 - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme */
            --primary-color: #2980b9;
            --primary-hover: #1a5276;
            --link-color: #c0392b;
            --text-color: #333;
            --text-light: #666;
            --text-muted: #999;
            --bg-color: #fff;
            --bg-secondary: #f8f9fa;
            --bg-code: #f5f5f5;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px rgba(0,0,0,0.1);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#torchoptimsgd">torch.optim.SGD</a><ul>
<li><a href="#1-基本语法">1. 基本语法</a></li>
<li><a href="#2-随机梯度下降sgd">2. 随机梯度下降（SGD）</a></li>
<li><a href="#3-带动量的-sgd">3. 带动量的 SGD</a></li>
<li><a href="#4-带-nesterov-动量的-sgd">4. 带 Nesterov 动量的 SGD</a></li>
<li><a href="#5-参数说明">5. 参数说明</a></li>
<li><a href="#6-示例代码">6. 示例代码</a><ul>
<li><a href="#不带动量的-sgd">不带动量的 SGD</a></li>
<li><a href="#带动量的-sgd">带动量的 SGD</a></li>
<li><a href="#带-nesterov-动量的-sgd">带 Nesterov 动量的 SGD</a></li>
</ul>
</li>
<li><a href="#7-注意事项">7. 注意事项</a></li>
<li><a href="#总结">总结</a></li>
</ul>
</li>
<li><a href="#torchoptimadam">torch.optim.Adam</a><ul>
<li><a href="#1-基本语法_1">1. 基本语法</a></li>
<li><a href="#2-adam-优化算法原理">2. Adam 优化算法原理</a><ul>
<li><a href="#一阶和二阶矩估计">一阶和二阶矩估计</a></li>
</ul>
</li>
<li><a href="#3-参数解释">3. 参数解释</a></li>
<li><a href="#4-示例代码">4. 示例代码</a><ul>
<li><a href="#标准-adam-优化器">标准 Adam 优化器</a></li>
<li><a href="#带权重衰减和自适应动量的-adam-优化器">带权重衰减和自适应动量的 Adam 优化器</a></li>
<li><a href="#启用-amsgrad-的-adam-优化器">启用 AMSGrad 的 Adam 优化器</a></li>
</ul>
</li>
<li><a href="#5-adam-优化器的优缺点">5. Adam 优化器的优缺点</a><ul>
<li><a href="#优点">优点</a></li>
<li><a href="#缺点">缺点</a></li>
</ul>
</li>
<li><a href="#6-adam-vs-sgd">6. Adam vs. SGD</a></li>
<li><a href="#7-总结">7. 总结</a></li>
</ul>
</li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>定义模型</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-01-28</span>
                        <span><i class="fas fa-folder"></i> AINotes/30.PyTorch/04.模型</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="torchoptimsgd">torch.optim.SGD<a class="anchor-link" href="#torchoptimsgd" title="Permanent link">&para;</a></h2>
<p><code>torch.optim.SGD</code> 是 PyTorch 中用于实现随机梯度下降（Stochastic Gradient Descent, SGD）优化算法的类。SGD 是一种常用的优化方法，广泛用于训练深度学习模型。</p>
<h3 id="1-基本语法">1. 基本语法<a class="anchor-link" href="#1-基本语法" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">torch.optim.SGD(params, lr=&lt;required parameter&gt;, momentum=0, dampening=0, weight_decay=0, nesterov=False)
</code></pre>
<ul>
<li><code>params</code>：要优化的模型参数，通常传递 <code>model.parameters()</code>。</li>
<li><code>lr</code>：学习率（learning rate），控制每次参数更新的步长。学习率是 SGD 的一个重要超参数。</li>
<li><code>momentum</code>：动量项（Momentum），用于加速 SGD 收敛，尤其是在存在噪声的情况下。默认值为 <code>0</code>，表示不使用动量。</li>
<li><code>dampening</code>：用于控制动量的衰减，默认值为 <code>0</code>，即没有衰减。</li>
<li><code>weight_decay</code>：权重衰减（L2 正则化），用于控制模型复杂度，防止过拟合。默认值为 <code>0</code>，表示不使用权重衰减。</li>
<li><code>nesterov</code>：布尔值，表示是否使用 Nesterov 动量，默认值为 <code>False</code>，即不使用。</li>
</ul>
<h3 id="2-随机梯度下降sgd">2. 随机梯度下降（SGD）<a class="anchor-link" href="#2-随机梯度下降sgd" title="Permanent link">&para;</a></h3>
<p>SGD 是一种逐个小批量（mini-batch）更新模型参数的优化方法。每次从数据集中随机抽取一个或多个样本进行梯度计算并更新参数。相比于标准的梯度下降（batch gradient descent）使用整个数据集计算梯度，SGD 能加速训练，但会带来一些噪声。</p>
<p>SGD 通过以下公式更新参数：<br />
<div class="math-display"><br />
    \theta = \theta - \eta \nabla_{\theta}J(\theta)<br />
</div><br />
- <span class="math-inline">\theta</span> 是模型参数。<br />
- <span class="math-inline">\eta</span> 是学习率。<br />
- <span class="math-inline">\nabla_{\theta}J(\theta)</span> 是损失函数关于 <span class="math-inline">\theta</span> 的梯度。</p>
<h3 id="3-带动量的-sgd">3. 带动量的 SGD<a class="anchor-link" href="#3-带动量的-sgd" title="Permanent link">&para;</a></h3>
<p>动量是 SGD 的一种改进版本，通过在梯度更新中引入动量项，动量可以减少训练过程中的震荡，加速收敛。动量项累积之前的梯度，使得优化方向更稳定。</p>
<p>带动量的 SGD 更新规则为：<br />
<div class="math-display"><br />
    v_t = \mu v_{t-1} + \eta \nabla_{\theta}J(\theta)<br />
</div></p>
<p><div class="math-display"><br />
    \theta = \theta - v_t<br />
</div><br />
其中：<br />
- <span class="math-inline">v_t</span> 是速度（velocity），它是在梯度上累积的动量。<br />
- <span class="math-inline">μ</span> 是动量系数，表示之前更新的权重。通常取值范围为 <code>[0, 1]</code>，如 <code>0.9</code>。</p>
<h3 id="4-带-nesterov-动量的-sgd">4. 带 Nesterov 动量的 SGD<a class="anchor-link" href="#4-带-nesterov-动量的-sgd" title="Permanent link">&para;</a></h3>
<p>Nesterov 动量是一种动量的改进版本，它在参数更新时使用了提前更新的梯度，这样可以更好地调整学习方向。Nesterov 动量的更新公式为：<br />
<div class="math-display"><br />
    v_t = \mu v_{t-1} + \eta \nabla_{\theta}J(\theta - \mu v_{t-1})<br />
</div></p>
<p><div class="math-display"><br />
    \theta = \theta - v_t<br />
</div><br />
在 PyTorch 中，你可以通过设置 <code>nesterov=True</code> 来使用 Nesterov 动量。</p>
<h3 id="5-参数说明">5. 参数说明<a class="anchor-link" href="#5-参数说明" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>学习率（<code>lr</code>）</strong>：学习率是控制优化器步长的重要参数。值太大会导致训练不稳定，太小则会收敛过慢。通常，学习率会随着训练进行而调整（如使用学习率调度器）。</p>
</li>
<li>
<p><strong>动量（<code>momentum</code>）</strong>：动量在优化过程中积累之前的梯度，使得参数更新不仅考虑当前的梯度，还考虑之前的梯度。常见值为 <code>0.9</code> 或 <code>0.99</code>。</p>
</li>
<li>
<p><strong>权重衰减（<code>weight_decay</code>）</strong>：权重衰减对应于 L2 正则化项，通常用于防止模型过拟合。它会对每次更新的权重进行一定的衰减。权重衰减公式如下：<br />
<div class="math-display"><br />
    \theta = \theta - \eta (\nabla_{\theta}J(\theta) + \lambda \theta)<br />
</div><br />
其中 <code>λ</code> 是权重衰减因子，也就是 <code>weight_decay</code>。</p>
</li>
<li>
<p><strong>dampening</strong>：动量的衰减参数，通常与 <code>momentum</code> 一起使用。当 <code>dampening</code> 为非零值时，动量的更新会随着时间逐渐减小。默认 <code>0</code> 不衰减。</p>
</li>
</ul>
<h3 id="6-示例代码">6. 示例代码<a class="anchor-link" href="#6-示例代码" title="Permanent link">&para;</a></h3>
<h4 id="不带动量的-sgd">不带动量的 SGD<a class="anchor-link" href="#不带动量的-sgd" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义模型
model = torch.nn.Linear(2, 1)

# 定义优化器
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 训练循环
for epoch in range(100):
    # 前向传播
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)
# 梯度清零
    optimizer.zero_grad()
# 反向传播
    loss.backward()
# 更新参数
    optimizer.step()
</code></pre>
<h4 id="带动量的-sgd">带动量的 SGD<a class="anchor-link" href="#带动量的-sgd" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义模型
model = torch.nn.Linear(2, 1)

# 定义带动量的优化器
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# 训练循环
for epoch in range(100):
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)

optimizer.zero_grad()
    loss.backward()
    optimizer.step()
</code></pre>
<h4 id="带-nesterov-动量的-sgd">带 Nesterov 动量的 SGD<a class="anchor-link" href="#带-nesterov-动量的-sgd" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义模型
model = torch.nn.Linear(2, 1)

# 定义带 Nesterov 动量的优化器
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)

# 训练循环
for epoch in range(100):
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)

optimizer.zero_grad()
    loss.backward()
    optimizer.step()
</code></pre>
<h3 id="7-注意事项">7. 注意事项<a class="anchor-link" href="#7-注意事项" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>学习率调整</strong>：SGD 对学习率敏感，通常需要在训练过程中使用调度器（如 <code>torch.optim.lr_scheduler</code>）来动态调整学习率。</li>
<li><strong>小批量数据</strong>：SGD 通常在小批量（mini-batch）数据上运行，这可以减少内存消耗并提高模型更新频率。</li>
<li><strong>动量设置</strong>：大多数情况下，使用 <code>momentum=0.9</code> 是一种常见的选择，尤其是当数据中有噪声时，动量能够加速收敛并减少震荡。</li>
</ol>
<h3 id="总结">总结<a class="anchor-link" href="#总结" title="Permanent link">&para;</a></h3>
<p><code>torch.optim.SGD</code> 是 PyTorch 中实现随机梯度下降（SGD）的优化器类。它可以通过引入动量和权重衰减等增强功能来改善模型的训练效果，特别是在深度学习中的应用。</p>
<hr />
<h2 id="torchoptimadam">torch.optim.Adam<a class="anchor-link" href="#torchoptimadam" title="Permanent link">&para;</a></h2>
<p><code>torch.optim.Adam</code> 是 PyTorch 中实现 <strong>Adam</strong> 优化算法的类。Adam（Adaptive Moment Estimation，自适应矩估计）是深度学习中一种非常流行的优化算法，它结合了<strong>动量法</strong>和<strong>RMSProp</strong> 的优点，能够高效处理大规模的数据并且无需手动调整学习率。</p>
<h3 id="1-基本语法_1">1. 基本语法<a class="anchor-link" href="#1-基本语法_1" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
</code></pre>
<ul>
<li><strong><code>params</code></strong>：要优化的参数（通常传递 <code>model.parameters()</code>）。</li>
<li><strong><code>lr</code></strong>：学习率，控制每次更新的步长。Adam 的默认学习率是 <code>0.001</code>，通常比 SGD 的默认学习率小，因为 Adam 会根据梯度变化自适应调整步长。</li>
<li><strong><code>betas</code></strong>：一对控制一阶和二阶矩估计的系数。默认值为 <code>(0.9, 0.999)</code>，分别对应一阶矩（动量项）和二阶矩（梯度平方的指数加权移动平均）。</li>
<li><strong><code>eps</code></strong>：为了防止除以零，Adam 算法在更新时加上的一个非常小的数值。默认值是 <code>1e-08</code>。</li>
<li><strong><code>weight_decay</code></strong>：权重衰减，等价于 L2 正则化，用于防止模型过拟合。默认值为 <code>0</code>。</li>
<li><strong><code>amsgrad</code></strong>：布尔值，是否启用 AMSGrad 算法的改进版本。默认值为 <code>False</code>。</li>
</ul>
<h3 id="2-adam-优化算法原理">2. Adam 优化算法原理<a class="anchor-link" href="#2-adam-优化算法原理" title="Permanent link">&para;</a></h3>
<p>Adam 算法结合了 SGD 中的<strong>动量法</strong>和 RMSProp。与标准的梯度下降方法不同，Adam 使用两个动量项：一个是梯度的动量（类似于 <code>SGD + momentum</code>），另一个是梯度平方的动量，用来调整学习率。</p>
<h4 id="一阶和二阶矩估计">一阶和二阶矩估计<a class="anchor-link" href="#一阶和二阶矩估计" title="Permanent link">&para;</a></h4>
<p>Adam 主要通过一阶和二阶矩的指数移动平均值来进行参数更新：</p>
<ul>
<li><strong>一阶矩估计</strong>：对梯度进行指数加权移动平均，类似于动量法。</li>
<li><strong>二阶矩估计</strong>：对梯度平方进行指数加权移动平均，用于调节学习率。</li>
</ul>
<p>更新公式如下：</p>
<ol>
<li>
<p><strong>一阶矩动量（动量）</strong>：<br />
<div class="math-display"><br />
    m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t<br />
</div><br />
其中，<code>m_t</code> 是当前时刻的梯度一阶矩动量，<code>g_t</code> 是当前时刻的梯度，<code>β_1</code> 是一阶矩的衰减系数，通常取 <code>0.9</code>。</p>
</li>
<li>
<p><strong>二阶矩动量</strong>：<br />
<div class="math-display"><br />
    v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2<br />
</div><br />
其中，<code>v_t</code> 是当前时刻的梯度二阶矩动量，<code>g_t^2</code> 是当前时刻的梯度平方，<code>β_2</code> 是二阶矩的衰减系数，通常取 <code>0.999</code>。</p>
</li>
<li>
<p><strong>偏差修正</strong>：为了修正初始时的偏差，Adam 引入了以下修正公式：<br />
<div class="math-display"><br />
    \hat{m_t} = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v_t} = \frac{v_t}{1 - \beta_2^t}<br />
</div></p>
</li>
<li><strong>参数更新</strong>：<br />
<div class="math-display"><br />
    \theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}<br />
</div><br />
其中，<code>θ_t</code> 是模型的参数，<code>η</code> 是学习率，<code>ε</code> 是为了避免除零的数值（默认值 <code>1e-8</code>）。</li>
</ol>
<h3 id="3-参数解释">3. 参数解释<a class="anchor-link" href="#3-参数解释" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong><code>lr</code>（学习率）</strong>：Adam 的学习率默认是 <code>0.001</code>，通常它不需要像 SGD 那样频繁调整，因为它对不同参数使用自适应学习率。如果要微调学习率，可以根据模型的具体情况调整。</p>
</li>
<li>
<p><strong><code>betas</code>（动量系数）</strong>：</p>
</li>
<li><code>beta1=0.9</code>：控制一阶矩估计的衰减率。较高的 <code>beta1</code> 值会平滑梯度更新，但可能会导致模型学习速度变慢。</li>
<li>
<p><code>beta2=0.999</code>：控制二阶矩估计的衰减率，用于调整学习率。如果 <code>beta2</code> 取值太小，学习率会波动过大。</p>
</li>
<li>
<p><strong><code>eps</code>（小数值）</strong>：用于数值稳定性，防止除以零的错误。通常不需要调整。</p>
</li>
<li>
<p><strong><code>weight_decay</code>（权重衰减）</strong>：在 Adam 中，权重衰减等价于 L2 正则化，用于防止过拟合。较大的 <code>weight_decay</code> 值会对模型施加更强的正则化。</p>
</li>
<li>
<p><strong><code>amsgrad</code></strong>：这个参数是 <code>Adam</code> 的一个改进版本。AMSGrad 通过记录历史最大值来保证优化器的收敛性。默认 <code>False</code> 即为标准的 Adam，<code>True</code> 时为 AMSGrad。</p>
</li>
</ul>
<h3 id="4-示例代码">4. 示例代码<a class="anchor-link" href="#4-示例代码" title="Permanent link">&para;</a></h3>
<h4 id="标准-adam-优化器">标准 Adam 优化器<a class="anchor-link" href="#标准-adam-优化器" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义一个简单的模型
model = torch.nn.Linear(2, 1)

# 定义 Adam 优化器
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练循环
for epoch in range(100):
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)

# 梯度清零
    optimizer.zero_grad()

# 反向传播
    loss.backward()

# 更新参数
    optimizer.step()
</code></pre>
<h4 id="带权重衰减和自适应动量的-adam-优化器">带权重衰减和自适应动量的 Adam 优化器<a class="anchor-link" href="#带权重衰减和自适应动量的-adam-优化器" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义模型
model = torch.nn.Linear(2, 1)

# 带有权重衰减的 Adam 优化器
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4, betas=(0.9, 0.999))

# 训练循环
for epoch in range(100):
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)

optimizer.zero_grad()
    loss.backward()
    optimizer.step()
</code></pre>
<h4 id="启用-amsgrad-的-adam-优化器">启用 AMSGrad 的 Adam 优化器<a class="anchor-link" href="#启用-amsgrad-的-adam-优化器" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">import torch
import torch.optim as optim

# 定义模型
model = torch.nn.Linear(2, 1)

# 使用 AMSGrad 的 Adam 优化器
optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)

# 训练循环
for epoch in range(100):
    outputs = model(torch.randn(10, 2))
    loss = torch.mean((outputs - torch.randn(10, 1)) ** 2)

optimizer.zero_grad()
    loss.backward()
    optimizer.step()
</code></pre>
<h3 id="5-adam-优化器的优缺点">5. Adam 优化器的优缺点<a class="anchor-link" href="#5-adam-优化器的优缺点" title="Permanent link">&para;</a></h3>
<h4 id="优点">优点<a class="anchor-link" href="#优点" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>自适应学习率</strong>：Adam 的每个参数都拥有自适应的学习率，不同参数的学习率会根据其梯度更新情况进行自动调整。</li>
<li><strong>动量</strong>：Adam 在参数更新中引入了动量项，有效地平滑了更新方向，减少了噪声影响，加快了收敛速度。</li>
<li><strong>无需手动调参</strong>：相比于 SGD，Adam 对学习率的要求相对宽松，训练过程较为稳定。</li>
<li><strong>高效计算</strong>：Adam 的计算效率高，占用内存小，非常适合大规模数据和模型的训练。</li>
</ol>
<h4 id="缺点">缺点<a class="anchor-link" href="#缺点" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>过拟合风险</strong>：由于 Adam 可以快速适应参数变化，可能会导致过拟合，尤其是当模型复杂度较高且训练数据量较少时。</li>
<li><strong>学习率退化</strong>：在一些特定任务中（如自然语言处理任务），Adam 可能会导致学习率在训练后期衰减过快，从而减缓模型进一步优化的速度。</li>
<li><strong>较差的泛化性能</strong>：有时 Adam 优化器训练出的模型在测试集上的表现不如 SGD 优化器，尤其是当数据量较大时。</li>
</ol>
<h3 id="6-adam-vs-sgd">6. Adam vs. SGD<a class="anchor-link" href="#6-adam-vs-sgd" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>SGD</strong>：具有更好的泛化能力，但收敛速度较慢，尤其在梯度较小或不平稳的情况下需要更大的调整。</li>
<li><strong>Adam</strong>：收敛速度更快且更稳定，适合处理稀疏数据和高维度数据，但在某些情况下泛化能力不足</li>
</ul>
<p>如 SGD。</p>
<h3 id="7-总结">7. 总结<a class="anchor-link" href="#7-总结" title="Permanent link">&para;</a></h3>
<p><code>torch.optim.Adam</code> 是一种自适应优化算法，它结合了动量法和 RMSProp 的优点，使得优化过程更加高效且稳定。它适用于各种深度学习任务，尤其在处理大规模数据和高维度问题时表现出色。然而，在某些特定任务中，Adam 的泛化性能可能不如 SGD，因此在选择优化器时应根据具体任务进行调试和比较。</p>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
