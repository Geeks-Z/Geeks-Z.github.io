<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>创建存放在 GPU 的数据</title>
    <meta name="description" content="创建存放在 GPU 的数据 - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme */
            --primary-color: #2980b9;
            --primary-hover: #1a5276;
            --link-color: #c0392b;
            --text-color: #333;
            --text-light: #666;
            --text-muted: #999;
            --bg-color: #fff;
            --bg-secondary: #f8f9fa;
            --bg-code: #f5f5f5;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px rgba(0,0,0,0.1);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#tensors">Tensors</a></li>
<li><a href="#tensor-与-variable">Tensor 与 Variable</a></li>
<li><a href="#tensor-创建方法">tensor 创建方法</a><ul>
<li><a href="#直接创建">直接创建</a></li>
<li><a href="#指定类型函数随机创建">指定类型函数随机创建</a></li>
<li><a href="#tensor-和-numpy-array-之间的相互转换">tensor 和 numpy array 之间的相互转换</a></li>
<li><a href="#根据数值创建">根据数值创建</a><ul>
<li><a href="#torchzeros">torch.zeros()</a></li>
<li><a href="#torchzeros_like">torch.zeros_like()</a></li>
<li><a href="#torchfull--torchfull_like">torch.full() | torch.full_like()</a></li>
<li><a href="#torcharange">torch.arange()</a></li>
<li><a href="#torchrand">torch.rand()</a></li>
<li><a href="#torchlinspace">torch.linspace()</a></li>
<li><a href="#torchlogspace">torch.logspace()</a></li>
<li><a href="#torcheye">torch.eye()</a></li>
</ul>
</li>
<li><a href="#根据概率创建">根据概率创建</a><ul>
<li><a href="#torchrandn">torch.randn</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#pytorch-中-tensor-的常用方法">PyTorch 中 tensor 的常用方法</a><ul>
<li><a href="#查看-tensor-维度信息">查看 tensor 维度信息</a></li>
<li><a href="#广播机制">广播机制</a></li>
<li><a href="#cuda-中的-tensor">CUDA 中的 tensor</a></li>
<li><a href="#torchnumel">torch.numel()</a></li>
</ul>
</li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>创建存放在 GPU 的数据</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-01-28</span>
                        <span><i class="fas fa-folder"></i> AINotes/30.PyTorch/02.Tensors</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="tensors"><a href="https://pytorch.org/docs/stable/torch.html#tensors">Tensors</a><a class="anchor-link" href="#tensors" title="Permanent link">&para;</a></h2>
<p>Tensor 中文为张量。张量的意思是一个多维数组，它是标量、向量、矩阵的高维扩展。</p>
<p>标量可以称为 0 维张量，向量可以称为 1 维张量，矩阵可以称为 2 维张量，RGB 图像可以表示 3 维张量。你可以把张量看作多维数组。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/image202209121805265.png"/></div>

<h2 id="tensor-与-variable">Tensor 与 Variable<a class="anchor-link" href="#tensor-与-variable" title="Permanent link">&para;</a></h2>
<p>在 PyTorch 0.4.0 之前，torch.autograd 包中存在 Variable 这种数据类型，主要是用于封装 Tensor，进行自动求导。Variable 主要包含下面几种属性。</p>
<p>data: 被包装的 Tensor。</p>
<p>grad: data 的梯度。</p>
<p>grad_fn: 创建 Tensor 所使用的 Function，是自动求导的关键，因为根据所记录的函数才能计算出导数。</p>
<p>requires_grad: 指示是否需要梯度，并不是所有的张量都需要计算梯度。</p>
<p>is_leaf: 指示是否叶子节点(张量)，叶子节点的概念在计算图中会用到，后面详细介绍。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/image202209121806485.png"/></div>

<p>在 PyTorch 0.4.0 之后，Variable 并入了 Tensor。在之后版本的 Tensor 中，除了具有上面 Variable 的 5 个属性，还有另外 3 个属性。</p>
<ul>
<li>dtype: 张量的数据类型，如 torch.FloatTensor，torch.cuda.FloatTensor。</li>
<li>shape: 张量的形状。如 (64, 3, 224, 224)</li>
<li>device: 张量所在设备 (CPU/GPU)，GPU 是加速计算的关键</li>
</ul>
<div align="center"><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/image202209121806841.png" alt="image"></div>

<p>关于 dtype，PyTorch 提供了 9 种数据类型，共分为 3 大类：float (16-bit, 32-bit, 64-bit)、integer (unsigned-8-bit ,8-bit, 16-bit, 32-bit, 64-bit)、Boolean。模型参数和数据用的最多的类型是 float-32-bit。label 常用的类型是 integer-64-bit。</p>
<div align="center"><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/image202209121806634.png"/></div>

<h2 id="tensor-创建方法">tensor 创建方法<a class="anchor-link" href="#tensor-创建方法" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th style="text-align: right;">函数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;">Tensor(sizes)</td>
<td>基础构造函数</td>
</tr>
<tr>
<td style="text-align: right;">tensor(data)</td>
<td>类似于 np.array</td>
</tr>
<tr>
<td style="text-align: right;">ones(sizes)</td>
<td>全 1</td>
</tr>
<tr>
<td style="text-align: right;">zeros(sizes)</td>
<td>全 0</td>
</tr>
<tr>
<td style="text-align: right;">eye(sizes)</td>
<td>对角为 1，其余为 0</td>
</tr>
<tr>
<td style="text-align: right;">arange(s,e,step)</td>
<td>从 s 到 e，步长为 step</td>
</tr>
<tr>
<td style="text-align: right;">linspace(s,e,steps)</td>
<td>从 s 到 e，均匀分成 step 份</td>
</tr>
<tr>
<td style="text-align: right;">rand/randn(sizes)</td>
<td>rand 是[0,1)均匀分布；randn 是服从 N(0，1)的正态分布</td>
</tr>
<tr>
<td style="text-align: right;">normal(mean,std)</td>
<td>正态分布(均值为 mean，标准差是 std)</td>
</tr>
<tr>
<td style="text-align: right;">randperm(m)</td>
<td>随机排列</td>
</tr>
</tbody>
</table>
<h3 id="直接创建">直接创建<a class="anchor-link" href="#直接创建" title="Permanent link">&para;</a></h3>
<p><code>torch.tensor()</code></p>
<pre><code class="language-python">torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)
</code></pre>
<p><code>data:</code> 数据，可以是 list，numpy</p>
<p><code>dtype:</code> 数据类型，默认与 data 的一致</p>
<p><code>device:</code> 所在设备，cuda/cpu</p>
<p><code>requires_grad:</code> 是否需要梯度</p>
<p><code>pin_memory:</code> 是否存于锁页内存</p>
<p>代码示例：</p>
<pre><code class="language-python">ndarray = np.ones((3, 3))
print(&quot;ndarray的数据类型：&quot;, ndarray.dtype)
# 创建存放在 GPU 的数据
# t = torch.tensor(ndarray, device='cuda')
t= torch.tensor(ndarray)
print(t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">ndarray的数据类型： float64
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], device='cuda:0', dtype=torch.float64)
</code></pre>
<h3 id="指定类型函数随机创建">指定类型函数随机创建<a class="anchor-link" href="#指定类型函数随机创建" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">out_a = torch.FloatTensor(2,3)
out_b = torch.IntTensor(2)
out_c = torch.IntTensor([1,2,3,4])
print(out_a,'\n',out_b,'\n',out_c)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([[1.9964e-16, 4.5898e-41, 2.0081e-32],
        [0.0000e+00, 0.0000e+00, 0.0000e+00]])
 tensor([627453024,     32754], dtype=torch.int32)
 tensor([1, 2, 3, 4], dtype=torch.int32)
</code></pre>
<h3 id="tensor-和-numpy-array-之间的相互转换">tensor 和 numpy array 之间的相互转换<a class="anchor-link" href="#tensor-和-numpy-array-之间的相互转换" title="Permanent link">&para;</a></h3>
<p><code>torch.from_numpy(ndarray)</code></p>
<p>从 numpy 创建 tensor。利用这个方法创建的 tensor 和原来的 ndarray 共享内存，当修改其中一个数据，另外一个也会被改动。</p>
<div align="center">
        <img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/image202209121806362.png" alt="image-20220912180657326">
</div>

<p>代码示例：</p>
<pre><code class="language-python">arr = np.array([[1, 2, 3], [4, 5, 6]])
t = torch.from_numpy(arr)

# 修改 array，tensor 也会被修改
# print(&quot;\n修改arr&quot;)
# arr[0, 0] = 0
# print(&quot;numpy array: &quot;, arr)
# print(&quot;tensor : &quot;, t)

# 修改 tensor，array 也会被修改
print(&quot;\n修改tensor&quot;)
t[0, 0] = -1
print(&quot;numpy array: &quot;, arr)
print(&quot;tensor : &quot;, t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">修改tensor
numpy array:  [[-1  2  3]
 [ 4  5  6]]
tensor :  tensor([[-1,  2,  3],
        [ 4,  5,  6]], dtype=torch.int32)
</code></pre>
<h3 id="根据数值创建">根据数值创建<a class="anchor-link" href="#根据数值创建" title="Permanent link">&para;</a></h3>
<h4 id="torchzeros">torch.zeros()<a class="anchor-link" href="#torchzeros" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：根据 size 创建全 0 张量</p>
<ul>
<li>size: 张量的形状</li>
<li>out: 输出的张量，如果指定了 out，那么<code>torch.zeros()</code>返回的张量和 out 指向的是同一个地址</li>
<li>layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。</li>
<li>device: 所在设备，cuda/cpu</li>
<li>requires_grad: 是否需要梯度</li>
</ul>
<p>代码示例：</p>
<pre><code class="language-python">out_t = torch.tensor([1])
# 这里制定了 out
t = torch.zeros((3, 3), out=out_t)
print(t, '\n', out_t)
# id 是取内存地址。最终 t 和 out_t 是同一个内存地址
print(id(t), id(out_t), id(t) == id(out_t))
</code></pre>
<p>输出是：</p>
<pre><code class="language-python">tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
 tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
2984903203072 2984903203072 True
</code></pre>
<h4 id="torchzeros_like">torch.zeros_like()<a class="anchor-link" href="#torchzeros_like" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
</code></pre>
<p>功能：根据 input 形状创建全 0 张量</p>
<ul>
<li>input: 创建与 input 同形状的全 0 张量</li>
<li>dtype: 数据类型</li>
<li>layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。</li>
</ul>
<p>同理还有全 1 张量的创建方法：<code>torch.ones()</code>，<code>torch.ones_like()</code>。</p>
<h4 id="torchfull--torchfull_like">torch.full() | torch.full_like()<a class="anchor-link" href="#torchfull--torchfull_like" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：创建自定义数值的张量</p>
<ul>
<li>size: 张量的形状，如 (3,3)</li>
<li>fill_value: 张量中每一个元素的值</li>
</ul>
<p>代码示例：</p>
<pre><code class="language-python">t = torch.full((3, 3), 1)
print(t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
</code></pre>
<h4 id="torcharange">torch.arange()<a class="anchor-link" href="#torcharange" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：创建等差的 1 维张量。注意区间为[start, end)。</p>
<ul>
<li>start: 数列起始值</li>
<li>end: 数列结束值，开区间，取不到结束值</li>
<li>step: 数列公差，默认为 1</li>
</ul>
<p>代码示例：</p>
<pre><code class="language-python">t = torch.arange(2, 10, 2)
print(t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([2, 4, 6, 8])
</code></pre>
<h4 id="torchrand">torch.rand()<a class="anchor-link" href="#torchrand" title="Permanent link">&para;</a></h4>
<blockquote>
<p><code>torch.rand</code> 是 PyTorch 中用于生成具有均匀分布随机数的函数。这个函数返回一个填充了从区间 [0, 1) 中均匀抽取的随机数的张量。</p>
</blockquote>
<p><code>torch.rand(*size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor</code></p>
<p><code>torch.rand</code> 的参数说明如下：</p>
<ul>
<li><strong>sizes (int...)</strong>: 这是一个整数序列，用于定义输出张量的形状。例如，<code>torch.rand(3, 4)</code> 会返回一个形状为 3x4 的张量，其中每个元素都是 [0, 1) 区间内的随机数。</li>
<li><strong>out (Tensor, optional)</strong>: 如果提供了这个参数，那么生成的随机数会被存放在提供的张量 <code>out</code> 中。如果 <code>out</code> 已有内容，则会被新生成的随机数覆盖。</li>
<li><strong>dtype (torch.dtype, optional)</strong>: 期望的输出张量的数据类型。如果没有提供，则使用默认的浮点数据类型（通常是 <code>torch.float32</code>）。</li>
<li><strong>layout (torch.layout, optional)</strong>: 期望的输出张量的内存布局。默认是 <code>torch.strided</code>。</li>
<li><strong>device (torch.device, optional)</strong>: 期望的输出张量所在的设备。可以是 CPU 或 GPU。如果没有提供，则使用当前默认的张量设备。</li>
<li><strong>requires_grad (bool, optional)</strong>: 如果设置为 <code>True</code>，则生成的张量将需要计算梯度，这在自动微分中是必要的。默认为 <code>False</code>。</li>
</ul>
<p>下面是一个简单的示例，演示了如何使用 <code>torch.rand</code>：</p>
<pre><code class="language-python">import torch

# 生成一个形状为 (2, 3) 的张量，其中的元素是从 [0, 1) 区间内均匀抽取的随机数
tensor = torch.rand(2, 3)
print(tensor)
</code></pre>
<p>输出可能类似于：</p>
<pre><code>tensor([[0.1234, 0.5678, 0.9012],
        [0.3456, 0.7890, 0.2345]])
</code></pre>
<p>每次调用 <code>torch.rand</code> 时，即使使用相同的形状和参数，得到的张量中的值也可能会有所不同，因为这些值是随机生成的。</p>
<h4 id="torchlinspace">torch.linspace()<a class="anchor-link" href="#torchlinspace" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：创建均分的 1 维张量。数值区间为 [start, end]</p>
<ul>
<li>start: 数列起始值</li>
<li>end: 数列结束值</li>
<li>steps: 数列长度 (元素个数)</li>
</ul>
<p>代码示例：</p>
<pre><code class="language-python"># t = torch.linspace(2, 10, 5)
t = torch.linspace(2, 10, 6)
print(t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([ 2.0000,  3.6000,  5.2000,  6.8000,  8.4000, 10.0000])
</code></pre>
<h4 id="torchlogspace">torch.logspace()<a class="anchor-link" href="#torchlogspace" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：创建对数均分的 1 维张量。数值区间为 [start, end]，底为 base。</p>
<ul>
<li>start: 数列起始值</li>
<li>end: 数列结束值</li>
<li>steps: 数列长度 (元素个数)</li>
<li>base: 对数函数的底，默认为 10</li>
</ul>
<p>代码示例：</p>
<pre><code class="language-python"># t = torch.logspace(2, 10, 5)
t = torch.logspace(2, 10, 6)
print(t)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([ 2.0000,  3.6000,  5.2000,  6.8000,  8.4000, 10.0000])
</code></pre>
<h4 id="torcheye">torch.eye()<a class="anchor-link" href="#torcheye" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>功能：创建单位对角矩阵( 2 维张量)，默认为方阵</p>
<ul>
<li>n: 矩阵行数。通常只设置 n，为方阵。</li>
<li>m: 矩阵列数</li>
</ul>
<h3 id="根据概率创建">根据概率创建<a class="anchor-link" href="#根据概率创建" title="Permanent link">&para;</a></h3>
<h4 id="torchrandn">torch.randn<a class="anchor-link" href="#torchrandn" title="Permanent link">&para;</a></h4>
<p><code>torch.randn([3,4])</code> 创建 3 行 4 列的<strong>随机数</strong>的 tensor，随机值的分布式均值为 0，方差为 1</p>
<pre><code class="language-python">torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
</code></pre>
<p>返回一个张量，包含了从标准正态分布(均值为 0，方差为 1，即高斯白噪声)中抽取一组随机数，形状由可变参数<code>sizes</code>定义。 参数:</p>
<ul>
<li>sizes (int...) – 整数序列，定义了输出形状</li>
<li>out (<em><a href="http://pytorch.org/docs/tensors.html#torch.Tensor">Tensor</a></em>, <em>optinal</em>) - 结果张量</li>
</ul>
<pre><code class="language-python">&gt;&gt;&gt; torch.randn(2, 3)

 1.4339  0.3351 -1.0999
 1.5458 -0.9643 -0.3558
[torch.FloatTensor of size 2x3]
</code></pre>
<h2 id="pytorch-中-tensor-的常用方法">PyTorch 中 tensor 的常用方法<a class="anchor-link" href="#pytorch-中-tensor-的常用方法" title="Permanent link">&para;</a></h2>
<h3 id="查看-tensor-维度信息">查看 tensor 维度信息<a class="anchor-link" href="#查看-tensor-维度信息" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">out = torch.randn(2, 3)
print(out.size())
print(out.shape)
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">torch.Size([2, 3])
torch.Size([2, 3])
</code></pre>
<p>tensor.size()</p>
<h3 id="广播机制">广播机制<a class="anchor-link" href="#广播机制" title="Permanent link">&para;</a></h3>
<p>当对两个形状不同的 Tensor 按元素运算时，可能会触发广播(broadcasting)机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算。</p>
<pre><code class="language-python">x = torch.arange(1, 3).view(1, 2)
print(x)
y = torch.arange(1, 4).view(3, 1)
print(y)
print(x + y)
</code></pre>
<pre><code class="language-python">tensor([[1, 2]])
tensor([[1],
        [2],
        [3]])
tensor([[2, 3],
        [3, 4],
        [4, 5]])
</code></pre>
<pre><code class="language-python">tensor([[1, 2]])
tensor([[1],
        [2],
        [3]])
tensor([[2, 3],
        [3, 4],
        [4, 5]])
</code></pre>
<p>由于 x 和 y 分别是 1 行 2 列和 3 行 1 列的矩阵，如果要计算 x+y，那么 x 中第一行的 2 个元素被广播 (复制)到了第二行和第三行，⽽ y 中第⼀列的 3 个元素被广播(复制)到了第二列。如此，就可以对 2 个 3 行 2 列的矩阵按元素相加。</p>
<h3 id="cuda-中的-tensor">CUDA 中的 tensor<a class="anchor-link" href="#cuda-中的-tensor" title="Permanent link">&para;</a></h3>
<p>CUDA（Compute Unified Device Architecture），是 NVIDIA 推出的运算平台。 CUDA™ 是一种由 NVIDIA 推出的通用并行计算架构，该架构使 GPU 能够解决复杂的计算问题。</p>
<p><code>torch.cuda</code>这个模块增加了对 CUDA tensor 的支持，能够在 cpu 和 gpu 上使用相同的方法操作 tensor</p>
<p>通过<code>.to</code>方法能够把一个 tensor 转移到另外一个设备(比如从 CPU 转到 GPU)</p>
<pre><code class="language-python">x = torch.randn(1,2)
if torch.cuda.is_available():
    device = torch.device(&quot;cuda&quot;)          # cuda device对象
    y = torch.ones_like(x, device=device)  # 创建一个在cuda上的tensor
    x = x.to(device)                       # 使用方法把x转为cuda 的tensor
    z = x + y
    print(z)
    print(z.to(&quot;cpu&quot;, torch.double))        # .to方法也能够同时设置类型
</code></pre>
<p>输出为：</p>
<pre><code class="language-python">tensor([[ 1.9796, -0.8879]], device='cuda:0')
tensor([[ 1.9796, -0.8879]], dtype=torch.float64)
</code></pre>
<h3 id="torchnumel">torch.numel()<a class="anchor-link" href="#torchnumel" title="Permanent link">&para;</a></h3>
<p><code>torch.numel()</code> 是 PyTorch 中用于计算张量（tensor）中元素总数的函数。它不接受任何参数，因为它直接作用于调用它的张量。</p>
<pre><code class="language-python">import torch

# 创建一个张量
tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])

# 使用 torch.numel() 计算张量中的元素总数
num_elements = tensor.numel()

print(num_elements)  # 输出：6
</code></pre>
<p><strong>注意事项</strong></p>
<ul>
<li><code>torch.numel()</code> 是张量的一个方法，而不是一个独立的函数。因此，你需要先有一个张量对象，然后才能调用这个方法。</li>
<li><code>torch.numel()</code> 返回一个整数，表示张量中的元素总数。</li>
<li>与 <code>torch.size()</code> 或 <code>tensor.shape</code> 不同，<code>torch.numel()</code> 返回的是张量中所有维度的元素总数，而不是各维度的大小。例如，对于一个形状为 <code>[a, b, c]</code> 的三维张量，<code>torch.numel()</code> 将返回 <code>a * b * c</code>。</li>
</ul>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
