<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled</title>
    <meta name="description" content="Untitled - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme */
            --primary-color: #2980b9;
            --primary-hover: #1a5276;
            --link-color: #c0392b;
            --text-color: #333;
            --text-light: #666;
            --text-muted: #999;
            --bg-color: #fff;
            --bg-secondary: #f8f9fa;
            --bg-code: #f5f5f5;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px rgba(0,0,0,0.1);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#loramoe">LoRAMoE</a></li>
<li><a href="#1-背景">1. 背景</a></li>
<li><a href="#2-大规模微调导致世界知识破坏">2. 大规模微调导致世界知识破坏</a><ul>
<li><a href="#21-实验设计">2.1 实验设计</a></li>
<li><a href="#22-实验结果">2.2 实验结果</a></li>
</ul>
</li>
<li><a href="#3-loramoe方法">3. LoRAMoE方法</a><ul>
<li><a href="#31-moe简介">3.1 MoE简介</a></li>
<li><a href="#32-lora简介">3.2 LoRA简介</a></li>
<li><a href="#33-loramoe">3.3 LoRA+MoE</a></li>
<li><a href="#34-专家平衡约束">3.4 专家平衡约束</a></li>
<li><a href="#35-实验">3.5 实验</a></li>
</ul>
</li>
<li><a href="#references">References</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>Untitled</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-01-28</span>
                        <span><i class="fas fa-folder"></i> AINotes/14.PEFT/01.LoRA/10.LoRAMoE</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="loramoe">LoRAMoE<a class="anchor-link" href="#loramoe" title="Permanent link">&para;</a></h2>
<h2 id="1-背景">1. 背景<a class="anchor-link" href="#1-背景" title="Permanent link">&para;</a></h2>
<p>大模型经过大量语料的无监督预训练后，得到所谓的基座模型，这时候通常还不能很好地完成下游任务，需要经过有监督的微调（SFT）后才能和人类指令对齐，释放其全部潜力。</p>
<p>一般来说，SFT的训练数据不需要太多，但当下游任务增多或者需要强化特定任务的性能时，增加SFT训练数据还是有必要的。如下图的左侧部分，当SFT数据从100K提升到3M时，大部分任务的性能显著增强。</p>
<p>但随着SFT数据的大规模增加，新的问题出现了：如下图的右侧部分所示，在某些评测数据集上性能显著下降，与之相伴的是大模型的参数变化量剧增（见红色线段）。这些数据集属于闭卷问答任务（Closed-Book Question Answering，简称CBQA），即只给大模型输入问题，大模型主要依靠在预训练过程中习得的世界知识来给出答案。</p>
<p>这里补充一下：像TriviaQA、Natural Questions这类数据其实是包含问题相关上下文的，也就是说如果用作开卷问答任务，则输入不仅包括问题还包括上下文，大模型可以从上下文中总结出答案；但如果用作闭卷问答任务，则输入中不提供上下文。论文[2]中6.1节有提到。  </p>
<p>我们有理由怀疑CBQA的性能下降与大模型世界知识的崩溃有关，下面将通过实验证明这一点。首先验证CBQA的推理依赖大模型的世界知识，其次证明CBQA数据集上性能的大幅下降归因于大规模微调会显着改变模型参数，导致世界知识的破坏，即发生知识遗忘。</p>
<h2 id="2-大规模微调导致世界知识破坏">2. 大规模微调导致世界知识破坏<a class="anchor-link" href="#2-大规模微调导致世界知识破坏" title="Permanent link">&para;</a></h2>
<p>下面详细介绍一下实验过程，即做实验证明大规模SFT导致大模型的世界知识严重受损，引起知识遗忘。</p>
<h3 id="21-实验设计">2.1 实验设计<a class="anchor-link" href="#21-实验设计" title="Permanent link">&para;</a></h3>
<p><strong>数据集</strong></p>
<p>准备了7种任务的数据集，分别是CBQA（闭卷问答）、coreference resolution（指代消解）、NLI（自然语言推理）、summarization（文本摘要）、multi-lingual translation（多语言翻译）、reading comprehension（阅读理解）、text classification（文本分类）。具体数据集见下图：  </p>
<p><strong>基座模型</strong></p>
<p>采用LLaMA-2-7B作为基座模型，属于在学术界非常流行的LLM之一。</p>
<p><strong>评估</strong></p>
<p>将任务分为两类：CBQA数据集用于评估模型的世界知识，前人工作发现CBQA数据集中有train-test重叠，因此做了过滤，只用未重叠的test集，命名为Filtered TriviaQA和Filtered NQ这种；其他的下游任务用opencompass[3]框架来评测。</p>
<h3 id="22-实验结果">2.2 实验结果<a class="anchor-link" href="#22-实验结果" title="Permanent link">&para;</a></h3>
<p>用前面说的7种任务的混合数据集微调大模型，数据规模逐渐增加，然后看不同下游任务的性能表现。如下图所示，像左侧的摘要、NLI、机器翻译这类任务，随着SFT训练数据的增加，性能显著提升；但是右侧的CBQA任务，却出现断崖式下跌。</p>
<p>我们已经高度怀疑CBQA的性能下降是由于大模型的世界知识崩坏引起的，为了更加确信，接下来我们仔细实验一下CBQA和大模型的世界知识到底有什么关系，具体做法是单独拿CBQA的25万条样本训练大模型，然后看大模型在未重叠的测试集上的表现。</p>
<p>如下图所示，在训练一开始大约1000样本的时候，性能已经快速提升到了很高的点，后续再增加更多的训练样本其实提升很有限。说明少量样本微调就帮助大模型完成了人类指令的对齐，大模型完成CBQA指标评测的能力主要依靠的是内在的世界知识，而不是微调过程中训练样本灌输的。因此我们更加确性CBQA指标高度依赖大模型在预训练过程中学到的世界知识，上图中CBQA的性能下降的原因就是世界知识的破坏。</p>
<p>再进一步实验，证明是大规模的微调导致了世界知识受损。具体做法如下表：第三列仅用CBQA训练数据微调，是可以CBQA测试集上打败Baseline的；而第四列是分两阶段，先用300万不包换CBQA的数据微调，然后再用和第三列同样的CBQA数据继续微调，结果在CBQA测试集上的表现比Baseline都差很远。</p>
<p>对比一下第三列和第四列，差别只在后者多了一个第一阶段300万数据的微调，说明它正是大模型世界知识崩塌的罪魁祸首，第二阶段即便加上CBQA训练数据，也无法弥补回来。同时发现大模型的参数发生了巨大变化，正好和前面结论相互佐证。</p>
<h2 id="3-loramoe方法">3. LoRAMoE方法<a class="anchor-link" href="#3-loramoe方法" title="Permanent link">&para;</a></h2>
<p>前面的实验表明，有些下游任务需要SFT的训练数据越多越好，即LLM的参数改变越大越好，而有些下游任务需要尽可能保留世界知识，即参数变化越小越好。这种冲突对于一般的全参微调或者LoRA微调都是搞不定的。论文[1]引入了MoE的思想来解决，实现LoRA微调的自适应。题外话，MoE在搜广推领域早就烂大街，这里又用到了LLM微调领域，说明技术都是相通的。</p>
<p>下面先分别介绍一下MoE和LoRA，然后看如何结合。</p>
<h3 id="31-moe简介">3.1 MoE简介<a class="anchor-link" href="#31-moe简介" title="Permanent link">&para;</a></h3>
<p>MoE全称Mixture of Experts，意味着有多个专家网络投票共同输出结果，只不过每个专家根据输入不同，分配不同的权重。我们可以想象成不同的专家具备不同领域的能力，然后根据输入的特征，给更匹配的专家分配更高的权重，从而动态组合专家输出。</p>
<p>MoE本身是一种思想，需要结合具体模型设计。对于transformer形式的网络，MoE可以将每个block中的前馈网改造成N个结构相同的前馈网 <span class="math-inline">{E_i}_{i=1}^N</span> 作为专家，然后再配合上门控函数 <span class="math-inline">G(\cdot)</span> 作为路由，即根据输入给不同的专家分配不同的权重。具体为：</p>
<p><span class="math-inline">y=\sum_{i=1}^N G(h)_iE_i(h)\</span></p>
<p>其中， <span class="math-inline">h</span> 为block中attention层的输出，同时作为MoE层的输入，<span class="math-inline">y</span> 为MoE层的输出，<span class="math-inline">E_i(h)</span> 为第 <span class="math-inline">i</span> 个专家的输出，<span class="math-inline">G(h)_i</span> 为第 <span class="math-inline">i</span> 个专家输出对应的权重。门控函数 <span class="math-inline">G(\cdot)</span> 具体为：</p>
<p><span class="math-inline">G(h)=Softmax(hW_g)\</span> <span class="math-inline">W_g</span> 为可训练的参数矩阵。</p>
<h3 id="32-lora简介">3.2 LoRA简介<a class="anchor-link" href="#32-lora简介" title="Permanent link">&para;</a></h3>
<p>如果大家对推荐系统中的SVD算法了解的话，LoRA的原理就非常简单了，无非用两个低秩矩阵相乘来拟合一个高秩矩阵，只不过这里拟合的不是模型的参数矩阵 <span class="math-inline">W_0\in\mathbb R^{d_{out}\times d_{in}}</span> 本身，而是参数矩阵的增量 <span class="math-inline">\Delta W</span>，即更新后的参数矩阵变为： <span class="math-inline"> W=W_0+\Delta W=W_0+BA\</span></p>
<p>其中 <span class="math-inline">B\in\mathbb R^{d_{out}\times r},A\in\mathbb R^{r\times d_{in}}</span>，且 <span class="math-inline">r\ll\min(d_{in},d_{out})</span>，这样微调过程中我们只需存储两个低秩的 <span class="math-inline">A</span> 和 <span class="math-inline">B</span> 矩阵即可，大幅减少存储空间。</p>
<p>按照LoRA的原始论文[4]，<span class="math-inline">A</span> 用高斯初始化，<span class="math-inline">B</span> 用全零初始化，且会增加一个缩放系数 <span class="math-inline">\alpha/r</span>，<span class="math-inline">\alpha</span> 为超参数，输入为 <span class="math-inline">x\in\mathbb R^{d_{in}}</span>，输出为 <span class="math-inline">h\in\mathbb R^{d_{out}}</span>，具体为：</p>
<p><span class="math-inline"> h=W_0x+\Delta Wx=W_0x+\frac{\alpha}{r}BAx\</span></p>
<p>训练过程中，固定 <span class="math-inline">W_0</span> 不变，<span class="math-inline">B</span> 用全零初始化可以保证在初始化阶段 <span class="math-inline">\Delta W=0</span>，调整 <span class="math-inline">\alpha</span> 相当于调整学习率，且我们在实验中可能经常会调整参数 <span class="math-inline">r</span>，这里缩放系数中除以 <span class="math-inline">r</span> 能减少超参数的调整。</p>
<p>论文[4]中对缩放系数的作用只是很简略的说了一段，令人摸不着头脑。对此我自己做了推导和调研，发现原生的缩放因子并未最佳选择，因和本文主旨无关，后续单独作文述之。</p>
<h3 id="33-loramoe">3.3 LoRA+MoE<a class="anchor-link" href="#33-loramoe" title="Permanent link">&para;</a></h3>
<p>我们结合LoRA和MoE的优点，将二者组合起来，便是LoRAMoE，看下图所示：</p>
<p>具体做法就是冻结已经预训练好的LLM，然后在FFN层中的每个线性层增加了一组LoRA适配器作为专家网络组，并通过门控网络（路由器机制）分配权重，公式为：</p>
<p><span class="math-inline"> o=W_0x+\frac{\alpha}{r}\sum_{i=1}^NG(x)_iB_iA_ix\</span></p>
<p>其中，<span class="math-inline">o</span> 为线性层的输出，<span class="math-inline">x</span> 为线性层的输入，<span class="math-inline">W_0</span> 为线性层的预训练好的参数（被冻结），<span class="math-inline">G(x)</span> 为门控函数，即 <span class="math-inline">G(x)=Softmax(xW_g)</span>，共 <span class="math-inline">N</span> 个专家网络。其余变量含义和前面介绍的LoRA完全类似，不再重复。修改后的线性层称之为LoRAMoE层。</p>
<p>对照公式我们再回看上面的图4，只能说图中的LoRAMoE部分是个示意图，意会即可。</p>
<h3 id="34-专家平衡约束">3.4 专家平衡约束<a class="anchor-link" href="#34-专家平衡约束" title="Permanent link">&para;</a></h3>
<p>如果不加任何约束微调MoE，经常会出现门控函数收敛到一种状态，即少数专家掌握了话语权，其他专家权重非常小，失去了平衡。</p>
<p>LoRAMoE人为地将专家分为两组，一组专注于学习下游任务，另一组专注于将世界知识和人类指令对齐。</p>
<p>形式上，我们先给每个LoRAMoE层定义一个重要性矩阵 <span class="math-inline">Q</span>，每个元素 <span class="math-inline">Q_{nm}</span> 表示一个batch中第 <span class="math-inline">m</span> 个样本在第 <span class="math-inline">n</span> 个专家上的重要度，论文[1]中给出一个公式(13)来计算 <span class="math-inline">Q_{nm}</span>，但公式明显有误，我只能按我的猜测重新给出一个： <span class="math-inline"> \omega_n^m=\sum_{j=1}^{T_m}G(x_j^m)_n\</span></p>
<p><span class="math-inline"> Q_{nm}=\frac{\exp(\omega_n^m/\tau)}{\sum_{k=1}^N\exp(\omega_k^m/\tau)}\</span></p>
<p>其中，<span class="math-inline">T_m</span> 表示第 <span class="math-inline">m</span> 个训练样本的token数，<span class="math-inline">x_j^m</span> 表示该样本第 <span class="math-inline">j</span> 个token的输入向量，<span class="math-inline">\omega_n^m</span> 为该样本所有token在第 <span class="math-inline">n</span> 个专家上的路由器权重之和，然后在所有专家上做个softmax归一化得到 <span class="math-inline">Q_{nm}</span>，<span class="math-inline">\tau</span> 为温度超参数。</p>
<p>然后再给 <span class="math-inline">Q</span> 配上一个相同尺寸的重要性系数矩阵 <span class="math-inline">I</span>，定义为：</p>
<p><span class="math-inline"> I_{nm}=\begin{cases} 1+\delta,\quad \text{Type}_e(n)=\text{Type}_s(m)\ 1-\delta,\quad \text{Type}_e(n)\ne\text{Type}_s(m) \end{cases}\</span></p>
<p>其中，<span class="math-inline">\delta\in[0,1]</span> 控制专家之间的平衡度。前面所讲，我们将专家人为分了两组，样本也可分为同样的两组，<span class="math-inline">\text{Type}_e(n)</span> 表示专家 <span class="math-inline">n</span> 的分组，<span class="math-inline">\text{Type}_s(m)</span> 表示样本 <span class="math-inline">m</span> 的分组。</p>
<p>我们真正使用的是加权版的重要性矩阵 <span class="math-inline">Z=I\circ Q</span>，即如果专家和样本分组一致，就在重要性分数 <span class="math-inline">Q_{nm}</span> 上乘上一个大于1的权重，否则乘上一个小于1的权重，目的是放大重要性分数之间的差距。然后构建一个损失函数如下，作为整体损失函数的一部分：</p>
<p><span class="math-inline"> \mathcal L_{lbc}=\frac{\sigma^2(Z)}{\mu(Z)}\</span></p>
<p>分子分母分别为方差和均值。通过这个损失函数就能够抑制专家强者恒强的现象。</p>
<p>整体损失函数为LLM的损失 <span class="math-inline">\mathcal L</span> 加上所有层的 <span class="math-inline">\mathcal L_{lbc}</span> 之和，后者有个 <span class="math-inline">\beta</span> 权重： <span class="math-inline"> \mathcal L_{total}=\mathcal L+\beta \mathcal L_{lbc}^{all}\</span></p>
<h3 id="35-实验">3.5 实验<a class="anchor-link" href="#35-实验" title="Permanent link">&para;</a></h3>
<p><strong>实验参数</strong>：</p>
<p>LoRAMoE层只替换LLM中FFN的线性层，且每个LoRAMoE层的专家数为6，其中3个用于下游任务，另外3个用于对齐世界知识。</p>
<p>超参 <span class="math-inline">\beta=\delta=0.1</span>，<span class="math-inline">\alpha=32</span>，<span class="math-inline">r=4</span>，dropout为0.05，学习率为2e-4，batch size为64。</p>
<p>300万的训练样本，在32张A100上训练。</p>
<p><strong>实验结果</strong>：  </p>
<p>可以看到，相比于全量微调或者传统的LoRA，本文的方法都取得明显提升，世界知识的遗忘问题也不再发生。详细结论不再细表，总之，LoRA结合上MoE的路由功能，让LoRA的参数增量不再是静态的死板一块，而是可以根据不同任务的输入来动态生成，有效解决了SFT大量训练数据和世界知识遗忘的冲突。</p>
<h2 id="references">References<a class="anchor-link" href="#references" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/685580458">LoRA遇上MoE，大模型再也不会健忘了</a></li>
</ul>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
