<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled</title>
    <meta name="description" content="Untitled - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme - 明亮清新配色 */
            --primary-color: #4A90D9;
            --primary-hover: #3678C2;
            --link-color: #E86B5F;
            --text-color: #2D2D2D;
            --text-light: #5A5A5A;
            --text-muted: #8A8A8A;
            --bg-color: #FFFFFF;
            --bg-secondary: #F5F7FA;
            --bg-code: #F8F9FC;
            --border-color: #E8ECF0;
            --shadow: 0 2px 8px rgba(0,0,0,0.06);
            --shadow-lg: 0 8px 24px rgba(0,0,0,0.08);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#boosting-continual-learning-of-vision-language-models-via-mixture-of-experts-adapters">Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters</a></li>
<li><a href="#0-摘要">0. 摘要</a></li>
<li><a href="#1-引言">1. 引言</a></li>
<li><a href="#2-相关工作">2. 相关工作</a><ul>
<li><a href="#21-连续学习">2.1. 连续学习</a></li>
<li><a href="#22-参数高效微调">2.2. 参数高效微调</a></li>
<li><a href="#23-专家混合">2.3. 专家混合</a></li>
</ul>
</li>
<li><a href="#3-方法论">3. 方法论</a><ul>
<li><a href="#31-连续学习">3.1. 连续学习</a></li>
<li><a href="#32-框架概述">3.2. 框架概述</a></li>
<li><a href="#33-增量混合专家适配器">3.3. 增量混合专家适配器</a></li>
<li><a href="#34-分布判别式自动选择器">3.4. 分布判别式自动选择器</a></li>
</ul>
</li>
<li><a href="#4-实验">4. 实验</a><ul>
<li><a href="#41-实验设置">4.1. 实验设置</a></li>
<li><a href="#42-与最先进方法的比较">4.2. 与最先进方法的比较</a></li>
<li><a href="#43-消融研究">4.3. 消融研究</a></li>
</ul>
</li>
<li><a href="#5-讨论">5. 讨论</a></li>
<li><a href="#a-更多实现细节">A. 更多实现细节</a></li>
<li><a href="#b-数据集大小对专家数量的影响">B. 数据集大小对专家数量的影响</a></li>
<li><a href="#c-ddas-中阈值和不同损失的影响分析">C. DDAS 中阈值和不同损失的影响分析</a></li>
<li><a href="#d-mtil-上更多比较结果">D. MTIL 上更多比较结果</a></li>
<li><a href="#e-moeadapters-中路由器选择的有效性">E. MoEAdapters 中路由器选择的有效性</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>Untitled</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-02-04</span>
                        <span><i class="fas fa-folder"></i> AINotes/43.多模态增量学习MMCL</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="boosting-continual-learning-of-vision-language-models-via-mixture-of-experts-adapters"><a href="http://arxiv.org/abs/2403.11549">Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters</a><a class="anchor-link" href="#boosting-continual-learning-of-vision-language-models-via-mixture-of-experts-adapters" title="Permanent link">&para;</a></h2>
<h2 id="0-摘要">0. 摘要<a class="anchor-link" href="#0-摘要" title="Permanent link">&para;</a></h2>
<p>连续学习可以使视觉 - 语言模型不断地获取新知识，无需访问整个历史数据集。然而，由于（i）终身学习过程中参数的偏移和（ii）与全模型调整相关的重大计算负担，减轻大规模模型中的性能退化并非易事。在这项工作中，我们提出了一个参数高效的持续学习框架，以缓解增量学习中视觉 - 语言模型的长期遗忘问题。我们的方法涉及通过集成 Mixture-of-Experts (MoE) 适配器来响应新任务，动态扩展预训练的 CLIP 模型。为了保持视觉 - 语言模型的零样本识别能力，我们进一步引入了一个分布判别式自动选择器（Distribution Discriminative Auto-Selector, DDAS），它自动将分布内和分布外的输入路由到 MoE 适配器和原始 CLIP。通过在各种设置中进行广泛的实验，我们提出的方法在降低参数训练负担 60% 的同时，始终优于以前的最先进方法。我们的代码位于 https://github.com/JiazuoYu/MoEAdapters4CL。</p>
<h2 id="1-引言">1. 引言<a class="anchor-link" href="#1-引言" title="Permanent link">&para;</a></h2>
<p>人工智能（AI），特别是在大规模基础模型领域，已经在理解开放世界方面取得了显著进展，这一点从最近的进展中可以看出 [43, 44, 55, 60, 66]。一个理想的 AI，类似于人类认知，应该能够从动态环境中持续吸收新知识。传统的全监督训练范式由于将新数据与历史数据集整合的高计算成本而无法适应这一场景。相比之下，连续学习（Continual Learning, CL）提供了一种高效的增量训练策略，通过在每个训练阶段关注新数据而出现。然而，CL 面临着“灾难性遗忘”的重大障碍，即模型在学习新任务时失去了先前获得的知识 [24, 51]。</p>
<p>为了解决这个问题，当前 CL 方法 [1, 16, 23, 42] 中流行的解决方案之一是开发动态扩展框架，通过向共享基础模型增量添加特定任务的组件（见图 1（a））。尽管这些方法在记忆和可扩展性方面显示出前景，但它们无法区分未见数据，因此忽视了零样本转移能力。最近的进展，如 ZSCL[78]，通过利用预训练的视觉 - 语言模型（Vision Language Model, VLM），将零样本转移能力引入了连续学习。如图 1（b）所示，这种方法依赖于知识蒸馏，从冻结的 CLIP 中整合零样本泛化能力，并使用参数正则化来防止连续学习中的知识退化。然而，这些设计通常涉及大量的计算负担，并在长期记忆方面表现出局限性。那么，我们是否能够结合预训练基础模型和动态扩展策略的优势，形成一个具有强大记忆和零样本转移能力的系统呢？</p>
<p>最近，参数高效微调（Parameter-Efficient Fine-Tune, PEFT）方法 [22, 28, 65, 73, 76] 已经证明，大型模型可以通过仅微调参数较少的适配器快速适应下游任务。这启发我们构建一个具有任务特定适配器的 VLM 动态扩展框架，以减轻长期 CL 中的参数负担。然而，在增量学习中直观地堆叠适配器的方法引入了对任务身份的依赖。这在实际场景中，如类别增量学习中，任务身份可能不可用时，带来了挑战。此外，使用独立适配器忽略了任务间知识共享和协作的潜力，导致有限的表示能力和效率。</p>
<p>为了克服上述挑战，我们提出了一个参数高效的连续学习框架，利用多任务学习领域的最新进展，即专家混合（Mixture-of-Experts, MoE）[31, 63]。我们在冻结的 CLIP 模型 [60] 上构建了一个动态扩展架构，称为增量 MoE-Adapters，其中我们将适配器作为稀疏专家，并使用逐步集成的任务特定路由器来选择相应的专家。在连续学习过程中，我们进一步应用了一种新颖的激活 - 冻结策略，以帮助专家学习任务内知识并鼓励任务间协作。此外，提出了一个分布判别式自动选择器（Distribution Discriminative Auto-Selector, DDAS），以自动分配测试数据到 MoE-Adapters 或预训练的 CLIP，实现对已见数据的有效预测和对未见数据的零样本转移，所有这些都在一个统一的框架内完成。</p>
<p>我们通过各种设置的广泛实验，证明了所提方法在解决灾难性遗忘问题方面的有效性，显著降低了 60% 的参数负担和内存需求。此外，当应用于少样本连续学习时，所提出的模型显示出卓越的抗遗忘能力，并在 5 次拍摄设置中通过 3.6%、7.0% 和 4.2% 的优势超越了先前的艺术。我们的贡献可以总结如下：</p>
<ul>
<li>我们引入了一个参数高效的训练框架，用于视觉 - 语言模型的连续学习，采用基于 MoE-Adapters 的动态扩展架构，以增强适应性和效率。</li>
<li>我们在 MoE 框架中开发了一个增量激活 - 冻结策略，使专家能够同时获得任务内知识和参与任务间协作。</li>
<li>我们设计了一个分布判别式自动选择器（DDAS），用于自动子流分配，有效地将抗遗忘和零样本转移能力合并到一个统一的模型中。</li>
</ul>
<h2 id="2-相关工作">2. 相关工作<a class="anchor-link" href="#2-相关工作" title="Permanent link">&para;</a></h2>
<h3 id="21-连续学习">2.1. 连续学习<a class="anchor-link" href="#21-连续学习" title="Permanent link">&para;</a></h3>
<p>根据增量数据的领域变化，现有的连续学习方法主要关注解决即类别增量学习（Class Incremental Learning, CIL）[3, 12, 33, 45, 70] 和任务增量学习（Task Incremental Learning, TIL）[50, 56, 78]。在这一领域已经做出了各种努力，开发了不同的架构 [11]，包括基于记忆的、基于正则化的和基于动态的模型。基于记忆的方法 [30, 40, 47, 57, 59, 61, 64] 通过将历史知识存储在记忆库中来保留历史知识，这将在增量学习中被访问和更新。然而，不断增长的学习数据通常会对记忆库造成负担，导致有限的终身学习能力。基于正则化的方法在权重 [2, 36, 41, 74] 或数据 [14, 18, 26, 42] 上添加显式的正则化项，以平衡旧任务和新任务之间的关系。它们通常用作基于记忆或动态模型的辅助技巧，以减轻遗忘问题。动态方法 [1, 19, 29, 70-72] 通过在基线上逐步添加新参数来解决连续学习，例如神经元、分支或预测头。动态方法通常比其他两个流程表现更好。然而，像基于记忆的方法一样，动态架构通常会带来大规模的模型尺寸，限制了模型的效率。尽管上述方法表现出了希望，但解决 AI 代理的关键能力，即对未见知识的零样本转移，仍然是一个挑战，并且难以整合到现有的流行流程中。在本文中，我们提出了将动态架构整合到视觉 - 语言模型中，以增强其对历史知识的记忆力，并减轻零样本转移能力的退化。与之高度相关的工作是 ZSCL[78]，它在大规模模型的连续学习中使用了参数正则化。与 ZSCL 中的全微调策略相比，我们的方法提出了增量 MoE 适配器，以减少调整的参数数量并增强历史学习适配器和正在进行的适配器之间的协作。</p>
<h3 id="22-参数高效微调">2.2. 参数高效微调<a class="anchor-link" href="#22-参数高效微调" title="Permanent link">&para;</a></h3>
<p>在自然语言处理（NLP）领域，对大型模型（例如，175B GPT-3[5]）进行微调在参数复杂性和时间消耗方面都带来了显著的负担。因此，探索了一些参数高效的微调方法 [27, 28, 32, 35, 75]，这些方法只设置了少量可训练参数并对它们进行微调以提高效率。在这些方法中，LoRA[28] 和 Compacter[35] 通过附加低秩超复数适配器层或在层之间共享适配器参数来减少可训练参数的数量。在 NLP 中高效调整策略的成功促进了它们在视觉 - 语言模型 [22, 34, 65, 76, 79] 如 CLIP[22] 上的应用。最近，Liu 等人 [45] 在 CLIP 的连续学习中引入了高效的调整策略，该策略使用可训练的适配器和参数保留策略分别适应下游任务和记忆历史知识。然而，这种方法仅应用于 CIL，并忽略了原始 CLIP 的零样本能力。在本文中，我们提出了一种新的参数高效调整方法，用于 CLIP，以增强连续学习中的抗遗忘和零样本能力。我们的模型可以灵活地适应 CIL 和 TIL，并在仅有少量数据训练的情况下（即少样本连续学习）实现出色的性能。</p>
<h3 id="23-专家混合">2.3. 专家混合<a class="anchor-link" href="#23-专家混合" title="Permanent link">&para;</a></h3>
<p>MoE[31] 包含多个专家和一个路由网络。它通过路由网络的加权策略聚合专家输出。基于 MoE[63] 的稀疏架构，一些方法 [10, 20, 53, 62] 被提出以减少计算成本并提高模型容量。这种技术也被引入到连续学习中以减轻遗忘问题。例如，Aljundi 等人 [1] 提出训练多个作为专家的主干，并自动将测试样本馈送到相关专家。Chen 等人 [7] 利用预训练的专家和门来存储先前的知识。这些方法已经展示了 MoE 在连续学习中的有希望的性能。我们提出了一个用于连续学习的增量 MoE-Adapters。我们使用适配器作为专家以增加适应速度，并引入了一种增量专家交互策略，以促进连续学习期间专家之间的协作。</p>
<h2 id="3-方法论">3. 方法论<a class="anchor-link" href="#3-方法论" title="Permanent link">&para;</a></h2>
<h3 id="31-连续学习">3.1. 连续学习<a class="anchor-link" href="#31-连续学习" title="Permanent link">&para;</a></h3>
<p>给定一组 <span class="math-inline">T</span> 任务 <span class="math-inline">{T_t}<em>{t=1}^T</span>，连续学习通过顺序访问和学习每个任务 <span class="math-inline">T_t = {d^t, C_t}</span> 来工作。这里，<span class="math-inline">d^t = {I_i^t, y</em>{ti}}<em>{i=1}^{N_t}</span> 表示第 <span class="math-inline">t</span> 个任务 <span class="math-inline">T_t</span> 的数据，其中 <span class="math-inline">I_i^t</span> 是输入图像，<span class="math-inline">y</em>{ti} \in C_t</span> 是相应的类别标签，<span class="math-inline">N_t</span> 是数据的大小。类别集合 <span class="math-inline">C_t = {c^{t}<em>{j}}</em>{j=1}^{M_t}</span> 包括 <span class="math-inline">T_t</span> 中的类名，共有 <span class="math-inline">M_t</span> 个类别。连续学习的目标是在所有任务上实现良好的性能，并且可以广泛地分类为任务增量学习（Task Incremental Learning, TIL）和类别增量学习（Class Incremental Learning, CIL）。在 TIL 中，模型在任务特定集合 <span class="math-inline">C_t</span> 内生成预测，这由当前任务身份 <span class="math-inline">t</span> 决定。同时，在 CIL 中，挑战包括区分所有以前遇到的类别 <span class="math-inline">\cup_{i=1}^t C_i</span>。</p>
<h3 id="32-框架概述">3.2. 框架概述<a class="anchor-link" href="#32-框架概述" title="Permanent link">&para;</a></h3>
<p>在本文中，我们提出了一个参数高效的框架，旨在增强视觉 - 语言模型的连续学习能力，实现对历史知识的稳健记忆，同时不牺牲零样本泛化能力。我们的方法基于 CLIP[22] 模型构建，该模型包含并行编码器 <span class="math-inline">(\mathcal{F}<em>I,\mathcal{F}_T)</span> 分别提取输入图像和文本的特征。按照 CLIP[22] 的做法，我们基于最终图像嵌入 <span class="math-inline">\mathcal{F}_I(I_i^t)</span> 和文本嵌入 <span class="math-inline">\mathcal{F}_T(c^{t}</em>{j})</span> 之间的余弦相似度进行预测。然后，输入图像被分配给相似度最高的类别。我们方法的整体框架如图 2 所示。我们在冻结的 CLIP 上引入 MoE 结构，以将所有下游任务整合到一个统一的模型中，其中任务依赖的路由器顺序添加以调节每个任务的专家。适配器模块，如 LoRA[28]，作为 MoE 设置中的专家，提高了训练期间的适应速度。为了减轻 MoE 对任务身份的依赖，我们进一步提出了一个分布判别式自动选择器（Distribution Discriminative Auto-Selector, DDAS）。DDAS 通过分析目标图像分布的变化自动推断任务上下文。因此，分布内数据将被分配到 MoE 中的相应路由器，而分布外输入将被识别并引导到原始 CLIP 以执行零样本识别。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241204100033.png" style="zoom: 80%;" /></div>

<h3 id="33-增量混合专家适配器">3.3. 增量混合专家适配器<a class="anchor-link" href="#33-增量混合专家适配器" title="Permanent link">&para;</a></h3>
<p>我们利用 MoE[63] 构建了一个可扩展的架构，以缓解 CLIP 连续学习中的“灾难性遗忘”问题。MoE 由几个专家 <span class="math-inline">{E_i}_{i=1}^{N_E}</span> 和路由器组成，其中 <span class="math-inline">N_E</span> 是预定义的专家数量。对于当前任务 <span class="math-inline">T_t</span>，只添加了一个任务特定的路由器 <span class="math-inline">\mathcal{R}^t</span>，它通过门控平均值整合专家的输出。适配器作为专家。视觉 - 语言模型中的 MoE 通常将专家内置于网络中，这些可以是 MLP 或注意力头 [8, 63, 77]。然而，将 MoE 内置于 VLM 可能会因全参数调整而带来显著的计算负担。一些方法 [22, 45] 已经证明，参数较少的适配器可以加快 VLM 在下游任务中的适应速度，并使其在连续学习中得到应用。受此启发，我们使用有效的适配器 LoRA[28]，它通过将原始的重型和冻结参数解耦到低秩可训练空间中，作为 MoE 中的专家，以加快 CLIP 的连续学习速度。</p>
<p>我们的 MoE-Adapters 在并行编码器 <span class="math-inline">(\mathcal{F}_I,\mathcal{F}_T)</span> 的所有 Transformer 块中实现，如图 2 所示。具体来说，在每个 Transformer 块中，多头注意力输出后的特征令牌 <span class="math-inline">x_t \in \mathbb{R}^{n \times d}</span> 被传递给 MoE 中的所有专家。然后，任务特定的路由器 <span class="math-inline">\mathcal{R}^t</span> 应用于通过门控求和融合专家的输出。注意，我们在图像编码器和文本编码器中实现了相同的 MoE 适配器，不共享参数。</p>
<p><strong>增量混合专家</strong>。在我们的 MoE 框架中，任务特定的路由器 <span class="math-inline">\mathcal{R}^t</span> 确定激活专家 <span class="math-inline">E_i</span> 以产生针对每个任务 <span class="math-inline">t</span> 量身定制的结果。任务的组合输出 <span class="math-inline">\textbf{\textit{y}}^t</span> 计算如下：<br />
<div class="math-display"><br />
    \textbf{\textit{y}}^t = \sum_{i=1}^{N_E}{W_i^t}\mathcal{E}<em>i(\textbf{\textit{x}}^t),<br />
</div><br />
其中 <span class="math-inline">W^t = {W_i^t}</em>{i=1}^{N_E}</span> 表示由 <span class="math-inline">\mathcal{R}^t</span> 分配的门控权重，决定每个专家的贡献。<span class="math-inline">x_t</span> 表示为任务 <span class="math-inline">t</span> 处理的令牌，<span class="math-inline">\textbf{\textit{y}}^t</span> 是 MoE-Adapters 的相应输出，与 <span class="math-inline">x_t</span> 的形状相匹配。我们通过两个关键修改来完善 MoE-Adapters 进行连续学习。与以前的方法 [10, 62] 将补丁或图像令牌输入路由器不同，我们使用初始令牌，即 [CLS] 令牌 <span class="math-inline">c_t \in \mathbb{R}^{1 \times d}</span>，以提高处理效率。然后按如下方式计算门控权重：<br />
<div class="math-display"><br />
    W^t = \text{Softmax}(\text{Topk}(\mathcal{R}^t(c_t))),<br />
</div><br />
其中 <span class="math-inline">\mathcal{R}^t</span> 将 <span class="math-inline">c_t</span> 投影到一个 1-D 向量，指示每个专家的激活可能性。Topk(·) 函数选择 k 个最相关的专家，其余设置为 <span class="math-inline">-\infty</span>。Softmax(·) 函数将这些权重归一化，以强调选定专家的贡献。</p>
<p><strong>MoE-Adapters 的训练</strong>。我们通过简单的反向传播来训练 MoE-Adapters，由增量激活 - 冻结策略协调。目标是增加专家对任务内知识的掌握，并促进任务间协作。具体来说，在旧任务训练后，我们统计其路由器输出的分布。然后，在后续任务训练中保持 Top-k 最激活的专家冻结，以保留任务特定知识。这样，面对新任务时，相应的路由器可以访问冻结的专家以利用历史任务的共享知识，并优化未冻结的专家以获取新任务的特定信息。如图 3 所示，在训练期间，路由器可以激活（a）仅未充分利用的专家，（b）未充分利用和先前学习的专家，以及（c）仅来自以前任务的学习专家。因此，这种策略允许专家协作巩固知识，类似于人脑加强和连接新信息与现有记忆的机制。</p>
<h3 id="34-分布判别式自动选择器">3.4. 分布判别式自动选择器<a class="anchor-link" href="#34-分布判别式自动选择器" title="Permanent link">&para;</a></h3>
<p>我们 MoE-Adapters 中的路由器的任务特定性质需要手动任务身份来激活适当的路由器。这种手动干预与任务增量学习（TIL）和类别增量学习（CIL）的自动化和实际性质不一致，并限制了 CLIP 模型固有的零样本泛化能力。为了解决这个限制，我们开发了分布判别式自动选择器（DDAS），它通过分析输入分布的变化自动选择适当的路由器。</p>
<p>DDAS 通过引入一系列任务特定的自编码器 <span class="math-inline">{\mathcal{F}<em>A^t}</em>{t=1}^T</span> 扩展了增量 MoE 框架，这些自编码器被训练为独立捕获任务  <span class="math-inline">{{\mathcal{T}^t}}<em>{t=1}^{T}</span> 的分布特征。用于训练自编码器的损失函数是均方误差（Mean Squared Error, MSE），定义如下：<br />
<div class="math-display"><br />
    d^t= ||\textit{\textbf{f}}^t_i - \textit{\textbf{f}}^t_o||^2,<br />
</div><br />
其中 <span class="math-inline">\textit{\textbf{f}}^t_i</span> 是从输入图像中提取的中间特征，<span class="math-inline">\textit{\textbf{f}}^t_o=\mathcal{F}_A^t(\textit{\textbf{f}}^t_i)</span> 是任务 <span class="math-inline">t</span> 的自编码器重构的特征表示。由于自编码器 <span class="math-inline">\mathcal{F}_A^t</span> 是独立地在任务 <span class="math-inline">t</span> 的数据上学习的，因此得到的重构分数 <span class="math-inline">d^t</span> 反映了输入图像属于任务的可能性，较低的分数表明更高的概率。此外，为了在连续学习期间保持 CLIP 的零样本转移能力，我们还包括了一个额外的自编码器 <span class="math-inline">\mathcal{F}^0_A</span>，它在参考数据集上训练以识别分布外数据。在学习过程完成后，DDAS 为每个输入图像计算一组分布分数 <span class="math-inline">{d^t}</em>{t=1}^T</span>。如果所有分数都超过特定阈值 <span class="math-inline">\text{Thres}</span>，则系统将输入分类为“未见数据”，并将其重定向到冻结的 CLIP 进行零样本转移。相反，低于此阈值的输入被路由到具有最低分布分数的相应路由器，确保有效且准确的任务识别。</p>
<h2 id="4-实验">4. 实验<a class="anchor-link" href="#4-实验" title="Permanent link">&para;</a></h2>
<h3 id="41-实验设置">4.1. 实验设置<a class="anchor-link" href="#41-实验设置" title="Permanent link">&para;</a></h3>
<p><strong>数据集</strong>。我们评估了我们的方法在两个任务上的表现：多域 TIL（MTIL）和 CIL。对于 MTIL，我们遵循 [78] 中提出的二阶训练协议。对于 CIL，我们遵循 [19] 在 CIFAR100[19] 和 TinyImageN_Et[70] 上进行实验。CIFAR100 的 100 个类别被划分为{10, 20, 50}子集，TinyImageN_Et 的 100 个类别被划分为{5, 10, 20}子集，以评估类别分布适应性。</p>
<p><strong>度量标准</strong>。为了评估我们的方法在 MTIL 上的表现，我们使用了 [78] 提出的度量标准，即“Transfer”、“Average”和“Last”。“Transfer”度量标准评估模型对未见数据的零样本转移能力。“Last”评估模型对历史知识的记忆能力。“Average”是一个复合度量标准，测量“Transfer”和“Last”之间的平均性能。在 CIL 中，我们遵循 [19]，计算所有子集的平均准确率（“Average”）和最后一个子集的准确率（“Last”）。</p>
<p><strong>实现细节</strong>。与 [78] 一样，我们使用 CLIP 模型和 ViT-B/16[17] 作为所有实验的骨干。我们采用 LoRA[28] 作为专家，并将总专家数 N_E 设置为 22。路由器是一个单一的 MLP，它混合了前两个门控分数的专家。在 DDAS 中，参考数据是 TinyImageN_Et[70]，full-shot和少射击的阈值分别为 0.065 和 0.06。自编码器是基于预训练的 AlexN_Et[39] 构建的，具有 MLP 和非线性层。我们使用 AdamW[48] 优化器和标签平滑 [52] 技术以获得更好的结果。对于 TIL，我们在每个任务上分别训练 1k 次full-shot和 500 次少射击。对于 DDAS，我们分别在参考数据集和增量任务上训练 1k 次和 300 次。除了参考数据集外，在连续学习期间，MoE-Adapters 和 DDAS 是联合训练的。</p>
<h3 id="42-与最先进方法的比较">4.2. 与最先进方法的比较<a class="anchor-link" href="#42-与最先进方法的比较" title="Permanent link">&para;</a></h3>
<p><strong>多域任务增量学习</strong>。表 1 展示了我们提出的方法与替代方法在 MTIL 任务中的比较。我们的方法使用了 [78] 中预定义的 Order-I，其中数据集按从左到右的顺序训练和测试，如表 1 所示。附加的 Order-II 结果在补充材料中提供。表 1 的最上面部分显示了通过零样本推理、全参数微调和参数高效微调在每个任务中独立应用 CLIP 的结果。“zero-shot”表示 CLIP 在每个任务上的零样本转移的最佳结果，而其他两行表示在每个相应任务中微调 CLIP 的最高可能结果。我们提出的方法，标记为“Ours”，在大多数任务上优于第二好的方法，分别在“Transfer”、“Average”和“Last”方面提高了 0.8%、1.3% 和 1.4%。此外，将训练迭代次数从 1k 增加到 3k，我们的方法（标记为“Ours†”）在“Average”和“Last”方面分别提高了 1.8% 和 3.8%，而在“Transfer”方面比 ZSCL[78] 下降了 0.7%。此外，与上限方法相比，我们的模型在抗遗忘和零样本转移方面的表现优于 ZSCL，显示出在抗遗忘和零样本转移方面的优势。</p>
<p><strong>少样本多域任务增量学习</strong>。我们还对少样本 MTIL 进行了实验，限制 CLIP 模型每个任务只能访问少量样本。在 5 次射击设置中，比较结果如表 2 所示，使用与表 1 相同的度量标准。我们的方法在大多数数据集上优于大多数最先进的方法，分别在“Transfer”、“Average”和“Last”方面超过了第二好的方法 3.6%、7.0% 和 4.2%。这些结果证明了所提出的增量 MoE-Adapters 在长期连续学习中解决遗忘问题的有效性，即使样本有限。此外，我们提出的 DDAS 有效地学习了数据分布判别，即使在训练样本较少的情况下。</p>
<p><strong>类别增量学习</strong>。我们进行了类别增量学习实验，以验证我们的方法在单域 CL 上的表现。与 MTIL 不同，在 CL 中输入图像的任务 ID 是未知的。因此，我们的 MoE-Adapters 仅使用一个路由器和两个专家来适应所有子集。我们的方法与最先进的方法在 CIFAR100 和 TinyImageN_Et 上的比较结果分别显示在表 3 和表 4 中。可以看出，我们提出的方法一致地优于其他竞争对手，包括动态扩展和基于 CLIP 的方法，证明了我们的 MoE-Adapters 在解决单域 CL 方面的有效性和可扩展性。计算成本。上述实验已经证明了我们的方法在 MTIL 和 CIL 中的出色表现。我们进一步比较了我们的方法与其他人在训练期间的计算成本，以证明其参数和时间效率。表 5 显示，与最先进的方法 ZSCL 相比，我们的方法在训练参数（M）、GPU 负担（MiB）和每次迭代的时间方面分别减少了约 60%、15% 和 60%。此外，我们分析了我们提出的两个组件 MoE-Adapters 和 DDAS 的效率，证明了它们在减少训练期间的显著计算负担的同时，有效地增强了 CLIP 的连续学习。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241203181031.png" style="zoom: 80%;" /></div>

<h3 id="43-消融研究">4.3. 消融研究<a class="anchor-link" href="#43-消融研究" title="Permanent link">&para;</a></h3>
<p>在本节中，我们主要分析了所提出的增量 MoE-Adapters 和 DDAS 的有效性。所有实验都在 MTIL 设置中进行。更多的分析可以在补充材料中找到。MoE-Adapters 的分析。我们对 MoE-Adapters 的不同设置进行了详细的消融研究，如表 6 所示。与零样本 CLIP 和具有一个适配器的微调版本相比，我们的 MoE-Adapters 有效地缓解了“灾难性遗忘”问题，并保留了对未见数据的零样本转移能力。在所提出的 MoE-Adapters 中，我们使用 T 个任务特定的路由器来自适应地激活预定义专家池中的 Top-k 专家。表 6 说明了几种不同的专家和路由器组合。可以看出，与使用更多专家相比，任务特定的路由器在提高抗遗忘和零样本转移能力方面贡献更大。在 MoE 的训练中，我们提出了增量激活 - 冻结策略，使先前学习的专家和未激活的专家之间可以协作，以实现更准确的预测。“Ours”和“+22E/11R w/o F”之间的比较证明了这一策略的有效性。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241203180645.png" style="zoom: 80%;" /></div>

<p><strong>专家数量分析</strong>。图 4 显示了在 MoE-Adapters 中使用的专家数量的消融研究。实验在具有 T 个任务特定路由器的 1k/3k 次迭代训练的模型上进行。图中曲线的平滑性表明我们的方法对专家数量变化的鲁棒性。可以观察到，随着专家数量的变化，三个指标保持相对稳定。如图 4（a）和（b）所示，在 1k 次迭代设置中比 3k 次迭代更稳定。这种现象是由于迭代次数的增加，导致专家选择的总体频率增加。当专家数量较少时，我们的激活 - 冻结策略可能会激活更多的未充分利用的专家并对它们进行几次训练，导致路由器在推理阶段错误地激活未完全训练的专家。波动在可接受的范围内，并且不会显著影响最终性能。</p>
<p><strong>DDAS 的分析</strong>。我们使用 DDAS 通过学习任务特定自编码器中数据分布的变化来自动区分来自已见或未见数据的输入图像。为了验证 DDAS 的有效性，我们分析了特征空间中的分布判别，结果如图 5 所示。我们采用重构特征 <span class="math-inline">\textit{\textbf{f}}^t_o</span> 并绘制了连续学习完成后的图表。可以看出，所提出的 DDAS 在full-shot和少射击 MTIL 中有效地学习了每个学习任务的判别分布。如图 5 所示，来自任务 9 的一些样本与任务 11 的样本的特征分布重叠。这是因为这些样本被 DDAS 错误分类为分布外数据，并执行了参考自编码器的特征提取。尽管不可避免地发生了错误分类，但我们的方法仍然在各种度量标准上优于最先进的方法。</p>
<h2 id="5-讨论">5. 讨论<a class="anchor-link" href="#5-讨论" title="Permanent link">&para;</a></h2>
<p>我们提出了一个参数高效的训练框架，以增强视觉 - 语言模型的连续学习能力。我们采用 MoE-Adapters 帮助 CLIP 模型高效适应并泛化所有任务。此外，我们引入了分布判别式自动选择器（DDAS），以自动将推理数据分配给 MoE-Adapters 或冻结的 CLIP。在各种设置中的广泛实验结果证明了我们的方法在分类准确性和训练效率方面优于以前的艺术。我们框架的一个限制是所提出的 DDAS 需要为所有任务预定义一个阈值来确定下游分支。随着任务数量的增长，使用单一阈值适应所有任务会带来错误。此外，将学到的知识整合以提高原始 CLIP 的零样本转移能力是未来的研究方向。</p>
<h2 id="a-更多实现细节">A. 更多实现细节<a class="anchor-link" href="#a-更多实现细节" title="Permanent link">&para;</a></h2>
<p>我们为多域任务增量学习（MTIL）基准测试设置了 64 的批量大小，为类别增量学习（CIL）基准测试设置了 128 的批量大小。学习率在<span class="math-inline">[10^{-3}, 10^{-4}]</span> 间搜索。标签平滑可以替代权重衰减的正则化，并取得更好的性能。标签平滑强度在 {0.1, 0.2}之间搜索。对于 CIL，我们将权重衰减设置为 0，标签平滑设置为 0.0。</p>
<h2 id="b-数据集大小对专家数量的影响">B. 数据集大小对专家数量的影响<a class="anchor-link" href="#b-数据集大小对专家数量的影响" title="Permanent link">&para;</a></h2>
<p>额外的消融实验旨在探索不同任务大小下的最佳专家数量，结果如表 7 所示。该表展示了在full-shot设置中数据集大小对最佳专家数量 <span class="math-inline">N_E</span> 的影响。我们注意到，通常更多的任务需要更多的专家，而简单地应用更多的专家并不总是提高准确性。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241203182219.png" style="zoom: 80%;" /></div>

<h2 id="c-ddas-中阈值和不同损失的影响分析">C. DDAS 中阈值和不同损失的影响分析<a class="anchor-link" href="#c-ddas-中阈值和不同损失的影响分析" title="Permanent link">&para;</a></h2>
<p>为了进一步分析分布判别式自动选择器（DDAS）中不同阈值（Thres）的影响，我们对不同阈值的方法（“Ours”和“Ours†”）进行了消融实验，结果如图 6 所示。阈值在 [0.06, 0.07] 范围内搜索。结果表明，我们的方法在一定阈值范围内的性能波动相对稳定。与方法“Ours†”相比，方法“Ours”在阈值变化时表现出更一致的性能。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241203182453.png" style="zoom: 80%;" /></div>

<p>此外，我们对 DDAS 的自编码器进行了不同损失函数的消融实验，结果如表 8 所示。可以看出，当使用均方误差（MSE）损失时，我们的方法取得了最佳性能。</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241203182517.png" style="zoom: 80%;" /></div>

<h2 id="d-mtil-上更多比较结果">D. MTIL 上更多比较结果<a class="anchor-link" href="#d-mtil-上更多比较结果" title="Permanent link">&para;</a></h2>
<p>MTIL 基准测试的完整结果是一个 T×T 的矩阵，其中 T 是增量任务的数量。在表 9 和 10 中，我们分别展示了在 1k 次迭代训练的“Ours”和 3k 次迭代训练的“Ours†”在 MTIL 基准测试上的完整矩阵。此外，表 11 和 12 显示了full-shot和少射击 MTIL 基准测试的 Order-II 的结果。Order-II 序列包括：StanfordCars、Food、MNIST、OxfordPet、Flowers、SUN397、Aircraft、Caltech101、DTD、EuroSAT、CIFAR100。可以看出，所提出的方法在三个度量标准上都优于最先进的方法。值得注意的是，所提出的方法的零样本转移能力接近预训练 CLIP 的上限。</p>
<h2 id="e-moeadapters-中路由器选择的有效性">E. MoEAdapters 中路由器选择的有效性<a class="anchor-link" href="#e-moeadapters-中路由器选择的有效性" title="Permanent link">&para;</a></h2>
<p>我们可视化了 MoE-Adapters 的专家为每个增量任务选择的频率，如图 7 所示。可以看出，专家的激活频率记录在 CLIP 的所有视觉 Transformer 块中，每个块有 22 个专家和 Top-k 为 2。可视化展示了我们路由器选择激活的专家的稀疏性以及特定专家和共享专家之间的协作。</p>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
