<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled</title>
    <meta name="description" content="Untitled - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme - 明亮清新配色 */
            --primary-color: #4A90D9;
            --primary-hover: #3678C2;
            --link-color: #E86B5F;
            --text-color: #2D2D2D;
            --text-light: #5A5A5A;
            --text-muted: #8A8A8A;
            --bg-color: #FFFFFF;
            --bg-secondary: #F5F7FA;
            --bg-code: #F8F9FC;
            --border-color: #E8ECF0;
            --shadow: 0 2px 8px rgba(0,0,0,0.06);
            --shadow-lg: 0 8px 24px rgba(0,0,0,0.08);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> 目录</h3>
                <div class="toc">
<ul>
<li><a href="#核心结论">核心结论</a></li>
<li><a href="#核心公式">核心公式</a></li>
<li><a href="#大模型中的scaling-law">大模型中的Scaling Law</a><ul>
<li><a href="#gpt4">GPT4</a></li>
<li><a href="#baichuan2">Baichuan2</a></li>
<li><a href="#mindllm">MindLLM</a></li>
</ul>
</li>
<li><a href="#scaling-law实操-计算效率最优">Scaling Law实操: 计算效率最优</a></li>
<li><a href="#llama-反scaling-law的大模型">LLaMA: 反Scaling Law的大模型</a></li>
<li><a href="#计算量模型和数据大小的关系推导">计算量、模型和数据大小的关系推导</a></li>
<li><a href="#参考资料">参考资料</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> 返回博客列表
                    </a>
                    <h1>Untitled</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-02-04</span>
                        <span><i class="fas fa-folder"></i> 大模型</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/667489780">解析大模型中的Scaling Law</a></p>
</blockquote>
<p>在大模型的研发中，通常会有下面一些需求：</p>
<ol>
<li>计划训练一个10B的模型，想知道至少需要多大的数据？</li>
<li>收集到了1T的数据，想知道能训练一个多大的模型？</li>
<li>老板准备1个月后开发布会，给的资源是100张A100，应该用多少数据训多大的模型效果最好？</li>
<li>老板对现在10B的模型不满意，想知道扩大到100B模型的效果能提升到多少？</li>
</ol>
<p>以上这些问题都可以基于Scaling Law的理论进行回答。本文是阅读了一系列 Scaling Law的文章后的整理和思考，包括Scaling Law的概念和推导以及反Scaling Law的场景，不当之处，欢迎指正。</p>
<h2 id="核心结论">核心结论<a class="anchor-link" href="#核心结论" title="Permanent link">&para;</a></h2>
<p>大模型的Scaling Law是OpenAI在2020年提出的概念[1]，具体如下:</p>
<ol>
<li>对于Decoder-only的模型，计算量<span class="math-inline">C</span>(Flops), 模型参数量<span class="math-inline">N</span>, 数据大小<span class="math-inline">D</span>(token数)，三者满足: <span class="math-inline">C ≈ 6ND</span> 。(推导见本文最后)</li>
<li>模型的最终性能<strong>主要与</strong>计算量<span class="math-inline">C</span>，模型参数量<span class="math-inline">N</span> 数据大小<span class="math-inline">D</span> 者相关，而与模型的具体结构(层数/深度/宽度)基本无关。</li>
</ol>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656010.jpg" />  </p>
<blockquote>
<p>固定模型的总参数量，调整层数/深度/宽度，不同模型的性能差距很小，大部分在2%以内</p>
</blockquote>
<ol start="3">
<li>对于计算量<span class="math-inline">C</span>，模型参数量<span class="math-inline">N</span> 数据大小<span class="math-inline">D</span>，当不受其他两个因素制约时，模型性能与每个因素都呈现<strong>幂律关系</strong></li>
</ol>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656011.jpg" />  </p>
<ol start="4">
<li>
<p>为了提升模型性能，模型参数量<span class="math-inline">N</span> 数据大小<span class="math-inline">D</span> 要同步放大，但模型和数据分别放大的比例还存在争议。</p>
</li>
<li>
<p>Scaling Law不仅适用于语言模型，还适用于其他模态以及跨模态的任务[4]：  </p>
</li>
</ol>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656012.jpg" />  </p>
<blockquote>
<p>这里横轴单位为PF-days: 如果每秒钟可进行<span class="math-inline">10^{15}</span> 运算，就是1 peta flops，那么一天的运算就是<span class="math-inline">10^{15} × 24 × 3600 = 8.64 × 10^{19}</span>，这个算力消耗被称为1个petaflop/s-day。</p>
</blockquote>
<h2 id="核心公式">核心公式<a class="anchor-link" href="#核心公式" title="Permanent link">&para;</a></h2>
<p><span class="math-inline">L(x) = L_{\infty} + (\frac{x_{0}}{x})^{\alpha} \</span> </p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656013.jpg" />  </p>
<ul>
<li>第一项<span class="math-inline">L_{\infty}</span> 指无法通过增加模型规模来减少的损失，可以认为是数据自身的熵（例如数据中的噪音）</li>
<li>第二项<span class="math-inline">(x_{0} / x)^{\alpha}</span> 指能通过增加计算量来减少的损失，可以认为是模型拟合的分布与实际分布之间的差。</li>
</ul>
<p>根据公式，增大<span class="math-inline">x</span>(例如计算量<span class="math-inline">C</span>)，模型整体loss下降，模型性能提升；伴随<span class="math-inline">x</span> 向于无穷大，模型能拟合数据的真实分布，让第二项逼近0，整体趋向于<span class="math-inline">L_{\infty}</span> </p>
<h2 id="大模型中的scaling-law">大模型中的Scaling Law<a class="anchor-link" href="#大模型中的scaling-law" title="Permanent link">&para;</a></h2>
<h3 id="gpt4">GPT4<a class="anchor-link" href="#gpt4" title="Permanent link">&para;</a></h3>
<p>下图是GPT4报告[5]中的Scaling Law曲线，计算量<span class="math-inline">C</span> 模型性能满足幂律关系</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656014.jpg" />  </p>
<ul>
<li>横轴是归一化之后的计算量，假设GPT4的计算量为1。基于10,000倍小的计算规模，就能预测最终GPT4的性能。</li>
<li>纵轴是"Bits for words", 这也是交叉熵的一个单位。在计算交叉熵时，如果使用以 2 为底的对数，交叉熵的单位就是 "bits per word"，与信息论中的比特（bit）概念相符。所以这个值越低，说明模型的性能越好。</li>
</ul>
<h3 id="baichuan2">Baichuan2<a class="anchor-link" href="#baichuan2" title="Permanent link">&para;</a></h3>
<p>下图是Baichuan2[6]技术报告中的Scaling Law曲线。基于10M到3B的模型在1T数据上训练的性能，可预测出最后7B模型和13B模型在2.6T数据上的性能</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656015.jpg" />  </p>
<h3 id="mindllm">MindLLM<a class="anchor-link" href="#mindllm" title="Permanent link">&para;</a></h3>
<p>下图是MindLLM[7]技术报告中的Scaling Law曲线。基于10M到500M的模型在10B数据上训练的性能，预测出最后3B模型在500B数据上的性能。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656016.jpg" />  </p>
<h2 id="scaling-law实操-计算效率最优">Scaling Law实操: 计算效率最优<a class="anchor-link" href="#scaling-law实操-计算效率最优" title="Permanent link">&para;</a></h2>
<p>根据幂律定律，模型的参数固定，无限堆数据并不能无限提升模型的性能，模型最终性能会慢慢趋向一个固定的值</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656017.jpg" /><br />
如图所示，如果模型的参数量为<span class="math-inline">10^3</span>（图中紫色的线），在数量达到<span class="math-inline">10^9</span>，模型基本收敛。所以在数据量达到<span class="math-inline">10^9</span> ，继续增加数据产生的计算量，没有同样计算量下提升模型参数量带来的收益大（<strong>计算效率更优</strong>）。根据<span class="math-inline">C=6ND</span>，可以进一步转换成模型参数与计算量的关系，即: 模型参数为<span class="math-inline">10^3</span>，在计算量为<span class="math-inline">6 \times 10^{12}</span> Flops，即<span class="math-inline">7 \times 10^{-8}</span> PF-days时基本收敛。也就是右图中紫色线的拐点。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656018.jpg" /><br />
根据Baichuan[6]的实验，在中英场景下，7B模型收敛时的算力是 <span class="math-inline">10^{23}</span> FLOPS，对应的数据量应该是 <span class="math-inline">D = \frac{10^{23}}{6<em>7</em>10^{9}} = 2.3T</span> </p>
<p>按照上面的思路，下面进行Scaling Law的实操。</p>
<p>首先准备充足的数据（例如1T），设计不同模型参数量的小模型(例如0.001B - 1B)，独立训练每个模型，每个模型都训练到基本收敛（假设数据量充足）。根据训练中不同模型的参数和数据量的组合，收集计算量与模型性能的关系。然后可以进一步获得<strong>计算效率最优</strong>时，即同样计算量下性能最好的模型规模和数据大小的组合，模型大小与计算量的关系，以及数据大小与计算量的关系。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656019.jpg" /><br />
如图所示，根据左图可以看到计算量与模型性能呈现幂律关系（可以认为数据和模型都不受限制），根据中图和右图，可以发现<span class="math-inline">N_{opt} \propto C^{a}, D_{opt} \propto C^{b}</span>，即计算效率最优时，模型的参数与计算量的幂次成线性关系，数据量的大小也与计算量的幂次成线性关系。</p>
<p>根据<span class="math-inline">C=6ND</span>，可以推算出<span class="math-inline">a+b=1</span>，但是<span class="math-inline">a,b</span> 别是多少存在分歧。</p>
<p>OpenAI[1]认为模型规模更重要，即<span class="math-inline">a=0.73, b=0.27</span>，而DeepMind在Chinchilla工作[2]和Google在PaLM工作[3]中都验证了 <span class="math-inline">a=b=0.5</span> ，即模型和数据同等重要。</p>
<p>所以假定计算量整体放大10倍，OpenAI认为模型参数更重要，模型应放大<span class="math-inline">10^{0.73}</span> (5.32)倍，数据放大 <span class="math-inline">10^{0.27}</span> (1.86)倍；后来DeepMind和Google认为模型参数量与数据同等重要，两者都应该分别放大 <span class="math-inline">10^{0.5}</span> (3.16)倍。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656020.jpg" /><br />
例如在PaLM的实验中，计算量从<span class="math-inline">1 \times 10^{21}</span> 大10倍到<span class="math-inline">1 \times 10^{22}</span>， 模型参数也提升了3.2倍，3.35B-&gt;10.7B。</p>
<p>具体最好在自己的数据上做实验来获得你场景下的<span class="math-inline">a</span> <span class="math-inline">b</span>。</p>
<h2 id="llama-反scaling-law的大模型">LLaMA: 反Scaling Law的大模型<a class="anchor-link" href="#llama-反scaling-law的大模型" title="Permanent link">&para;</a></h2>
<p>假设遵循<strong>计算效率最优</strong>来研发LLM，那么根据Scaling Law，给定模型大小，可以推算出最优的计算量，进一步根据最优计算量就能推算出需要的token数量，然后训练就行。</p>
<p>但是<strong>计算效率最优</strong>这个观点是针对<strong>训练阶段</strong>而言的，并不是<strong>推理阶段，</strong>实际应用中推理阶段效率更实用。</p>
<p>Meta在LLaMA[8]的观点是：给定模型的目标性能，并不需要用最优的计算效率在<strong>最快</strong>时间训练好模型，而应该在更大规模的数据上，训练一个相对<strong>更小</strong>模型，这样的模型在推理阶段的成本更低，尽管训练阶段的效率不是最优的（同样的算力其实能获得更优的模型，但是模型尺寸也会更大）。根据Scaling Law，10B模型只需要200B的数据，但是作者发现7B的模型性能在1T的数据后还能继续提升。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656021.jpg" /><br />
所以LLaMA工作的重点是训练一系列语言模型，通过使用更多的数据，让模型在<strong>有限推理资源下有最佳的性能</strong>。</p>
<p>具体而言，确定模型尺寸后，Scaling Law给到的只是最优的数据量，或者说是一个<strong>至少</strong>的数据量，实际在训练中观察在各个指标上的性能表现，只要还在继续增长，就可以持续增加训练数据。</p>
<p><img alt="" src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/202409241656022.jpg" />  </p>
<h2 id="计算量模型和数据大小的关系推导">计算量、模型和数据大小的关系推导<a class="anchor-link" href="#计算量模型和数据大小的关系推导" title="Permanent link">&para;</a></h2>
<p>对于Decoder-only的模型，计算量<span class="math-inline">C</span>(Flops), 模型参数量<span class="math-inline">N</span>(除去Embedding部分), 数据大小<span class="math-inline">D</span>(token数), 三者的关系为: <span class="math-inline">C ≈ 6ND</span></p>
<p>推导如下，记模型的结构为:</p>
<p>decoder层数: <span class="math-inline">l</span> </p>
<p>attention 隐层维度: <span class="math-inline">d</span> </p>
<p>attention feedforward层维度: <span class="math-inline">d_{ff}</span>， 一般来说 <span class="math-inline">d_{ff} = 4*d</span> </p>
<p>首先推导模型的参数量<span class="math-inline">N</span>（忽略embedding，norm和bias）计算如下:</p>
<p>transformer每层包括: self-attetion 和 MLP 两个部分:</p>
<p>self-attention的参数为<span class="math-inline">W_{Q}, W_{K}, W_{V}, W_{O}</span>，每个矩阵的维度均为<span class="math-inline">\mathbb{R}^{d \times d}</span>，整体参数量: <span class="math-inline">4d^{2}</span> </p>
<p>MLP的层数的参数为<span class="math-inline">W_{1} \in \mathbb{R}^{d \times d_{ff}}, W_{2} \in \mathbb{R}^{d_{ff} \times d}</span>，整体参数量: <span class="math-inline">2 * d * d_{ff} = 2 * d * 4d = 8d^2</span> </p>
<p>所以每层的参数量为: <span class="math-inline">4d^2 + 8d^2 = 12d^2</span>，全部的<span class="math-inline">l</span> 的参数量为: <span class="math-inline">12ld^{2}</span>，即<span class="math-inline">N=12ld^{2}</span></p>
<p>继续推导模型的前向推理的计算量:</p>
<blockquote>
<p>计算量的单位是FLOPs，floating point operations 对于矩阵<span class="math-inline">A \in \mathbb{R}^{m \times n}, B \in \mathbb{R}^{n \times p}</span>，<span class="math-inline">AB</span> 乘的计算量为<span class="math-inline">2mnp</span>，一次加法一次乘法。</p>
</blockquote>
<p>假设Decoder层的输入<span class="math-inline">X \in \mathbb{R}^{b \times s \times d}</span>, <span class="math-inline">b</span> batch size，<span class="math-inline">s</span> 序列长度, <span class="math-inline">d</span> 模型维度。</p>
<ul>
<li>self-attention部分的计算:</li>
</ul>
<p>输入线性层: <span class="math-inline">XW_{Q}, XW_{K}, XW_{V}</span>，计算量为:<span class="math-inline">3 * b * s * d * d * 2 = 6bsd^2</span> </p>
<p>atention计算: <span class="math-inline">QK^{T}</span>，计算量为:<span class="math-inline">2 * b * s * s * d = 2bs^2d</span> </p>
<p>socre与V的计算: <span class="math-inline">S_{attention}V</span>，计算量为: <span class="math-inline">b * 2 * s * s * d = 2bs^2d</span> </p>
<p>输出线性层: <span class="math-inline">X^{'}W_{O}</span>，计算量为: <span class="math-inline">b * 2 * s * d * d = 2bsd^2</span> </p>
<ul>
<li>MLP部分的计算</li>
</ul>
<p>升维: <span class="math-inline">XW_{1}</span>，计算量为: <span class="math-inline">b * 2 * s * d * 4d = 8bsd^2</span> </p>
<p>降维: <span class="math-inline">XW_{2}</span>，计算量为: <span class="math-inline">b * 2 * s * 4d * d = 8bsd^2</span> </p>
<p>所以整个decoder层的计算量为:<span class="math-inline">24bsd^2 + 4bs^2d</span>，全部<span class="math-inline">l</span> 为: <span class="math-inline">C_{forward} = 24lbsd^2 + 4lbs^2d</span></p>
<p>反向传播计算量是正向的2倍，所以全部的计算量为: <span class="math-inline">C = 3*C_{forward} = 72lbsd^2 + 12lbs^2d</span></p>
<p>平均每个token的计算量为 <span class="math-inline">C_{token} = \frac{C}{bs} = 72ld^2 + 12lsd = 6N(1+\frac{s}{6d}) \approx 6N</span> (<span class="math-inline">s \ll 6d</span>)</p>
<p>所以对于全部包含<span class="math-inline">D</span> token的数据集: <span class="math-inline">C = C_{token}D  \approx 6ND</span> </p>
<h2 id="参考资料">参考资料<a class="anchor-link" href="#参考资料" title="Permanent link">&para;</a></h2>
<ul>
<li>[1] <a href="https://arxiv.org/abs/2001.08361">https://arxiv.org/abs/2001.08361</a></li>
<li>[2] <a href="https://arxiv.org/abs/2203.15556">https://arxiv.org/abs/2203.15556</a></li>
<li>[3] <a href="https://arxiv.org/abs/2305.10403">https://arxiv.org/abs/2305.10403</a></li>
<li>[4] <a href="https://arxiv.org/abs/2010.14701">https://arxiv.org/abs/2010.14701</a></li>
<li>[5] <a href="https://arxiv.org/abs/2303.08774">https://arxiv.org/abs/2303.08774</a></li>
<li>[6] <a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a></li>
<li>[7] <a href="https://arxiv.org/abs/2310.15777">https://arxiv.org/abs/2310.15777</a></li>
<li>[8] <a href="https://arxiv.org/abs/2302.13971">https://arxiv.org/abs/2302.13971</a></li>
<li>[9] <a href="https://zhuanlan.zhihu.com/p/106406433">https://zhuanlan.zhihu.com/p/106406433</a></li>
<li>[10] <a href="https://www.zhihu.com/question/629230332/answer/3278779348">https://www.zhihu.com/question/629230332/answer/3278779348</a></li>
<li>[11] <a href="https://zhuanlan.zhihu.com/p/631357320">https://zhuanlan.zhihu.com/p/631357320</a></li>
<li>[12] <a href="https://zhuanlan.zhihu.com/p/624740065">https://zhuanlan.zhihu.com/p/624740065</a></li>
</ul>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> 评论</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>© 2025 Hongwei Zhao. Built with ❤️</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="切换主题">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
