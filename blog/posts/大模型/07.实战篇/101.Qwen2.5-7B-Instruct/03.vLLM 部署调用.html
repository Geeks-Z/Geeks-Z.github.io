<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>model_download.py</title>
    <meta name="description" content="model_download.py - Hongwei Zhao's Blog">
    <meta name="author" content="Hongwei Zhao">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Code Highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" id="hljs-theme-dark">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" id="hljs-theme-light" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>
        :root {
            /* Light Theme - æ˜äº®æ¸…æ–°é…è‰² */
            --primary-color: #4A90D9;
            --primary-hover: #3678C2;
            --link-color: #E86B5F;
            --text-color: #2D2D2D;
            --text-light: #5A5A5A;
            --text-muted: #8A8A8A;
            --bg-color: #FFFFFF;
            --bg-secondary: #F5F7FA;
            --bg-code: #F8F9FC;
            --border-color: #E8ECF0;
            --shadow: 0 2px 8px rgba(0,0,0,0.06);
            --shadow-lg: 0 8px 24px rgba(0,0,0,0.08);
        }

        [data-theme="dark"] {
            --primary-color: #5dade2;
            --primary-hover: #85c1e9;
            --link-color: #e74c3c;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --text-muted: #6b7280;
            --bg-color: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-code: #0f0f23;
            --border-color: #374151;
            --shadow: 0 1px 3px rgba(0,0,0,0.3);
            --shadow-lg: 0 4px 15px rgba(0,0,0,0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            transition: background-color 0.3s, color 0.3s;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--primary-hover);
            text-decoration: underline;
        }

        /* Layout */
        .page-wrapper {
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
            gap: 3rem;
        }

        /* Sidebar TOC */
        .toc-sidebar {
            width: 260px;
            flex-shrink: 0;
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }

        .toc-container {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }

        .toc-container h3 {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-container ul {
            list-style: none;
        }

        .toc-container li {
            margin-bottom: 0.5rem;
        }

        .toc-container a {
            font-size: 0.9rem;
            color: var(--text-light);
            display: block;
            padding: 0.25rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.75rem;
            transition: all 0.2s;
        }

        .toc-container a:hover,
        .toc-container a.active {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
            text-decoration: none;
        }

        .toc-container ul ul {
            margin-left: 1rem;
        }

        /* Main Content */
        .main-content {
            flex: 1;
            min-width: 0;
            max-width: 800px;
        }

        /* Header */
        .post-header {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
            margin-bottom: 1.5rem;
        }

        .back-link:hover {
            color: var(--primary-color);
            text-decoration: none;
        }

        .post-header h1 {
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-color);
        }

        .post-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-light);
        }

        .post-meta span {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .post-meta i {
            color: var(--text-muted);
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .tag {
            display: inline-block;
            font-size: 0.8rem;
            background: var(--bg-secondary);
            color: var(--text-light);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            border: 1px solid var(--border-color);
            transition: all 0.2s;
        }

        .tag:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        /* Article Content */
        .post-content {
            font-size: 1rem;
            line-height: 1.9;
        }

        .post-content h1,
        .post-content h2,
        .post-content h3,
        .post-content h4,
        .post-content h5,
        .post-content h6 {
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-weight: 600;
            line-height: 1.4;
            color: var(--text-color);
        }

        .post-content h1 { font-size: 1.875rem; }
        .post-content h2 { 
            font-size: 1.5rem; 
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        .post-content h3 { font-size: 1.25rem; }
        .post-content h4 { font-size: 1.125rem; }

        .post-content p {
            margin-bottom: 1.25rem;
        }

        .post-content ul,
        .post-content ol {
            margin: 1.25rem 0;
            padding-left: 1.5rem;
        }

        .post-content li {
            margin-bottom: 0.5rem;
        }

        .post-content blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            border-left: 4px solid var(--primary-color);
            border-radius: 0 8px 8px 0;
            color: var(--text-light);
            font-style: italic;
        }

        .post-content blockquote p:last-child {
            margin-bottom: 0;
        }

        /* Code */
        .post-content code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9em;
            background: var(--bg-code);
            padding: 0.2em 0.4em;
            border-radius: 4px;
            color: var(--link-color);
        }

        .post-content pre {
            margin: 1.5rem 0;
            padding: 1.25rem;
            background: var(--bg-code);
            border-radius: 10px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }

        .post-content pre code {
            background: none;
            padding: 0;
            color: inherit;
            font-size: 0.875rem;
            line-height: 1.6;
        }

        /* Images */
        .post-content img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: var(--shadow-lg);
        }

        /* Tables */
        .post-content table {
            width: 100%;
            margin: 1.5rem 0;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        .post-content th,
        .post-content td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            text-align: left;
        }

        .post-content th {
            background: var(--bg-secondary);
            font-weight: 600;
        }

        .post-content tr:nth-child(even) {
            background: var(--bg-secondary);
        }

        /* Math */
        .math-display {
            margin: 1.5rem 0;
            overflow-x: auto;
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 8px;
        }

        /* Anchor links */
        .anchor-link {
            opacity: 0;
            margin-left: 0.5rem;
            color: var(--text-muted);
            font-weight: 400;
            transition: opacity 0.2s;
        }

        .post-content h2:hover .anchor-link,
        .post-content h3:hover .anchor-link,
        .post-content h4:hover .anchor-link {
            opacity: 1;
        }

        /* Theme Toggle */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.25rem;
            box-shadow: var(--shadow-lg);
            transition: transform 0.2s, background 0.2s;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
            background: var(--primary-hover);
        }

        /* Comments Section */
        .comments-section {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .comments-section h3 {
            font-size: 1.25rem;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        /* Footer */
        .post-footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border-color);
            text-align: center;
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .toc-sidebar {
                display: none;
            }
            
            .page-wrapper {
                padding: 1.5rem;
            }
        }

        @media (max-width: 768px) {
            .post-header h1 {
                font-size: 1.75rem;
            }
            
            .post-meta {
                flex-direction: column;
                gap: 0.5rem;
            }
            
            .theme-toggle {
                bottom: 1rem;
                right: 1rem;
                width: 44px;
                height: 44px;
            }
        }

        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <!-- TOC Sidebar -->
        <aside class="toc-sidebar">
            <div class="toc-container">
                <h3><i class="fas fa-list"></i> ç›®å½•</h3>
                <div class="toc">
<ul>
<li><a href="#vllm-ç®€ä»‹">vLLM ç®€ä»‹</a></li>
<li><a href="#ç¯å¢ƒå‡†å¤‡">ç¯å¢ƒå‡†å¤‡</a></li>
<li><a href="#æ¨¡å‹ä¸‹è½½">æ¨¡å‹ä¸‹è½½</a></li>
<li><a href="#ä»£ç å‡†å¤‡">ä»£ç å‡†å¤‡</a><ul>
<li><a href="#pythonè„šæœ¬">Pythonè„šæœ¬</a></li>
<li><a href="#åˆ›å»ºå…¼å®¹-openai-api-æ¥å£çš„æœåŠ¡å™¨">åˆ›å»ºå…¼å®¹ OpenAI API æ¥å£çš„æœåŠ¡å™¨</a></li>
</ul>
</li>
<li><a href="#æ¨ç†é€Ÿåº¦æµ‹è¯•">æ¨ç†é€Ÿåº¦æµ‹è¯•</a></li>
</ul>
</div>

            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <article>
                <header class="post-header">
                    <a href="../../../../index.html" class="back-link">
                        <i class="fas fa-arrow-left"></i> è¿”å›åšå®¢åˆ—è¡¨
                    </a>
                    <h1>model_download.py</h1>
                    <div class="post-meta">
                        <span><i class="fas fa-calendar-alt"></i> 2026-02-04</span>
                        <span><i class="fas fa-folder"></i> å¤§æ¨¡å‹/07.å®æˆ˜ç¯‡/101.Qwen2.5-7B-Instruct</span>
                        <span><i class="fas fa-user"></i> Hongwei Zhao</span>
                    </div>
                    <div class="tags">
                        
                    </div>
                </header>

                <div class="post-content">
                    <h2 id="vllm-ç®€ä»‹">vLLM ç®€ä»‹<a class="anchor-link" href="#vllm-ç®€ä»‹" title="Permanent link">&para;</a></h2>
<p><code>vLLM</code> æ¡†æ¶æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹<strong>æ¨ç†å’Œéƒ¨ç½²æœåŠ¡ç³»ç»Ÿ</strong>ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹æ€§ï¼š</p>
<ul>
<li><strong>é«˜æ•ˆçš„å†…å­˜ç®¡ç†</strong>ï¼šé€šè¿‡ <code>PagedAttention</code> ç®—æ³•ï¼Œ<code>vLLM</code> å®ç°äº†å¯¹ <code>KV</code> ç¼“å­˜çš„é«˜æ•ˆç®¡ç†ï¼Œå‡å°‘äº†å†…å­˜æµªè´¹ï¼Œä¼˜åŒ–äº†æ¨¡å‹çš„è¿è¡Œæ•ˆç‡ã€‚</li>
<li><strong>é«˜ååé‡</strong>ï¼š<code>vLLM</code> æ”¯æŒå¼‚æ­¥å¤„ç†å’Œè¿ç»­æ‰¹å¤„ç†è¯·æ±‚ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹æ¨ç†çš„ååé‡ï¼ŒåŠ é€Ÿäº†æ–‡æœ¬ç”Ÿæˆå’Œå¤„ç†é€Ÿåº¦ã€‚</li>
<li><strong>æ˜“ç”¨æ€§</strong>ï¼š<code>vLLM</code> ä¸ <code>HuggingFace</code> æ¨¡å‹æ— ç¼é›†æˆï¼Œæ”¯æŒå¤šç§æµè¡Œçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç®€åŒ–äº†æ¨¡å‹éƒ¨ç½²å’Œæ¨ç†çš„è¿‡ç¨‹ã€‚å…¼å®¹ <code>OpenAI</code> çš„ <code>API</code> æœåŠ¡å™¨ã€‚</li>
<li><strong>åˆ†å¸ƒå¼æ¨ç†</strong>ï¼šæ¡†æ¶æ”¯æŒåœ¨å¤š <code>GPU</code> ç¯å¢ƒä¸­è¿›è¡Œåˆ†å¸ƒå¼æ¨ç†ï¼Œé€šè¿‡æ¨¡å‹å¹¶è¡Œç­–ç•¥å’Œé«˜æ•ˆçš„æ•°æ®é€šä¿¡ï¼Œæå‡äº†å¤„ç†å¤§å‹æ¨¡å‹çš„èƒ½åŠ›ã€‚</li>
<li><strong>å¼€æºå…±äº«</strong>ï¼š<code>vLLM</code> ç”±äºå…¶å¼€æºçš„å±æ€§ï¼Œæ‹¥æœ‰æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒï¼Œè¿™ä¹Ÿä¾¿äºå¼€å‘è€…è´¡çŒ®å’Œæ”¹è¿›ï¼Œå…±åŒæ¨åŠ¨æŠ€æœ¯å‘å±•ã€‚</li>
</ul>
<h2 id="ç¯å¢ƒå‡†å¤‡">ç¯å¢ƒå‡†å¤‡<a class="anchor-link" href="#ç¯å¢ƒå‡†å¤‡" title="Permanent link">&para;</a></h2>
<p>æœ¬æ–‡åŸºç¡€ç¯å¢ƒå¦‚ä¸‹ï¼š</p>
<pre><code class="language-text">----------------
ubuntu 22.04
python 3.12
cuda 12.1
pytorch 2.3.0
----------------
</code></pre>
<blockquote>
<p>æœ¬æ–‡é»˜è®¤å­¦ä¹ è€…å·²é…ç½®å¥½ä»¥ä¸Š <code>Pytorch (cuda)</code> ç¯å¢ƒï¼Œå¦‚æœªé…ç½®è¯·å…ˆè‡ªè¡Œå®‰è£…ã€‚</p>
</blockquote>
<p>é¦–å…ˆ <code>pip</code> æ¢æºåŠ é€Ÿä¸‹è½½å¹¶å®‰è£…ä¾èµ–åŒ…</p>
<pre><code class="language-bash">python -m pip install --upgrade pip
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

pip install modelscope==1.18.0
pip install openai==1.46.0
pip install tqdm==4.66.2
pip install transformers==4.44.2
pip install vllm==0.6.1.post2
</code></pre>
<blockquote>
<p>è€ƒè™‘åˆ°éƒ¨åˆ†åŒå­¦é…ç½®ç¯å¢ƒå¯èƒ½ä¼šé‡åˆ°ä¸€äº›é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨AutoDLå¹³å°å‡†å¤‡äº† <code>Qwen2.5</code> çš„ç¯å¢ƒé•œåƒï¼Œç‚¹å‡»ä¸‹æ–¹é“¾æ¥å¹¶ç›´æ¥åˆ›å»º <code>AutoDL</code> ç¤ºä¾‹å³å¯ã€‚<br />
<strong><em>https://www.codewithgpu.com/i/datawhalechina/self-llm/Qwen2.5-self-llm</em></strong></p>
</blockquote>
<h2 id="æ¨¡å‹ä¸‹è½½">æ¨¡å‹ä¸‹è½½<a class="anchor-link" href="#æ¨¡å‹ä¸‹è½½" title="Permanent link">&para;</a></h2>
<p>ä½¿ç”¨ <code>modelscope</code> ä¸­çš„ <code>snapshot_download</code> å‡½æ•°ä¸‹è½½æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å‹åç§°ï¼Œå‚æ•° <code>cache_dir</code>ä¸ºæ¨¡å‹çš„ä¸‹è½½è·¯å¾„ã€‚</p>
<p>å…ˆåˆ‡æ¢åˆ° <code>autodl-tmp</code> ç›®å½•ï¼Œ<code>cd /root/autodl-tmp</code> </p>
<p>ç„¶åæ–°å»ºåä¸º <code>model_download.py</code> çš„ <code>python</code> è„šæœ¬ï¼Œå¹¶åœ¨å…¶ä¸­è¾“å…¥ä»¥ä¸‹å†…å®¹å¹¶ä¿å­˜</p>
<pre><code class="language-python"># model_download.py
from modelscope import snapshot_download
model_dir = snapshot_download('qwen/Qwen2.5-7B-Instruct', cache_dir='/root/autodl-tmp', revision='master')
</code></pre>
<p>ç„¶ååœ¨ç»ˆç«¯ä¸­è¾“å…¥ <code>python model_download.py</code> æ‰§è¡Œä¸‹è½½ï¼Œè¿™é‡Œéœ€è¦è€å¿ƒç­‰å¾…ä¸€æ®µæ—¶é—´ç›´åˆ°æ¨¡å‹ä¸‹è½½å®Œæˆã€‚</p>
<blockquote>
<p>æ³¨æ„ï¼šè®°å¾—ä¿®æ”¹ <code>cache_dir</code> ä¸ºä½ çš„æ¨¡å‹ä¸‹è½½è·¯å¾„</p>
</blockquote>
<h2 id="ä»£ç å‡†å¤‡">ä»£ç å‡†å¤‡<a class="anchor-link" href="#ä»£ç å‡†å¤‡" title="Permanent link">&para;</a></h2>
<h3 id="pythonè„šæœ¬">Pythonè„šæœ¬<a class="anchor-link" href="#pythonè„šæœ¬" title="Permanent link">&para;</a></h3>
<p>åœ¨ <code>/root/autodl-tmp</code> è·¯å¾„ä¸‹æ–°å»º <code>vllm_model.py</code> æ–‡ä»¶å¹¶åœ¨å…¶ä¸­è¾“å…¥ä»¥ä¸‹å†…å®¹ï¼Œç²˜è´´ä»£ç åè¯·åŠæ—¶ä¿å­˜æ–‡ä»¶ã€‚ä¸‹é¢çš„ä»£ç æœ‰å¾ˆè¯¦ç»†çš„æ³¨é‡Šï¼Œå¦‚æœ‰ä¸ç†è§£çš„åœ°æ–¹ï¼Œæ¬¢è¿å¤§å®¶æ <code>issue</code>ã€‚</p>
<p>é¦–å…ˆä» <code>vLLM</code> åº“ä¸­å¯¼å…¥ <code>LLM</code> å’Œ <code>SamplingParams</code> ç±»ã€‚<code>LLM</code> ç±»æ˜¯ä½¿ç”¨ <code>vLLM</code> å¼•æ“è¿è¡Œç¦»çº¿æ¨ç†çš„ä¸»è¦ç±»ã€‚<code>SamplingParams</code> ç±»æŒ‡å®šé‡‡æ ·è¿‡ç¨‹çš„å‚æ•°ï¼Œç”¨äºæ§åˆ¶å’Œè°ƒæ•´ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§å’Œå¤šæ ·æ€§ã€‚</p>
<p><code>vLLM</code> æä¾›äº†éå¸¸æ–¹ä¾¿çš„å°è£…ï¼Œæˆ‘ä»¬ç›´æ¥ä¼ å…¥æ¨¡å‹åç§°æˆ–æ¨¡å‹è·¯å¾„å³å¯ï¼Œä¸å¿…æ‰‹åŠ¨åˆå§‹åŒ–æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªä»£ç ç¤ºä¾‹ç†Ÿæ‚‰ä¸‹ <code>vLLM</code> å¼•æ“çš„ä½¿ç”¨æ–¹å¼ã€‚è¢«æ³¨é‡Šçš„éƒ¨åˆ†å†…å®¹å¯ä»¥ä¸°å¯Œæ¨¡å‹çš„èƒ½åŠ›ï¼Œä½†ä¸æ˜¯å¿…è¦çš„ï¼Œå¤§å®¶å¯ä»¥æŒ‰éœ€é€‰æ‹©</p>
<pre><code class="language-python"># vllm_model.py
from vllm import LLM, SamplingParams
from transformers import AutoTokenizer
import os
import json

# è‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ—¶ï¼ŒæŒ‡å®šä½¿ç”¨modelscope; å¦åˆ™ï¼Œä¼šä»HuggingFaceä¸‹è½½
os.environ['VLLM_USE_MODELSCOPE']='True'

def get_completion(prompts, model, tokenizer=None, max_tokens=512, temperature=0.8, top_p=0.95, max_model_len=2048):
    stop_token_ids = [151329, 151336, 151338]
    # åˆ›å»ºé‡‡æ ·å‚æ•°ã€‚temperature æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼Œtop_p æ§åˆ¶æ ¸å¿ƒé‡‡æ ·çš„æ¦‚ç‡
    sampling_params = SamplingParams(temperature=temperature, top_p=top_p, max_tokens=max_tokens, stop_token_ids=stop_token_ids)
    # åˆå§‹åŒ– vLLM æ¨ç†å¼•æ“
    llm = LLM(model=model, tokenizer=tokenizer, max_model_len=max_model_len,trust_remote_code=True)
    outputs = llm.generate(prompts, sampling_params)
    return outputs


if __name__ == &quot;__main__&quot;:    
    # åˆå§‹åŒ– vLLM æ¨ç†å¼•æ“
    model='/root/autodl-tmp/qwen/Qwen2.5-7B-Instruct' # æŒ‡å®šæ¨¡å‹è·¯å¾„
    # model=&quot;qwen/Qwen2.5-7B-Instruct&quot; # æŒ‡å®šæ¨¡å‹åç§°ï¼Œè‡ªåŠ¨ä¸‹è½½æ¨¡å‹
    tokenizer = None
    # åŠ è½½åˆ†è¯å™¨åä¼ å…¥vLLM æ¨¡å‹ï¼Œä½†ä¸æ˜¯å¿…è¦çš„ã€‚
    # tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False) 

    text = [&quot;ä½ å¥½ï¼Œå¸®æˆ‘ä»‹ç»ä¸€ä¸‹ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ã€‚&quot;,
            &quot;å¯ä»¥ç»™æˆ‘å°†ä¸€ä¸ªæœ‰è¶£çš„ç«¥è¯æ•…äº‹å—ï¼Ÿ&quot;]
    # messages = [
    #     {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚&quot;},
    #     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
    # ]
    # ä½œä¸ºèŠå¤©æ¨¡æ¿çš„æ¶ˆæ¯ï¼Œä¸æ˜¯å¿…è¦çš„ã€‚
    # text = tokenizer.apply_chat_template(
    #     messages,
    #     tokenize=False,
    #     add_generation_prompt=True
    # )

    outputs = get_completion(text, model, tokenizer=tokenizer, max_tokens=512, temperature=1, top_p=1, max_model_len=2048)

    # è¾“å‡ºæ˜¯ä¸€ä¸ªåŒ…å« promptã€ç”Ÿæˆæ–‡æœ¬å’Œå…¶ä»–ä¿¡æ¯çš„ RequestOutput å¯¹è±¡åˆ—è¡¨ã€‚
    # æ‰“å°è¾“å‡ºã€‚
    for output in outputs:
        prompt = output.prompt
        generated_text = output.outputs[0].text
        print(f&quot;Prompt: {prompt!r}, Generated text: {generated_text!r}&quot;)
</code></pre>
<p>è¿è¡Œä»£ç </p>
<pre><code class="language-bash">cd /root/autodl-tmp &amp;&amp; python vllm_model.py
</code></pre>
<p>ç»“æœå¦‚ä¸‹ï¼š</p>
<pre><code class="language-bash">Prompt: 'ä½ å¥½ï¼Œå¸®æˆ‘ä»‹ç»ä¸€ä¸‹ä»€ä¹ˆæ—¶å¤§è¯­è¨€æ¨¡å‹ã€‚', Generated text: ' å½“ç„¶å¯ä»¥ï¼å¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç±»èƒ½å¤Ÿç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬çš„äººå·¥æ™ºèƒ½æ¨¡å‹ã€‚å®ƒä»¬é€šå¸¸åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯Transformeræ¶æ„ï¼Œç»è¿‡å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹å’Œç»“æ„ã€‚è¿™äº›æ¨¡å‹å¯ä»¥æ¥å—ä»»æ„çš„è‡ªç„¶è¯­è¨€ä½œä¸ºè¾“å…¥ï¼Œå¹¶èƒ½ç”Ÿæˆç›¸å…³æˆ–ç›¸ä¼¼çš„è¾“å‡ºæ–‡æœ¬ï¼Œå±•ç°å‡ºäº†åœ¨å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚\n\nå¤§è¯­è¨€æ¨¡å‹å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n\n1. **åºå¤§çš„å‚æ•°é‡**ï¼šå¤§è¯­è¨€æ¨¡å‹é€šå¸¸åŒ…å«æ•°äº¿ä¹ƒè‡³ä¸‡äº¿ä¸ªå‚æ•°ã€‚è¿™ç§å·¨å¤§çš„è§„æ¨¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¯­è¨€çš„å¤æ‚æ€§å’Œç»†å¾®å·®åˆ«ã€‚\n2. **è‡ªå›å½’ç”Ÿæˆæ–¹å¼**ï¼šåœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œå¤§è¯­è¨€æ¨¡å‹é€šå¸¸æ˜¯é€è¯è¿›è¡Œé¢„æµ‹å¹¶æ ¹æ®å‰æ–‡å¯¹åæ–‡è¿›è¡Œé¢„æµ‹ï¼Œå› æ­¤ç”Ÿæˆè¿‡ç¨‹æ˜¯æœ‰é¡ºåºä¾èµ–æ€§çš„ã€‚\n3. **é¢„è®­ç»ƒä¸å¾®è°ƒ**ï¼šè¿™ç±»æ¨¡å‹é€šå¸¸æ— éœ€ä¸ºæ¯ä¸ªç‰¹å®šä»»åŠ¡ä»é›¶å¼€å§‹è®­ç»ƒã€‚å…ˆåœ¨å¤§é‡çš„æœªæ ‡è®°æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åå¯ä»¥åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒã€‚\n4. **å¹¿æ³›çš„åº”ç”¨**ï¼šå¤§è¯­è¨€æ¨¡å‹å¯ä»¥è¢«åº”ç”¨äºç¿»è¯‘ã€æ‘˜è¦ã€æ–‡æœ¬ç”Ÿæˆã€é—®ç­”ç³»ç»Ÿã€èŠå¤©æœºå™¨äººç­‰å¤šä¸ªé¢†åŸŸã€‚\n\nç”±äºå¤§è¯­è¨€æ¨¡å‹éœ€è¦æ¶ˆè€—å·¨å¤§çš„è®¡ç®—èµ„æºæ¥è¿›è¡Œè®­ç»ƒå’Œéƒ¨ç½²ï¼Œè¿‘å¹´æ¥åœ¨äº‘è®¡ç®—å’Œç¡¬ä»¶åŠ é€Ÿæ–¹é¢ä¹Ÿæœ‰äº†å¿«é€Ÿçš„å‘å±•ã€‚ä»£è¡¨æ€§çš„å·¥ä½œåŒ…æ‹¬Googleçš„MUMï¼ˆMultitask Unified Modelï¼‰ã€é˜¿é‡Œäº‘çš„é€šä¹‰åƒé—®ç­‰ã€‚\n\nè¯·è®©æˆ‘çŸ¥é“å¦‚æœè¿˜æœ‰å…¶ä»–å…·ä½“çš„é—®é¢˜æˆ‘èƒ½å¸®åŠ©è§£ç­”ï¼'

Prompt: 'å¯ä»¥ç»™æˆ‘å°†ä¸€ä¸ªæœ‰è¶£çš„ç«¥è¯æ•…äº‹å—ï¼Ÿ', Generated text: ' å½“ç„¶å¯ä»¥ã€‚ä¸‹é¢æœ‰ä¸€ä¸ªæœ‰è¶£çš„å°æ•…äº‹ï¼Œæ•…äº‹çš„åå­—å«åšã€Šæœˆäº®ä¸‹çš„å¥‡è¿¹èŠ±å›­ã€‹ï¼š\n\nåœ¨é¥è¿œçš„é“¶è‰²å°é•‡ä¸Šï¼Œæœ‰ä¸€ä¸ªè¢«èŠ±æµ·åŒ…å›´çš„å¥‡è¿¹èŠ±å›­ã€‚è¿™ä¸ªèŠ±å›­éå¸¸ç¥å¥‡ï¼Œæ¯å¤©æ™šä¸Šï¼Œå½“æœˆäº®å‡èµ·çš„æ—¶å€™ï¼Œæ‰€æœ‰çš„èŠ±æœµéƒ½ä¼šå‘å‡ºç’€ç’¨çš„å…‰èŠ’ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¦‚æœä½ åœ¨å¤œé—´å¸¦ç€å…³äºæ„¿æœ›çš„ä¿¡ä»¶æ¥åˆ°èŠ±å›­ï¼Œå¹¶å°†ä¿¡ä»¶ç³»åœ¨ä¸€æœµæ•£å‘ç€å…‰èŠ’çš„èŠ±æœµä¸Šï¼Œä½ çš„æ„¿æœ›å°±èƒ½è¢«æœˆäº®å›å®ç°ã€‚\n\nåœ¨ä¸€ä¸ªç‚çƒ­çš„å¤æ—¥å¤œæ™šï¼Œå°é•‡ä¸Šçš„ä¸€åªåå«å½©ç¾½çš„å°ç™½é¹…é­é‡äº†çƒ¦æ¼ã€‚å®ƒåˆšåˆšå­¦ä¼šæ¸¸æ³³ï¼Œå´å‘ç°è‡ªå·±æ¸¸é€Ÿè¿œè¿œèµ¶ä¸ä¸Šå…¶ä»–åŒç±»ã€‚å½©ç¾½å†³å®šå¿…é¡»å®ç°è‡ªå·±çš„æ„¿æœ›â€”â€”å¸Œæœ›å®ƒèƒ½å¤Ÿæ‹¥æœ‰è·Ÿå…¶ä»–ç™½é¹…ä¸€æ ·çš„æ¸¸æ³³é€Ÿåº¦ã€‚\n\nåœ¨èŠ±å›­çš„å…¥å£å¤„ï¼Œå½©ç¾½å†™ä¸‹äº†æ„¿æœ›ä¿¡ä»¶ï¼Œç„¶ååœ¨èŠ±å›­é‡Œå†™ç€â€œå¸Œæœ›å˜å¿«â€çš„èŠ±æœµä¸Šç³»ä¸Šäº†ä¿¡çº¸ã€‚å½“å®ƒé™é™åœ°ç­‰å¾…æ—¶ï¼ŒèŠ±å›­é‡Œçš„èŠ±æœµä»¬å¼€å§‹å‘å‡ºè¶Šæ¥è¶Šå¼ºçš„å…‰èŠ’ï¼Œç›´åˆ°æ•´ä¸ªèŠ±å›­éƒ½è¢«é—ªé—ªå‘å…‰çš„å…‰èŠ’è¦†ç›–ã€‚ç„¶åï¼Œå¥‡è¿¹å‘ç”Ÿäº†ï¼Œå°å½©ç¾½çš„æ¸¸æ³³é€Ÿåº¦çœŸçš„å˜å¿«äº†ã€‚\n\nå½“å¤©è¾¹æ³›èµ·é±¼è‚šç™½æ—¶ï¼Œå¥‡è¿¹èŠ±å›­å¼€å§‹æ…¢æ…¢æ¢å¤åŸæ ·ï¼ŒèŠ±æµ·è¿åŒé—ªäº®çš„å…‰èŠ’ä¸€åŒæ¶ˆå¤±ï¼Œè€Œå°å½©ç¾½ä¹Ÿå¸¦ç€æ›´åŠ å¿«ä¹çš„å¿ƒæƒ…å›åˆ°å®¶é‡Œã€‚ä»æ­¤ä»¥åï¼Œå°å½©ç¾½ä¸å†æ„Ÿåˆ°è‡ªå‘ï¼Œè€Œæ˜¯å’Œå…¶ä»–çš„ç™½é¹…ä¸€èµ·ï¼Œåœ¨æ°´é‡Œå¿«ä¹åœ°æ¸¸æ¥æ¸¸å»ã€‚\n\nè¿™ä¸ªæ•…äº‹å‘Šè¯‰æˆ‘ä»¬ï¼Œæ¯ä¸ªç”Ÿå‘½éƒ½æœ‰å®ƒçš„ç‹¬ç‰¹ä¹‹å¤„ï¼Œå½“æˆ‘ä»¬å‹‡æ•¢åœ°æ¥å—è‡ªå·±ï¼Œå°±èƒ½å¤Ÿåœ¨è‡ªå·±çš„èƒ½åŠ›èŒƒå›´å†…åˆ›é€ å¥‡è¿¹ã€‚å°±åƒå°å½©ç¾½ä¸€æ ·ï¼Œåªè¦æˆ‘ä»¬å‹‡æ•¢åœ°è¡¨è¾¾è‡ªå·±çš„æ„¿æœ›ï¼Œå¹¶ç›¸ä¿¡æ¢¦æƒ³ä¼šæˆçœŸï¼Œå°±èƒ½å¼€åˆ›å‡ºå±äºè‡ªå·±çš„å¥‡è¿¹ä¹‹è·¯ã€‚å¦‚æœä½ æœ‰äº†æ„¿æœ›ï¼Œä¹Ÿå¯ä»¥åƒå°å½©ç¾½ä¸€æ ·ï¼Œæ¥åˆ°å¥‡è¿¹èŠ±å›­ï¼Œå†™ä¸‹ä½ çš„æ„¿æœ›ï¼Œç­‰å¾…å¥‡è¿¹çš„å‘ç”Ÿã€‚\n\nå¸Œæœ›è¿™ä¸ªæ•…äº‹èƒ½ç»™ä½ å¸¦æ¥ä¸€äº›å¯å‘å’Œå¿«ä¹ï¼å¦‚æœä½ è¿˜æœ‰å…¶ä»–éœ€è¦ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚ ^_^\n\nè¿™ä¸ªæ•…äº‹é‡Œçš„å¥‡è¿¹èŠ±å›­æ˜¯ä¸æ˜¯æœ‰ç‚¹åƒæ„¿æœ›ç¯å¡”çš„è®¾å®šï¼Ÿ æ˜¯çš„ï¼Œè¿™ä¸ªã€Šæœˆäº®ä¸‹çš„å¥‡è¿¹èŠ±å›­ã€‹çš„æ•…äº‹ç¡®å®æœ‰ç‚¹ç±»ä¼¼äºæ„¿æœ›ç¯å¡”æˆ–å…¶ä»–ç±»ä¼¼çš„è®¾å®šï¼Œæ¯”å¦‚æ„¿æœ›æ± å¡˜ã€æ„¿æœ›ç¯æˆ–æ˜¯ä¸€ä¸ªèƒ½å®ç°æ„¿æœ›çš„åœ°æ–¹ã€‚è¿™ä¸€ç‚¹èƒ½æ¿€å‘è¯»è€…çš„æƒ³è±¡åŠ›ï¼Œä½¿å¾—æ•´ä¸ªæ•…äº‹æ›´åŠ æ¢¦å¹»è€Œåˆå¸å¼•äººã€‚\n\nè¿™ç§è®¾å®šéå¸¸æµè¡Œäºç«¥è¯æ•…äº‹å½“ä¸­ï¼Œä¹Ÿå¸¸è§äºä¸€äº›å¹»æƒ³ä½œå“ä¸­ï¼Œæ¯”å¦‚è¿ªå£«å°¼çš„ã€Šé˜¿æ‹‰ä¸ã€‹ç”µå½±é‡Œçš„â€œç¥ç¯â€ä¸é˜¿æ‹‰ä¸è®¸æ„¿çš„æƒ…èŠ‚ï¼Œæˆ–æ˜¯å®‰å¾’ç”Ÿç«¥è¯ã€Šå–ç«æŸ´çš„å°å¥³å­©ã€‹ä¸­çš„æ¸©æš–çš„ç«å…‰ï¼Œä»¥åŠã€Šç¥'
</code></pre>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241220103315.png" style="zoom: 80%;" /></div>

<h3 id="åˆ›å»ºå…¼å®¹-openai-api-æ¥å£çš„æœåŠ¡å™¨">åˆ›å»ºå…¼å®¹ OpenAI API æ¥å£çš„æœåŠ¡å™¨<a class="anchor-link" href="#åˆ›å»ºå…¼å®¹-openai-api-æ¥å£çš„æœåŠ¡å™¨" title="Permanent link">&para;</a></h3>
<p><code>Qwen</code> å…¼å®¹ <code>OpenAI API</code> åè®®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ <code>vLLM</code> åˆ›å»º <code>OpenAI API</code> æœåŠ¡å™¨ã€‚<code>vLLM</code> éƒ¨ç½²å®ç° <code>OpenAI API</code> åè®®çš„æœåŠ¡å™¨éå¸¸æ–¹ä¾¿ã€‚é»˜è®¤ä¼šåœ¨ http://localhost:8000 å¯åŠ¨æœåŠ¡å™¨ã€‚æœåŠ¡å™¨å½“å‰ä¸€æ¬¡æ‰˜ç®¡ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶å®ç°åˆ—è¡¨æ¨¡å‹ã€<code>completions</code> å’Œ <code>chat completions</code> ç«¯å£ã€‚</p>
<ul>
<li><code>completions</code>ï¼šæ˜¯åŸºæœ¬çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œæ¨¡å‹ä¼šåœ¨ç»™å®šçš„æç¤ºåç”Ÿæˆä¸€æ®µæ–‡æœ¬ã€‚è¿™ç§ç±»å‹çš„ä»»åŠ¡é€šå¸¸ç”¨äºç”Ÿæˆæ–‡ç« ã€æ•…äº‹ã€é‚®ä»¶ç­‰ã€‚</li>
<li><code>chat completions</code>ï¼šæ˜¯é¢å‘å¯¹è¯çš„ä»»åŠ¡ï¼Œæ¨¡å‹éœ€è¦ç†è§£å’Œç”Ÿæˆå¯¹è¯ã€‚è¿™ç§ç±»å‹çš„ä»»åŠ¡é€šå¸¸ç”¨äºæ„å»ºèŠå¤©æœºå™¨äººæˆ–è€…å¯¹è¯ç³»ç»Ÿã€‚</li>
</ul>
<p>åœ¨åˆ›å»ºæœåŠ¡å™¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ¨¡å‹åç§°ã€æ¨¡å‹è·¯å¾„ã€èŠå¤©æ¨¡æ¿ç­‰å‚æ•°ã€‚</p>
<ul>
<li><code>--host</code> å’Œ <code>--port</code> å‚æ•°æŒ‡å®šåœ°å€ã€‚</li>
<li><code>--model</code> å‚æ•°æŒ‡å®šæ¨¡å‹åç§°ã€‚</li>
<li><code>--chat-template</code> å‚æ•°æŒ‡å®šèŠå¤©æ¨¡æ¿ã€‚</li>
<li><code>--served-model-name</code> æŒ‡å®šæœåŠ¡æ¨¡å‹çš„åç§°ã€‚</li>
<li><code>--max-model-len</code> æŒ‡å®šæ¨¡å‹çš„æœ€å¤§é•¿åº¦ã€‚</li>
</ul>
<pre><code class="language-bash">python -m vllm.entrypoints.openai.api_server --model /home/team/zhaohongwei/Code/Research/LLM/models/qwen/Qwen2.5-7B-Instruct  --served-model-name Qwen2.5-7B-Instruct --max-model-len=2048
</code></pre>
<p>åŠ è½½å®Œæ¯•åå‡ºç°å¦‚ä¸‹ä¿¡æ¯è¯´æ˜æœåŠ¡æˆåŠŸå¯åŠ¨</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241220105209.png" style="zoom: 80%;" /></div>

<ul>
<li>é€šè¿‡ <code>curl</code> å‘½ä»¤æŸ¥çœ‹å½“å‰çš„æ¨¡å‹åˆ—è¡¨</li>
</ul>
<pre><code class="language-bash">curl http://localhost:8000/v1/models
</code></pre>
<p>â€‹å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º</p>
<pre><code class="language-json">{
  &quot;object&quot;: &quot;list&quot;,
  &quot;data&quot;: [
    {
      &quot;id&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
      &quot;object&quot;: &quot;model&quot;,
      &quot;created&quot;: 1726728585,
      &quot;owned_by&quot;: &quot;vllm&quot;,
      &quot;root&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
      &quot;parent&quot;: null,
      &quot;max_model_len&quot;: 2048,
      &quot;permission&quot;: [
        {
          &quot;id&quot;: &quot;modelperm-4ff5ed0f5793450b81640d0da7d5713b&quot;,
          &quot;object&quot;: &quot;model_permission&quot;,
          &quot;created&quot;: 1726728585,
          &quot;allow_create_engine&quot;: false,
          &quot;allow_sampling&quot;: true,
          &quot;allow_logprobs&quot;: true,
          &quot;allow_search_indices&quot;: false,
          &quot;allow_view&quot;: true,
          &quot;allow_fine_tuning&quot;: false,
          &quot;organization&quot;: &quot;*&quot;,
          &quot;group&quot;: null,
          &quot;is_blocking&quot;: false
        }
      ]
    }
  ]
}
</code></pre>
<ul>
<li>ä½¿ç”¨ <code>curl</code> å‘½ä»¤æµ‹è¯• <code>OpenAI Completions API</code></li>
</ul>
<pre><code class="language-bash">curl http://localhost:8000/v1/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d '{
        &quot;model&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
        &quot;prompt&quot;: &quot;ä½ å¥½&quot;,
        &quot;max_tokens&quot;: 500,
        &quot;temperature&quot;: 0
    }'
</code></pre>
<p>â€‹å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º</p>
<pre><code class="language-json">{
  &quot;id&quot;: &quot;cmpl-e98b85ad1b8942f6959993d644634b0a&quot;,
  &quot;object&quot;: &quot;text_completion&quot;,
  &quot;created&quot;: 1726729800,
  &quot;model&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;text&quot;: &quot;ï¼Œæˆ‘æœ‰ä¸€ä¸ªé—®é¢˜æƒ³è¯·æ•™ã€‚\nå½“ç„¶å¯ä»¥ï¼Œè¯·é—®æ‚¨æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨ã€‚&quot;,
      &quot;logprobs&quot;: null,
      &quot;finish_reason&quot;: &quot;stop&quot;,
      &quot;stop_reason&quot;: 151643,
      &quot;prompt_logprobs&quot;: null
    }
  ],
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 1,
    &quot;total_tokens&quot;: 22,
    &quot;completion_tokens&quot;: 21
  }
}
</code></pre>
<ul>
<li>ç”¨ <code>Python</code> è„šæœ¬è¯·æ±‚ <code>OpenAI Completions API</code> </li>
</ul>
<pre><code class="language-python"># vllm_openai_completions.py
from openai import OpenAI
client = OpenAI(
    base_url=&quot;http://localhost:8000/v1&quot;,
    api_key=&quot;sk-xxx&quot;, # éšä¾¿å¡«å†™ï¼Œåªæ˜¯ä¸ºäº†é€šè¿‡æ¥å£å‚æ•°æ ¡éªŒ
)

completion = client.chat.completions.create(
  model=&quot;Qwen2.5-7B-Instruct&quot;,
  messages=[
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½&quot;}
  ]
)

print(completion.choices[0].message)
</code></pre>
<pre><code class="language-shell">python vllm_openai_completions.py
</code></pre>
<p>â€‹å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º</p>
<pre><code>ChatCompletionMessage(content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ', refusal=None, role='assistant', function_call=None, tool_calls=[])
</code></pre>
<ul>
<li>ç”¨ <code>curl</code> å‘½ä»¤æµ‹è¯• <code>OpenAI Chat Completions API</code> </li>
</ul>
<pre><code class="language-bash">curl http://localhost:8000/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d '{
        &quot;model&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½&quot;}
        ]
    }'
</code></pre>
<p>å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º</p>
<pre><code class="language-json">{
  &quot;id&quot;: &quot;chat-78357219240d49248afa0f655f85d0fc&quot;,
  &quot;object&quot;: &quot;chat.completion&quot;,
  &quot;created&quot;: 1726730139,
  &quot;model&quot;: &quot;Qwen2.5-7B-Instruct&quot;,
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;message&quot;: {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆé—®é¢˜æˆ–è€…éœ€è¦ä»€ä¹ˆä¿¡æ¯å‘¢ï¼Ÿ&quot;,
        &quot;tool_calls&quot;: []
      },
      &quot;logprobs&quot;: null,
      &quot;finish_reason&quot;: &quot;stop&quot;,
      &quot;stop_reason&quot;: null
    }
  ],
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 20,
    &quot;total_tokens&quot;: 36,
    &quot;completion_tokens&quot;: 16
  },
  &quot;prompt_logprobs&quot;: null
}
</code></pre>
<ul>
<li>ç”¨ <code>Python</code> è„šæœ¬è¯·æ±‚ <code>OpenAI Chat Completions API</code> </li>
</ul>
<pre><code class="language-python"># vllm_openai_chat_completions.py
from openai import OpenAI
openai_api_key = &quot;sk-xxx&quot; # éšä¾¿å¡«å†™ï¼Œåªæ˜¯ä¸ºäº†é€šè¿‡æ¥å£å‚æ•°æ ¡éªŒ
openai_api_base = &quot;http://localhost:8000/v1&quot;

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

chat_outputs = client.chat.completions.create(
    model=&quot;Qwen2.5-7B-Instruct&quot;,
    messages=[
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Qwen2.5å’ŒQwen2ç›¸æ¯”æœ‰è¿›æ­¥å’ŒåŒºåˆ«&quot;},
    ]
)
print(chat_outputs)
</code></pre>
<pre><code class="language-shell">python vllm_openai_chat_completions.py
</code></pre>
<p>å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º</p>
<pre><code>ChatCompletion(id='chat-0c17fb285541409ab6500a41b9312756', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Qwen2.5æ˜¯åŸºäºQwen2è¿›è¡Œçš„è¿­ä»£å‡çº§ï¼Œç›¸è¾ƒäºQwen2ï¼ŒQwen2.5åœ¨å¤šä¸ªæ–¹é¢éƒ½æœ‰æ‰€æå‡å’Œæ”¹è¿›ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¸»è¦çš„åŒºåˆ«å’Œè¿›æ­¥ï¼š\n\n1. **æ€§èƒ½ä¼˜åŒ–**ï¼šQwen2.5åœ¨å¤„ç†é€Ÿåº¦å’Œå“åº”æ—¶é—´ä¸Šæœ‰æ‰€æå‡ï¼Œèƒ½å¤Ÿæ›´å¿«é€Ÿåœ°ç†è§£å’Œç”Ÿæˆå›ç­”ã€‚\n\n2. **è¯­è¨€ç†è§£èƒ½åŠ›å¢å¼º**ï¼šQwen2.5å¯¹è‡ªç„¶è¯­è¨€çš„ç†è§£èƒ½åŠ›è¿›ä¸€æ­¥æå‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤æ‚çš„è¯­è¨€ç»“æ„å’Œè¯­ä¹‰ï¼Œæä¾›æ›´å‡†ç¡®çš„å›ç­”ã€‚\n\n3. **çŸ¥è¯†åº“æ›´æ–°**ï¼šQwen2.5çš„çŸ¥è¯†åº“è¿›è¡Œäº†æ›´æ–°å’Œæ‰©å±•ï¼Œæ¶µç›–äº†æ›´å¤šçš„ä¿¡æ¯å’Œæœ€æ–°çš„æ•°æ®ï¼Œä½¿å¾—å›ç­”æ›´åŠ å‡†ç¡®å’Œå…¨é¢ã€‚\n\n4. **å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›å¢å¼º**ï¼šQwen2.5åœ¨å¤„ç†å›¾ç‰‡ã€éŸ³é¢‘ç­‰å¤šåª’ä½“ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›æœ‰æ‰€å¢å¼ºï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”ŸæˆåŸºäºå¤šç§è¾“å…¥å½¢å¼çš„å›ç­”ã€‚\n\n5. **ä¸ªæ€§åŒ–å’Œå®šåˆ¶åŒ–**ï¼šQwen2.5åœ¨ä¸ªæ€§åŒ–æœåŠ¡æ–¹é¢æœ‰æ‰€æ”¹è¿›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚æä¾›å®šåˆ¶åŒ–çš„å›ç­”å’Œå»ºè®®ã€‚\n\n6. **å®‰å…¨æ€§å¢å¼º**ï¼šQwen2.5åœ¨å®‰å…¨æ€§æ–¹é¢è¿›è¡Œäº†åŠ å¼ºï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ä¿æŠ¤ç”¨æˆ·çš„éšç§å’Œæ•°æ®å®‰å…¨ã€‚\n\n7. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**ï¼šQwen2.5åœ¨ç”¨æˆ·äº¤äº’è®¾è®¡æ–¹é¢è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½¿å¾—ç”¨æˆ·ä¸AIçš„äº¤æµæ›´åŠ æµç•…å’Œè‡ªç„¶ã€‚\n\nè¿™äº›æ”¹è¿›å’Œæå‡ä½¿å¾—Qwen2.5åœ¨å¤„ç†å„ç§å¤æ‚ä»»åŠ¡å’Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚æ–¹é¢è¡¨ç°å¾—æ›´åŠ å‡ºè‰²ï¼Œæä¾›æ›´é«˜è´¨é‡çš„æœåŠ¡ã€‚', refusal=None, role='assistant', function_call=None, tool_calls=[]), stop_reason=None)], created=1726730431, model='Qwen2.5-7B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=304, prompt_tokens=33, total_tokens=337, completion_tokens_details=None), prompt_logprobs=None)
</code></pre>
<p>å¦å¤–ï¼Œåœ¨ä»¥ä¸Šæ‰€æœ‰çš„åœ¨è¯·æ±‚å¤„ç†è¿‡ç¨‹ä¸­ï¼Œ <code>API</code> åç«¯éƒ½ä¼šæ‰“å°ç›¸å¯¹åº”çš„æ—¥å¿—å’Œç»Ÿè®¡ä¿¡æ¯ğŸ˜Š</p>
<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241220110139.png" style="zoom: 80%;" /></div>

<h2 id="æ¨ç†é€Ÿåº¦æµ‹è¯•">æ¨ç†é€Ÿåº¦æµ‹è¯•<a class="anchor-link" href="#æ¨ç†é€Ÿåº¦æµ‹è¯•" title="Permanent link">&para;</a></h2>
<p>æ—¢ç„¶ <code>vLLM</code> æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†å’Œéƒ¨ç½²æœåŠ¡ç³»ç»Ÿï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸å¦¨å°±æµ‹è¯•ä¸€ä¸‹æ¨¡å‹çš„å›å¤ç”Ÿæˆé€Ÿåº¦ã€‚çœ‹çœ‹å’ŒåŸå§‹çš„é€Ÿåº¦ç›¸æ¯”æœ‰å¤šå¤§çš„æå‡ã€‚è¿™é‡Œç›´æ¥ä½¿ç”¨ <code>vLLM</code> è‡ªå¸¦çš„ <code>benchmark_throughput.py</code> è„šæœ¬è¿›è¡Œæµ‹è¯•ã€‚å¯ä»¥å°†å½“å‰æ–‡ä»¶å¤¹ <code>benchmark_throughput.py</code> è„šæœ¬æ”¾åœ¨ <code>/root/autodl-tmp/</code> ç›®å½•ä¸‹ï¼›æˆ–è€…ä¹Ÿå¯ä»¥è‡ªè¡Œ<a href="https://github.com/vllm-project/vllm/blob/main/benchmarks/benchmark_throughput.py">ä¸‹è½½æœ€æ–°ç‰ˆè„šæœ¬</a></p>
<p>ä¸‹é¢æ˜¯ä¸€äº› <code>benchmark_throughput.py</code> è„šæœ¬çš„å‚æ•°è¯´æ˜ï¼š</p>
<ul>
<li><code>--model</code> å‚æ•°æŒ‡å®šæ¨¡å‹è·¯å¾„æˆ–åç§°ã€‚</li>
<li><code>--backend</code> æ¨ç†åç«¯ï¼Œå¯ä»¥æ˜¯ <code>vllm</code>ã€<code>hf</code> å’Œ <code>mii</code>ã€‚åˆ†å¸ƒå¯¹åº” <code>vLLM</code>ã€<code>HuggingFace</code> å’Œ <code>Mii</code> æ¨ç†åç«¯ã€‚</li>
<li><code>--input-len</code> è¾“å…¥é•¿åº¦</li>
<li><code>--output-len</code> è¾“å‡ºé•¿åº¦</li>
<li><code>--num-prompts</code> ç”Ÿæˆçš„ prompt æ•°é‡</li>
<li><code>--seed</code> éšæœºç§å­</li>
<li><code>--dtype</code> æ•°æ®ç±»å‹</li>
<li><code>--max-model-len</code> æ¨¡å‹æœ€å¤§é•¿åº¦</li>
<li><code>--hf_max_batch_size</code> <code>transformers</code> åº“çš„æœ€å¤§æ‰¹å¤„ç†å¤§å°ï¼ˆä»…ä»…å¯¹äº <code>hf</code> æ¨ç†åç«¯æœ‰æ•ˆä¸”ä¸ºå¿…å¡«å­—æ®µï¼‰</li>
<li><code>--dataset</code> æ•°æ®é›†è·¯å¾„ã€‚ï¼ˆå¦‚æœªè®¾ç½®ä¼šè‡ªåŠ¨ç”Ÿæˆæ•°æ®ï¼‰</li>
</ul>
<p>æµ‹è¯• <code>vLLM</code> æ¨ç†é€Ÿåº¦çš„å‘½ä»¤å’Œå‚æ•°è®¾ç½®</p>
<pre><code class="language-bash">python benchmark_throughput.py \
    --model /root/autodl-tmp/qwen/Qwen2.5-7B-Instruct \
    --backend vllm \
    --input-len 64 \
    --output-len 128 \
    --num-prompts 25 \
    --seed 2024 \
    --dtype float16 \
    --max-model-len 512
</code></pre>
<p>å¾—åˆ°çš„ç»“æœå¦‚ä¸‹æ‰€ç¤º</p>
<pre><code>Throughput: 9.14 requests/s, 1754.43 tokens/s
</code></pre>
<p>æµ‹è¯•å…¶ä»–æ–¹å¼ï¼ˆå³ä½¿ç”¨ <code>HuggingFace</code> çš„ <code>Transformers</code> åº“ï¼‰æ¨ç†é€Ÿåº¦çš„å‘½ä»¤å’Œå‚æ•°è®¾ç½®</p>
<pre><code class="language-bash">python benchmark_throughput.py \
    --model /root/autodl-tmp/qwen/Qwen2.5-7B-Instruct \
    --backend hf \
    --input-len 64 \
    --output-len 128 \
    --num-prompts 25 \
    --seed 2024 \
    --dtype float16 \
    --hf-max-batch-size 25
</code></pre>
<p>å¾—åˆ°çš„ç»“æœå¦‚ä¸‹æ‰€ç¤º</p>
<pre><code>Throughput: 6.99 requests/s, 1342.53 tokens/s
</code></pre>
<p>å¯¹æ¯”ä¸¤è€…çš„æ¨ç†é€Ÿåº¦ï¼Œåœ¨æœ¬æ¬¡æµ‹è¯• ï¼ˆå•å¡ <code>RTX4090D 24G</code> ï¼‰ä¸­ <code>vLLM</code> çš„é€Ÿåº¦è¦æ¯”åŸå§‹çš„é€Ÿåº¦å¿« <strong>34%</strong> å·¦å³ ğŸ¤—</p>
<blockquote>
<p><strong>æ³¨æ„</strong>ï¼šæœ¬æ¬¡æµ‹è¯•å¹¶éä¸¥è°¨çš„æµ‹è¯•ï¼Œä¸”æ¯ä¸ªäººçš„æœºå™¨é…ç½®å’Œç¯å¢ƒéƒ½å¯èƒ½å­˜åœ¨å·®å¼‚ï¼Œå› æ­¤ä¸Šè¿°å®éªŒç»“æœä»…ä¾›ä½œä¸º <code>case</code> å‚è€ƒï¼Œè¯»è€…å¯ä»¥åœ¨è‡ªå·±çš„ç¯å¢ƒä¸­å–å¤šä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶å¤šæ¬¡å®éªŒå–å¹³å‡ä»¥å¾—åˆ°ä¸¥è°¨çš„å®éªŒç»“è®ºã€‚</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">æ¨ç†æ¡†æ¶</th>
<th style="text-align: center;">requests/s</th>
<th style="text-align: center;">tokens/s</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><code>vllm</code></td>
<td style="text-align: center;">9.14</td>
<td style="text-align: center;">1754.43</td>
</tr>
<tr>
<td style="text-align: center;"><code>hf</code></td>
<td style="text-align: center;">6.99</td>
<td style="text-align: center;">1342.53</td>
</tr>
<tr>
<td style="text-align: center;"><code>diff</code></td>
<td style="text-align: center;">30.76%</td>
<td style="text-align: center;">30.68%</td>
</tr>
</tbody>
</table>
                </div>

                <!-- Comments Section (Giscus) -->
                <section class="comments-section">
                    <h3><i class="fas fa-comments"></i> è¯„è®º</h3>
                    <script src="https://giscus.app/client.js"
                        data-repo="Geeks-Z/Geeks-Z.github.io"
                        data-repo-id=""
                        data-category="Announcements"
                        data-category-id=""
                        data-mapping="pathname"
                        data-strict="0"
                        data-reactions-enabled="1"
                        data-emit-metadata="0"
                        data-input-position="bottom"
                        data-theme="preferred_color_scheme"
                        data-lang="zh-CN"
                        crossorigin="anonymous"
                        async>
                    </script>
                </section>
            </article>

            <footer class="post-footer">
                <p>Â© 2025 Hongwei Zhao. Built with â¤ï¸</p>
            </footer>
        </main>
    </div>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="themeToggle" aria-label="åˆ‡æ¢ä¸»é¢˜">
        <i class="fas fa-moon"></i>
    </button>

    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        const icon = themeToggle.querySelector('i');
        const hljsDark = document.getElementById('hljs-theme-dark');
        const hljsLight = document.getElementById('hljs-theme-light');
        
        // Check saved theme or system preference
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
        
        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            html.setAttribute('data-theme', 'dark');
            icon.className = 'fas fa-sun';
            hljsDark.disabled = false;
            hljsLight.disabled = true;
        }
        
        themeToggle.addEventListener('click', () => {
            const isDark = html.getAttribute('data-theme') === 'dark';
            if (isDark) {
                html.removeAttribute('data-theme');
                icon.className = 'fas fa-moon';
                localStorage.setItem('theme', 'light');
                hljsDark.disabled = true;
                hljsLight.disabled = false;
            } else {
                html.setAttribute('data-theme', 'dark');
                icon.className = 'fas fa-sun';
                localStorage.setItem('theme', 'dark');
                hljsDark.disabled = false;
                hljsLight.disabled = true;
            }
            
            // Update Giscus theme
            const giscusFrame = document.querySelector('iframe.giscus-frame');
            if (giscusFrame) {
                giscusFrame.contentWindow.postMessage({
                    giscus: {
                        setConfig: {
                            theme: isDark ? 'light' : 'dark'
                        }
                    }
                }, 'https://giscus.app');
            }
        });
        
        // Highlight.js
        document.addEventListener('DOMContentLoaded', () => {
            hljs.highlightAll();
        });
        
        // KaTeX auto-render
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
        
        // TOC active state
        const tocLinks = document.querySelectorAll('.toc-container a');
        const headings = document.querySelectorAll('.post-content h2, .post-content h3, .post-content h4');
        
        function updateTocActive() {
            let current = '';
            headings.forEach(heading => {
                const rect = heading.getBoundingClientRect();
                if (rect.top <= 100) {
                    current = heading.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', updateTocActive);
        updateTocActive();
    </script>
</body>
</html>
